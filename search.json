[{"path":"https://mark-eis.github.io/ParaAnita/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 ParaAnita authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Mark Eisler. Author, maintainer, copyright holder.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Eisler M (2024). ParaAnita: Functions Binary Binomial Data Analysis. R package version 1.1.1.00005, https://mark-eis.github.io/ParaAnita/.","code":"@Manual{,   title = {ParaAnita: Functions for Binary and Binomial Data Analysis},   author = {Mark Eisler},   year = {2024},   note = {R package version 1.1.1.00005},   url = {https://mark-eis.github.io/ParaAnita/}, }"},{"path":[]},{"path":"https://mark-eis.github.io/ParaAnita/index.html","id":"r-functions-for-binary-and-binomial-data-analysis","dir":"","previous_headings":"","what":"R Functions for Binary and Binomial Data Analysis","title":"Functions for Binary and Binomial Data Analysis","text":"Author: Mark C. Eisler eMail: Mark.Eisler@bristol.ac.uk ORCID = 0000-0001-6843-3345","code":""},{"path":"https://mark-eis.github.io/ParaAnita/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Functions for Binary and Binomial Data Analysis","text":"can install development version ParaAnita GitHub :","code":"# install.packages(\"devtools\") devtools::install_github(\"Mark-Eis/ParaAnita\")"},{"path":"https://mark-eis.github.io/ParaAnita/index.html","id":"paraanita-package-description-","dir":"","previous_headings":"Installation","what":"ParaAnita Package Description: –","title":"Functions for Binary and Binomial Data Analysis","text":"ParaAnita R package includes functions intended address simplify number issues commonly encountered binary (Bernoulli) binomial data analysis using generalised linear models. specifically, ParaAnita following: – Summarises binary binomial proportion data contingency tables contingency_table(), xcontingency_table(), binom_contingency(). Calculates odds ratios confidence intervals associated probabilities odds_ratio(). Gets, sets removes contrasts attribute selected categorical variables (factors) within data get_contrasts(), get_contr_data(), set_contrasts(), set_contrasts<-(), set_contr_treat() set_contr_treat<-(). Gets, sets manipulates categorical variable contrast names contr_colnames(), contr_colnames<-(), contr_colpfx<-(), helm_names() helm_names<-(). Compares related generalised linear models using various measures anova_tbl(), comp_glm(), summanov() univ_anova(). Collates model results standard errors, optional grouping levels selected categorical variables, format convenient plotting glm_plotlist() glm_plotdata(), plots individual faceted plots ggplot.glm_plotdata() var_labs(). Adds, modifies, removes selects factors data add_grps(), drop_null(), drop_zero(), expl_fcts(), fct_to_num(), good_levels(). Simulates Bernoulli binomial proportion data sets categorical explanatory variables bernoulli_data() binom_data(). Simplifies statistical analysis chsqfish() starsig(). Provides auxiliary print functions prints objects derived ParaAnita S3 methods announce(), lf(), print_all() print_lf(). Tidies R workspace rm_objects(). Includes dataset: budworm, David Collett (1991). Modelling Binary Data. London: Chapman & Hall.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/ParaAnita-package.html","id":null,"dir":"Reference","previous_headings":"","what":"ParaAnita: Functions for Binary and Binomial Data Analysis — ParaAnita-package","title":"ParaAnita: Functions for Binary and Binomial Data Analysis — ParaAnita-package","text":"Summarises binary (Bernoulli) binomial proportion data contingency tables as_binom_contingency(), contingency_table(), xcontingency_table(), binom_contingency(). Calculates odds ratios confidence intervals associated probabilities odds_ratio(). Gets, sets removes contrasts attribute selected categorical variables (factors) within data get_contrasts(), get_contr_data(), set_contrasts(), set_contrasts<-(), set_contr_treat() set_contr_treat<-(). Gets, sets manipulates contrast names contr_colnames(), contr_colnames<-(), contr_colpfx<-(), helm_names() helm_names<-(). Compares related generalised linear models using various measures anova_tbl(), comp_glm(), summanov() univ_anova(). Collates model results standard errors, optional grouping levels selected categorical variables, format convenient plotting glm_plotlist() glm_plotdata(); plots individual faceted plots ggplot.glm_plotdata() var_labs(). Adds, modifies, removes selects factors data add_grps(), drop_null(), drop_zero(), expl_fcts(), fct_to_num(), good_levels(). Simulates Bernoulli binomial proportion data sets categorical explanatory variables bernoulli_data() binom_data(). Simplifies statistical analysis chsqfish() starsig(). Provides auxilliary print functions prints objects derived ParaAnita S3 methods announce(), lf(), print_all(), print_lf(). Tidies workspace rm_objects(). Dataset: budworm.","code":""},{"path":[]},{"path":"https://mark-eis.github.io/ParaAnita/reference/ParaAnita-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"ParaAnita: Functions for Binary and Binomial Data Analysis — ParaAnita-package","text":"Maintainer: Mark Eisler Mark.Eisler@bristol.ac.uk (ORCID) [copyright holder]","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/Print_Methods.html","id":null,"dir":"Reference","previous_headings":"","what":"S3 Print Methods — Print_Methods","title":"S3 Print Methods — Print_Methods","text":"S3 methods printing objects class \"announce\", \"binom_contingency\", \"contingency_table\", \"odds_ratio\" \"summ_anov\".","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/Print_Methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"S3 Print Methods — Print_Methods","text":"","code":"# S3 method for announce print(x, ...)  # S3 method for binom_contingency print(   x,   width = NULL,   ...,   n = NULL,   max_extra_cols = NULL,   max_footer_lines = NULL )  # S3 method for contingency_table print(   x,   width = NULL,   ...,   n = NULL,   max_extra_cols = NULL,   max_footer_lines = NULL )  # S3 method for odds_ratio print(   x,   width = NULL,   ...,   n = NULL,   max_extra_cols = NULL,   max_footer_lines = NULL,   digits = 7 )  # S3 method for summ_anov print(x, ...)"},{"path":"https://mark-eis.github.io/ParaAnita/reference/Print_Methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"S3 Print Methods — Print_Methods","text":"x object used select method. ... arguments passed methods. width used max.levels NULL, see . n Number rows show. NULL, default, print rows less print_max option. Otherwise, print many rows specified print_min option. max_extra_cols Number extra columns print abbreviated information , width small entire tibble. NULL, max_extra_cols option used. previously defined n_extra argument soft-deprecated. max_footer_lines Maximum number footer lines. NULL, max_footer_lines option used. digits integer indicating maximum number decimal places p-values, see round(); default 7.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/Print_Methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"S3 Print Methods — Print_Methods","text":"argument x.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/Print_Methods.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"S3 Print Methods — Print_Methods","text":"print methods return argument x invisibly, via invisible(). Notwithstanding print.odds_ratio() rounds p-values maximimum number decimal places specified digits argument, p-values printed show three significant figures.","code":""},{"path":[]},{"path":"https://mark-eis.github.io/ParaAnita/reference/Print_Methods.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"S3 Print Methods — Print_Methods","text":"","code":"## print.announce() — print an 'announce' object announce(\"x\", lead = \"Lorem ipsum dolor sit amet\") #> _____________________________ #> Lorem ipsum dolor sit amet: - #>  #> [1] \"x\"  (d <- bernoulli_data()) #> ___________________________ #> Simulated Bernoulli Data: - #>  #> # A tibble: 330 × 2 #>    iv       dv #>  * <fct> <int> #>  1 a         0 #>  2 a         1 #>  3 a         1 #>  4 a         0 #>  5 a         0 #>  6 a         0 #>  7 a         0 #>  8 a         0 #>  9 a         1 #> 10 a         1 #> # ℹ 320 more rows  ## print.binom_contingency() — print a 'binom_contingency' object d |> binom_contingency(dv) #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 5 × 3 #>   iv       pn    qn #> * <fct> <int> <int> #> 1 a        29    37 #> 2 b        25    41 #> 3 c        27    39 #> 4 d        16    50 #> 5 e         7    59  (d2 <- tibble(     iv = letters[1:4] |> sample(10, replace = TRUE) |> as.factor(),     dv = c(\"Success\", \"Fail\", \"Borderline\")  |> sample(10, replace = TRUE)   )) #> # A tibble: 10 × 2 #>    iv    dv         #>    <fct> <chr>      #>  1 a     Borderline #>  2 a     Success    #>  3 a     Borderline #>  4 b     Success    #>  5 c     Success    #>  6 a     Fail       #>  7 c     Fail       #>  8 c     Borderline #>  9 b     Success    #> 10 d     Fail        ## print.contingency_table() — print a 'contingency_table' object d2 |> contingency_table(dv) #> ____________________ #> Contingency Table: - #>  #> # A tibble: 4 × 4 #>   iv    Borderline Success  Fail #> * <fct>      <int>   <int> <int> #> 1 a              2       1     1 #> 2 b              0       2     0 #> 3 c              1       1     1 #> 4 d              0       0     1  ## print.odds_ratio() — print an 'odds_ratio' object d |> odds_ratio(.dep_var = dv, .ind_var = iv) #> Waiting for profiling to be done... #> ____________________________ #> Estimates and Odds Ratios: - #>  #> # A tibble: 5 × 7 #>   parameter   estimate    se     p_val odds_ratio ci[,\"2.5%\"] [,\"97.5%\"] sig   #>   <chr>          <dbl> <dbl>     <dbl>      <dbl>       <dbl>      <dbl> <fct> #> 1 (Intercept)   -0.244 0.248 0.326          1         NA          NA     NS    #> 2 ivb           -0.251 0.355 0.479          0.778      0.386       1.56  NS    #> 3 ivc           -0.124 0.352 0.725          0.883      0.441       1.76  NS    #> 4 ivd           -0.896 0.379 0.0182         0.408      0.191       0.850 *     #> 5 ive           -1.89  0.470 0.0000599      0.151      0.0562      0.363 ***    ## print.odds_ratio() — print an 'odds_ratio' object with p values to 12 decimal places d |> odds_ratio(.dep_var = dv, .ind_var = iv) |> print(digits = 12) #> Waiting for profiling to be done... #> ____________________________ #> Estimates and Odds Ratios: - #>  #> # A tibble: 5 × 7 #>   parameter   estimate    se     p_val odds_ratio ci[,\"2.5%\"] [,\"97.5%\"] sig   #>   <chr>          <dbl> <dbl>     <dbl>      <dbl>       <dbl>      <dbl> <fct> #> 1 (Intercept)   -0.244 0.248 0.326          1         NA          NA     NS    #> 2 ivb           -0.251 0.355 0.479          0.778      0.386       1.56  NS    #> 3 ivc           -0.124 0.352 0.725          0.883      0.441       1.76  NS    #> 4 ivd           -0.896 0.379 0.0182         0.408      0.191       0.850 *     #> 5 ive           -1.89  0.470 0.0000599      0.151      0.0562      0.363 ***    ## print.summanov() — print a 'summanov' object d |> summanov(dv, iv) #> _______________________________________ #> GLM Summary and Analysis of Deviance: - #>  #> $iv #> ______________ #> GLM Summary: - #>  #>  #> Call: #> glm(formula = inject(!!.dep_var ~ !!sym(x)), family = .family,  #>     data = data) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)  -0.2436     0.2480  -0.982   0.3260     #> ivb          -0.2511     0.3548  -0.708   0.4792     #> ivc          -0.1241     0.3524  -0.352   0.7247     #> ivd          -0.8958     0.3795  -2.361   0.0182 *   #> ive          -1.8880     0.4704  -4.013 5.99e-05 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 411.29  on 329  degrees of freedom #> Residual deviance: 385.15  on 325  degrees of freedom #> AIC: 395.15 #>  #> Number of Fisher Scoring iterations: 4 #>  #> ____________ #> GLM Anova: - #>  #> Analysis of Deviance Table #>  #> Model: binomial, link: logit #>  #> Response: dv #>  #> Terms added sequentially (first to last) #>  #>  #>      Df Deviance Resid. Df Resid. Dev  Pr(>Chi)     #> NULL                   329     411.29               #> iv    4   26.132       325     385.15 2.976e-05 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   rm(d, d2)"},{"path":"https://mark-eis.github.io/ParaAnita/reference/Simulate_Data.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated Bernoulli and Binomial Proportion Data — Simulate_Data","title":"Simulated Bernoulli and Binomial Proportion Data — Simulate_Data","text":"bernoulli_data() creates simulated univariate Bernoulli data set dependent variable dv values 0 1, independent variable iv levels represented lower case letters. binom_data() creates simulated univariate binomial proportion data set variable pn representing number successes, variable qn representing number failures, independent variable iv levels represented lower case letters.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/Simulate_Data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated Bernoulli and Binomial Proportion Data — Simulate_Data","text":"","code":"bernoulli_data(   levels = 5,   length = 66,   probs = seq(0.5, 0.1, length.out = levels) )  binom_data(   levels = 5,   length = 66L,   probs = seq(0.5, 0.1, length.out = levels) )"},{"path":"https://mark-eis.github.io/ParaAnita/reference/Simulate_Data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulated Bernoulli and Binomial Proportion Data — Simulate_Data","text":"levels numeric, desired number levels independent variable iv;  default 5. length numeric, desired number simulated observations per level independent variable iv; default 20. probs numeric vector length levels, representing probabilities success corresponding level; default seq(0.5, 0.1, length.= levels).","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/Simulate_Data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulated Bernoulli and Binomial Proportion Data — Simulate_Data","text":"object class \"announce\" inheriting tibble column iv independant variable, bernoulli_data(), column dv representing dependant variable; binom_data(), columns pn qn representing number \"successes\" \"failures\", follows: - iv factor representing levels independant variable. dv integer representing value dependent variable. pn integer representing  number successes. qn integer representing  number failures.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/Simulate_Data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulated Bernoulli and Binomial Proportion Data — Simulate_Data","text":"random sample Bernoulli distribution obtained level independent variable iv, corresponding probability given probs, using rbinom() size = 1. result returned tibble two columns, iv representing level independent variable dv representing simulated data. result may easily converted (simulated) proportion data inspected using binom_contingency(), see examples. random sample binomial distribution size length obtained level independent variable iv, corresponding probability given probs, using rbinom() size = levels. bernoulli_data() binom_data() used demonstrating testing functions contingency_table(), binom_contingency() odds_ratio().","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/Simulate_Data.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Simulated Bernoulli and Binomial Proportion Data — Simulate_Data","text":"default length 66 minimum number trials probability success 0.1 overall probability zero failures less 1 1000 .e., \\((1 - 0.1)^{66} < 0.001\\).","code":""},{"path":[]},{"path":"https://mark-eis.github.io/ParaAnita/reference/Simulate_Data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated Bernoulli and Binomial Proportion Data — Simulate_Data","text":"","code":"bernoulli_data() #> ___________________________ #> Simulated Bernoulli Data: - #>  #> # A tibble: 330 × 2 #>    iv       dv #>  * <fct> <int> #>  1 a         1 #>  2 a         0 #>  3 a         0 #>  4 a         0 #>  5 a         1 #>  6 a         0 #>  7 a         0 #>  8 a         1 #>  9 a         1 #> 10 a         0 #> # ℹ 320 more rows bernoulli_data() |> binom_contingency(dv, iv) #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 5 × 3 #>   iv       pn    qn #> * <fct> <int> <int> #> 1 a        30    36 #> 2 b        26    40 #> 3 c        20    46 #> 4 d        11    55 #> 5 e         6    60 bernoulli_data(probs = seq(0.4, 0, length.out = 5)) |> binom_contingency(dv, iv) #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 5 × 3 #>   iv       pn    qn #> * <fct> <int> <int> #> 1 a        31    35 #> 2 b        19    47 #> 3 c        12    54 #> 4 d         4    62 #> 5 e         0    66  binom_data() #> __________________________ #> Simulated Binomial Data: - #>  #> # A tibble: 5 × 3 #>   iv       pn    qn #> * <fct> <int> <int> #> 1 a        36    30 #> 2 b        22    44 #> 3 c        23    43 #> 4 d        10    56 #> 5 e         8    58 binom_data(probs = seq(0.4, 0, length.out = 5)) #> __________________________ #> Simulated Binomial Data: - #>  #> # A tibble: 5 × 3 #>   iv       pn    qn #> * <fct> <int> <int> #> 1 a        26    40 #> 2 b        19    47 #> 3 c        14    52 #> 4 d         8    58 #> 5 e         0    66"},{"path":"https://mark-eis.github.io/ParaAnita/reference/add_grps.html","id":null,"dir":"Reference","previous_headings":"","what":"Add Factors to Data Based on Grouped Levels of an Existing Factor — add_grps","title":"Add Factors to Data Based on Grouped Levels of an Existing Factor — add_grps","text":"Add new factors data based grouped levels existing factor, using key compatible fct_collapse.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/add_grps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add Factors to Data Based on Grouped Levels of an Existing Factor — add_grps","text":"","code":"add_grps(data, .fct, .key, .sort = TRUE)"},{"path":"https://mark-eis.github.io/ParaAnita/reference/add_grps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add Factors to Data Based on Grouped Levels of an Existing Factor — add_grps","text":"data data frame, data frame extension (e.g. tibble). .fct quoted name existing (ungrouped) factor. .key list nested, named lists representing groupings, containing series named character vectors. .sort logical, whether sort levels new factors; default TRUE.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/add_grps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add Factors to Data Based on Grouped Levels of an Existing Factor — add_grps","text":"data frame, data frame extension (e.g. tibble), equivalent data additional grouped factor(s).","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/add_grps.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add Factors to Data Based on Grouped Levels of an Existing Factor — add_grps","text":".key argument series named lists nested within outer list. nested named list must contain one named character vectors representing new factor groupings. nested lists structured compatibility fct_collapse() package forcats. add_grps() add new, grouped factors data, one nested list name. Levels assigned new grouped factors using name whichever character vector, , contains old factor level. none , original ungrouped factor level used. Various different groupings factor may conveniently added data using add_grps() corresponding series related binomial glms compared using comp_glm().","code":""},{"path":[]},{"path":"https://mark-eis.github.io/ParaAnita/reference/add_grps.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add Factors to Data Based on Grouped Levels of an Existing Factor — add_grps","text":"","code":"(d <- binom_data(levels = 6)) #> __________________________ #> Simulated Binomial Data: - #>  #> # A tibble: 6 × 3 #>   iv       pn    qn #> * <fct> <int> <int> #> 1 a        33    33 #> 2 b        21    45 #> 3 c        22    44 #> 4 d        15    51 #> 5 e        12    54 #> 6 f        12    54  ## One grouped factor (grp_key <- list(g = c(\"a\", \"c\", \"e\"), h = c(\"b\", \"d\", \"f\"))) #> $g #> [1] \"a\" \"c\" \"e\" #>  #> $h #> [1] \"b\" \"d\" \"f\" #>   d |> add_grps(iv, list(iv2 = grp_key)) #> __________________________ #> Simulated Binomial Data: - #>  #> # A tibble: 6 × 4 #>   iv    iv2      pn    qn #>   <fct> <fct> <int> <int> #> 1 a     g        33    33 #> 2 b     h        21    45 #> 3 c     g        22    44 #> 4 d     h        15    51 #> 5 e     g        12    54 #> 6 f     h        12    54  ## Several grouped factors grp_key <- list(     iv2 = grp_key,     iv3 = list(i = c(\"a\", \"b\", \"c\"), j = c(\"d\", \"e\", \"f\")),     iv4 = list(k = c(\"a\", \"b\"), l = c(\"c\", \"d\"), m = c(\"e\", \"f\")) )  d |> add_grps(iv, grp_key) #> __________________________ #> Simulated Binomial Data: - #>  #> # A tibble: 6 × 6 #>   iv    iv2   iv3   iv4      pn    qn #>   <fct> <fct> <fct> <fct> <int> <int> #> 1 a     g     i     k        33    33 #> 2 b     h     i     k        21    45 #> 3 c     g     i     l        22    44 #> 4 d     h     j     l        15    51 #> 5 e     g     j     m        12    54 #> 6 f     h     j     m        12    54  ## Cut out the middleman list(     iv2 = list(g = c(\"a\", \"c\", \"e\"), h = c(\"b\", \"d\", \"f\")),     iv3 = list(i = c(\"a\", \"b\", \"c\"), j = c(\"d\", \"e\", \"f\")),     iv4 = list(k = c(\"a\", \"b\"), l = c(\"c\", \"d\"), m = c(\"e\", \"f\")) ) |> add_grps(d, iv, .key = _) #> __________________________ #> Simulated Binomial Data: - #>  #> # A tibble: 6 × 6 #>   iv    iv2   iv3   iv4      pn    qn #>   <fct> <fct> <fct> <fct> <int> <int> #> 1 a     g     i     k        33    33 #> 2 b     h     i     k        21    45 #> 3 c     g     i     l        22    44 #> 4 d     h     j     l        15    51 #> 5 e     g     j     m        12    54 #> 6 f     h     j     m        12    54  ## Binomial data with month as explanatory variable, using dplyr and forcats package functions (d <- binom_data(12, probs = rep_len(0.5, 12)) |>     mutate(across(iv, \\(x) fct_recode(x, !!!setNames(letters[1:12], month.abb)))) |>     rename(month = \"iv\")) #> __________________________ #> Simulated Binomial Data: - #>  #> # A tibble: 12 × 3 #>    month    pn    qn #>    <fct> <int> <int> #>  1 Jan      31    35 #>  2 Feb      30    36 #>  3 Mar      31    35 #>  4 Apr      28    38 #>  5 May      35    31 #>  6 Jun      33    33 #>  7 Jul      35    31 #>  8 Aug      36    30 #>  9 Sep      38    28 #> 10 Oct      29    37 #> 11 Nov      25    41 #> 12 Dec      35    31  ## Name three lists of different month groupings using lapply() (grp_key <- list(     list(1:3, 4:6, 7:9, 10:12),     list(1:4, 5:8, 9:12),     list(c(1:3, 10:12), 4:9) ) |> lapply(\\(x) lapply(x, \\(y) month.abb[y])) |> lapply(\\(x) setNames(x, paste0(\"group\", seq_along(x)))) |> (\\(x) setNames(x, paste0(\"months\", seq_along(x))))()) #> $months1 #> $months1$group1 #> [1] \"Jan\" \"Feb\" \"Mar\" #>  #> $months1$group2 #> [1] \"Apr\" \"May\" \"Jun\" #>  #> $months1$group3 #> [1] \"Jul\" \"Aug\" \"Sep\" #>  #> $months1$group4 #> [1] \"Oct\" \"Nov\" \"Dec\" #>  #>  #> $months2 #> $months2$group1 #> [1] \"Jan\" \"Feb\" \"Mar\" \"Apr\" #>  #> $months2$group2 #> [1] \"May\" \"Jun\" \"Jul\" \"Aug\" #>  #> $months2$group3 #> [1] \"Sep\" \"Oct\" \"Nov\" \"Dec\" #>  #>  #> $months3 #> $months3$group1 #> [1] \"Jan\" \"Feb\" \"Mar\" \"Oct\" \"Nov\" \"Dec\" #>  #> $months3$group2 #> [1] \"Apr\" \"May\" \"Jun\" \"Jul\" \"Aug\" \"Sep\" #>  #>   add_grps(d, month, grp_key)        ## Add the new year groups to data #> __________________________ #> Simulated Binomial Data: - #>  #> # A tibble: 12 × 6 #>    month months1 months2 months3    pn    qn #>    <fct> <fct>   <fct>   <fct>   <int> <int> #>  1 Jan   group1  group1  group1     31    35 #>  2 Feb   group1  group1  group1     30    36 #>  3 Mar   group1  group1  group1     31    35 #>  4 Apr   group2  group1  group2     28    38 #>  5 May   group2  group2  group2     35    31 #>  6 Jun   group2  group2  group2     33    33 #>  7 Jul   group3  group2  group2     35    31 #>  8 Aug   group3  group2  group2     36    30 #>  9 Sep   group3  group3  group2     38    28 #> 10 Oct   group4  group3  group1     29    37 #> 11 Nov   group4  group3  group1     25    41 #> 12 Dec   group4  group3  group1     35    31  ## Example from fct_collapse() using gss_cat dataset from {forcats} package # \\dontshow{    if (!requireNamespace(\"forcats\", quietly = TRUE))         warning(\"package 'forcats' must be installed\")    try(gss_cat <- forcats::gss_cat) # }  fct_count(gss_cat$partyid) #> # A tibble: 10 × 2 #>    f                      n #>    <fct>              <int> #>  1 No answer            154 #>  2 Don't know             1 #>  3 Other party          393 #>  4 Strong republican   2314 #>  5 Not str republican  3032 #>  6 Ind,near rep        1791 #>  7 Independent         4119 #>  8 Ind,near dem        2499 #>  9 Not str democrat    3690 #> 10 Strong democrat     3490  grp_key <- list(     partyid2 = list(         missing = c(\"No answer\", \"Don't know\"),         other = \"Other party\",         rep = c(\"Strong republican\", \"Not str republican\"),         ind = c(\"Ind,near rep\", \"Independent\", \"Ind,near dem\"),         dem = c(\"Not str democrat\", \"Strong democrat\")     ) )  gss_cat |>     add_grps(partyid, grp_key) |>     _$partyid2 |> fct_count() #> # A tibble: 5 × 2 #>   f           n #>   <fct>   <int> #> 1 dem      7180 #> 2 ind      8409 #> 3 missing   155 #> 4 other     393 #> 5 rep      5346  gss_cat |>     add_grps(partyid, grp_key, .sort = FALSE) |>     _$partyid2 |> fct_count() #> # A tibble: 5 × 2 #>   f           n #>   <fct>   <int> #> 1 missing   155 #> 2 other     393 #> 3 rep      5346 #> 4 ind      8409 #> 5 dem      7180  # \\dontshow{     rm(gss_cat) # }  rm(grp_key, d)"},{"path":"https://mark-eis.github.io/ParaAnita/reference/announce.html","id":null,"dir":"Reference","previous_headings":"","what":"Announce Class for Consistent Printing — announce","title":"Announce Class for Consistent Printing — announce","text":"Creates object class \"announce\" built-title string used printing.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/announce.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Announce Class for Consistent Printing — announce","text":"","code":"announce(object = vector(), lead = \"Announce\", ...)"},{"path":"https://mark-eis.github.io/ParaAnita/reference/announce.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Announce Class for Consistent Printing — announce","text":"object Object converted \"announce\" class. lead character string giving title printed. ... named arguments forwarded print methods classes inherited object.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/announce.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Announce Class for Consistent Printing — announce","text":"object class \"announce\" inheriting class(es) object.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/announce.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Announce Class for Consistent Printing — announce","text":"announce() converts object class \"announce\", inheriting existing class(es).","code":""},{"path":[]},{"path":"https://mark-eis.github.io/ParaAnita/reference/announce.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Announce Class for Consistent Printing — announce","text":"","code":"announce() #> ___________ #> Announce: - #>  #> logical(0) (cpt <- announce(\"x\", lead = \"Lorem ipsum dolor sit amet\")) #> _____________________________ #> Lorem ipsum dolor sit amet: - #>  #> [1] \"x\" .class2(cpt) #> [1] \"announce\"  \"character\"  ## an Announce object, or one inheriting from announce, can be safely overwritten (cpt <- announce(cpt, \"Consectetur adipiscing elit\")) #> ______________________________ #> Consectetur adipiscing elit: - #>  #> [1] \"x\" .class2(cpt) #> [1] \"announce\"  \"character\"  rm(cpt)"},{"path":"https://mark-eis.github.io/ParaAnita/reference/anova_tbl.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Tibble from List of Anovas — anova_tbl","title":"Create Tibble from List of Anovas — anova_tbl","text":"Create tibble list anovas compare model null model compare two nested models.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/anova_tbl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Tibble from List of Anovas — anova_tbl","text":"","code":"anova_tbl(anova_ls)"},{"path":"https://mark-eis.github.io/ParaAnita/reference/anova_tbl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Tibble from List of Anovas — anova_tbl","text":"anova_ls list anova objects.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/anova_tbl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Tibble from List of Anovas — anova_tbl","text":"object classes \"anova_tbl\", \"announce\", inheriting tibble, showing table entries anova, one per line.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/anova_tbl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create Tibble from List of Anovas — anova_tbl","text":"anovas compared must type .e., must analyses single model object must comparisons two models. models one independent variable, results may difficult interpret warning given. anova_tbl() can used easily conveniently compare list anovas obtained summanov  list_transpose, see examples.","code":""},{"path":[]},{"path":"https://mark-eis.github.io/ParaAnita/reference/anova_tbl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Tibble from List of Anovas — anova_tbl","text":"","code":"## Following on from summanov() examples…  ## Simulate Bernoulli data (d <- list(     iv2 = list(g = c(\"a\", \"c\", \"e\"), h = c(\"b\", \"d\", \"f\")),     iv3 = list(i = c(\"a\", \"b\", \"c\"), j = c(\"d\", \"e\", \"f\")),     iv4 = list(k = c(\"a\", \"b\"), l = c(\"c\", \"d\"), m = c(\"e\", \"f\")) ) |> add_grps(binom_data(levels = 6), iv, .key = _)) #> __________________________ #> Simulated Binomial Data: - #>  #> # A tibble: 6 × 6 #>   iv    iv2   iv3   iv4      pn    qn #>   <fct> <fct> <fct> <fct> <int> <int> #> 1 a     g     i     k        38    28 #> 2 b     h     i     k        27    39 #> 3 c     g     i     l        19    47 #> 4 d     h     j     l        14    52 #> 5 e     g     j     m         9    57 #> 6 f     h     j     m         6    60  ## Create list of GLM anovas using summanov() (alist <- d |> summanov(cbind(pn, qn), starts_with(\"iv\")) |>     list_transpose() |> _$anova) #> $iv #> ____________ #> GLM Anova: - #>  #> Analysis of Deviance Table #>  #> Model: binomial, link: logit #>  #> Response: cbind(pn, qn) #>  #> Terms added sequentially (first to last) #>  #>  #>      Df Deviance Resid. Df Resid. Dev  Pr(>Chi)     #> NULL                     5      54.06               #> iv    5    54.06         0       0.00 2.037e-10 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> $iv2 #> ____________ #> GLM Anova: - #>  #> Analysis of Deviance Table #>  #> Model: binomial, link: logit #>  #> Response: cbind(pn, qn) #>  #> Terms added sequentially (first to last) #>  #>  #>      Df Deviance Resid. Df Resid. Dev Pr(>Chi)   #> NULL                     5     54.060            #> iv2   1   4.4865         4     49.573  0.03416 * #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> $iv3 #> ____________ #> GLM Anova: - #>  #> Analysis of Deviance Table #>  #> Model: binomial, link: logit #>  #> Response: cbind(pn, qn) #>  #> Terms added sequentially (first to last) #>  #>  #>      Df Deviance Resid. Df Resid. Dev  Pr(>Chi)     #> NULL                     5      54.06               #> iv3   1   38.699         4      15.36 4.944e-10 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> $iv4 #> ____________ #> GLM Anova: - #>  #> Analysis of Deviance Table #>  #> Model: binomial, link: logit #>  #> Response: cbind(pn, qn) #>  #> Terms added sequentially (first to last) #>  #>  #>      Df Deviance Resid. Df Resid. Dev  Pr(>Chi)     #> NULL                     5     54.060               #> iv4   2   48.681         3      5.379 2.686e-11 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ## Tibble from list of GLM anovas  alist |> anova_tbl() #> _________________________________________________ #> Analysis of Deviance (Comparing to null model): - #>  #> # A tibble: 4 × 9 #>   Name  `Null Df` `Null Dev`    Df Deviance `Resid. Df` `Resid. Dev` `Pr(>Chi)` #> * <chr>     <int>      <dbl> <int>    <dbl>       <int>        <dbl>      <dbl> #> 1 iv            5       54.1     5    54.1            0     5.77e-15   2.04e-10 #> 2 iv2           5       54.1     1     4.49           4     4.96e+ 1   3.42e- 2 #> 3 iv3           5       54.1     1    38.7            4     1.54e+ 1   4.94e-10 #> 4 iv4           5       54.1     2    48.7            3     5.38e+ 0   2.69e-11 #> # ℹ 1 more variable: sig <fct>  ## Add GLM anova with two independent variables alist$iv3_iv4 <- glm(cbind(pn, qn) ~ iv3 + iv4, family = binomial, data = d) |>     anova()  ## Tibble from list with multivariable anova invokes warning try(alist |> anova_tbl()) #> Warning: iv3_iv4 has > 1 independent variable, interpret with caution #> _________________________________________________ #> Analysis of Deviance (Comparing to null model): - #>  #> # A tibble: 5 × 9 #>   Name   `Null Df` `Null Dev`    Df Deviance `Resid. Df` `Resid. Dev` `Pr(>Chi)` #> * <chr>      <int>      <dbl> <int>    <dbl>       <int>        <dbl>      <dbl> #> 1 iv             5       54.1     5    54.1            0     5.77e-15   2.04e-10 #> 2 iv2            5       54.1     1     4.49           4     4.96e+ 1   3.42e- 2 #> 3 iv3            5       54.1     1    38.7            4     1.54e+ 1   4.94e-10 #> 4 iv4            5       54.1     2    48.7            3     5.38e+ 0   2.69e-11 #> 5 iv3_i…         5       54.1     1    38.7            4     1.54e+ 1   4.94e-10 #> # ℹ 1 more variable: sig <fct>  rm(d, alist)"},{"path":"https://mark-eis.github.io/ParaAnita/reference/binom_contingency.html","id":null,"dir":"Reference","previous_headings":"","what":"Binomial Contingency Table for Data with a Binary Outcome — binom_contingency","title":"Binomial Contingency Table for Data with a Binary Outcome — binom_contingency","text":"binom_contingency() creates binomial contingency table data binary dependent variable one categorical independent variables, optionally including totals, proportions confidence intervals.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/binom_contingency.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Binomial Contingency Table for Data with a Binary Outcome — binom_contingency","text":"","code":"binom_contingency(   .data,   .dep_var,   ...,   .drop_zero = FALSE,   .propci = FALSE,   .level = 0.95 )  as_binom_contingency(object, ...)  # S3 method for data.frame as_binom_contingency(   object,   ...,   .pn = NULL,   .qn = NULL,   .drop_zero = FALSE,   .propci = FALSE,   .level = 0.95 )"},{"path":"https://mark-eis.github.io/ParaAnita/reference/binom_contingency.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Binomial Contingency Table for Data with a Binary Outcome — binom_contingency","text":".data data frame, data frame extension (e.g. tibble). .dep_var <data-masking> quoted name binary dependent variable, numeric values 0 1. ... binomial_contingency():  <tidy-select> quoted name(s) one factor character vector columns .data, included (excluded ) output. as_binomial_contingency(): arguments passed methods. .drop_zero logical. TRUE, levels explanatory factors values .dep_var either zero one dropped output; default FALSE. .propci logical. TRUE, row output \"binom_contingency\" object includes totals, proportions confidence intervals; default FALSE. .level confidence level required; default 0.95. object data frame, data frame extension (e.g. tibble), coerced \"binom_contingency\" object. .pn, .qn character vector, names columns object representing numbers successes failures Bernoulli trials; default NULL.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/binom_contingency.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Binomial Contingency Table for Data with a Binary Outcome — binom_contingency","text":"object class \"binom_contingency\", \"announce\", inheriting tibble, columns pn qn representing number \"successes\" \"failures\" respectively, columns independent (explanatory) variables. .propci = TRUE additional columns output representing totals, proportions confidence intervals.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/binom_contingency.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Binomial Contingency Table for Data with a Binary Outcome — binom_contingency","text":"Categorical variables (.e. factors character vectors) .data required factors resulting contingency table may selected inclusion exclusion using ... argument <tidy-select> syntax package dplyr, including use “selection helpers”. ... arguments supplied, categorical variables .data (.dep_var) used. list defused R expressions, instance created expl_fcts(), may used ... arguments injected using splice-operator, !!!, see examples. Use drop_zero = TRUE drop levels explanatory factors values .dep_var either zero one, prevent warning messages ‘fitted probabilities numerically 0 1 occurred’ fitting generalized linear models using glm() calculating odds ratios using odds_ratio(); see examples Venables & Ripley (2002, pp. 197–8). as_binom_contingency() attempts coerce object class \"binom_contingency\". .pn .qn arguments provided, assumed columns \"pn\" \"qn\" respectively.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/binom_contingency.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Binomial Contingency Table for Data with a Binary Outcome — binom_contingency","text":"Confidence intervals calculated using prop.test(), based Wilson's score method without continuity correction (Newcombe, 1998).","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/binom_contingency.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Binomial Contingency Table for Data with a Binary Outcome — binom_contingency","text":"Confidence interval R's prop.test() differs hand calculation result SAS.  Stack Exchange. Newcombe R.G. (1998). Two-Sided Confidence Intervals Single Proportion: Comparison Seven Methods. Statistics Medicine, 17, 857-872.  doi:10.1002/(SICI)1097-0258(19980430)17:8<857::AID-SIM777>3.0.CO;2-E . Venables, W.N. Ripley, B.D. (2002) Modern Applied Statistics S. New York: Springer. doi:10.1007/978-0-387-21706-2 . Yates' continuity correction confidence interval returned prop.test.  Stack Exchange.","code":""},{"path":[]},{"path":"https://mark-eis.github.io/ParaAnita/reference/binom_contingency.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Binomial Contingency Table for Data with a Binary Outcome — binom_contingency","text":"","code":"## Bernoulli data with a single explanatory variable (d <- bernoulli_data()) #> ___________________________ #> Simulated Bernoulli Data: - #>  #> # A tibble: 330 × 2 #>    iv       dv #>  * <fct> <int> #>  1 a         0 #>  2 a         1 #>  3 a         1 #>  4 a         1 #>  5 a         0 #>  6 a         1 #>  7 a         1 #>  8 a         0 #>  9 a         0 #> 10 a         1 #> # ℹ 320 more rows  d |> binom_contingency(dv) #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 5 × 3 #>   iv       pn    qn #> * <fct> <int> <int> #> 1 a        28    38 #> 2 b        26    40 #> 3 c        19    47 #> 4 d        18    48 #> 5 e         8    58  d |> binom_contingency(dv, .propci = TRUE) #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 5 × 7 #>   iv       pn    qn     n     p  lower upper #> * <fct> <int> <int> <int> <dbl>  <dbl> <dbl> #> 1 a        28    38    66 0.424 0.312  0.544 #> 2 b        26    40    66 0.394 0.285  0.515 #> 3 c        19    47    66 0.288 0.193  0.406 #> 4 d        18    48    66 0.273 0.180  0.390 #> 5 e         8    58    66 0.121 0.0627 0.221 #> \tConfidence level 0.95   ## Use .data pronoun for more informative error messages d |> binom_contingency(.data$dv) #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 5 × 3 #>   iv       pn    qn #> * <fct> <int> <int> #> 1 a        28    38 #> 2 b        26    40 #> 3 c        19    47 #> 4 d        18    48 #> 5 e         8    58  try(d |> binom_contingency(dx)) #> Error : object 'dx' not found  try(d |> binom_contingency(.data$dx)) #> Error in .data$dx : Column `dx` not found in `.data`.  ## NB this section is intended to be pasted in, rather than run by example() if (FALSE) {     oldopt <- options(warn = 0, nwarnings = 50)      ## Bernoulli data with identical responses for     ##   the last level of the explanatory variable     d <- bernoulli_data(probs = seq(0.4, 0, length.out = 5))     d |> binom_contingency(dv)      ## Elicits mutiple warnings in glm.fit()     ##   'fitted probabilities numerically 0 or 1 occurred'     d |> binom_contingency(dv) |>         glm(cbind(pn, qn) ~ iv, binomial, data = _) |>         confint()     summary(warnings())      ##  Argument .drop_zero = TRUE in binom_contingency()     ##    prevents these warnings     d |> binom_contingency(dv, .drop_zero = TRUE)      d |> binom_contingency(dv, .drop_zero = TRUE) |>         glm(cbind(pn, qn) ~ iv, binomial, data = _) |>         confint()      options(oldopt) }  ## Bernoulli data with multiple explanatory variables (d <- list(     iv2 = list(i = c(\"a\", \"c\", \"e\", \"g\"), j = c(\"b\", \"d\", \"f\", \"h\")),     iv3 = list(k = c(\"a\", \"b\", \"c\", \"d\"), l = c(\"e\", \"f\", \"g\", \"h\")),     iv4 = list(k = c(\"a\", \"b\"), l = c(\"c\", \"d\"), m = c(\"e\", \"f\")) ) |> add_grps(bernoulli_data(levels = 8), iv, .key = _)) #> ___________________________ #> Simulated Bernoulli Data: - #>  #> # A tibble: 528 × 5 #>    iv    iv2   iv3   iv4      dv #>    <fct> <fct> <fct> <fct> <int> #>  1 a     i     k     k         1 #>  2 a     i     k     k         1 #>  3 a     i     k     k         0 #>  4 a     i     k     k         0 #>  5 a     i     k     k         0 #>  6 a     i     k     k         0 #>  7 a     i     k     k         0 #>  8 a     i     k     k         1 #>  9 a     i     k     k         0 #> 10 a     i     k     k         0 #> # ℹ 518 more rows  d |> binom_contingency(dv) #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 8 × 6 #>   iv    iv2   iv3   iv4      pn    qn #> * <fct> <fct> <fct> <fct> <int> <int> #> 1 a     i     k     k        24    42 #> 2 b     j     k     k        28    38 #> 3 c     i     k     l        26    40 #> 4 d     j     k     l        25    41 #> 5 e     i     l     m        18    48 #> 6 f     j     l     m        12    54 #> 7 g     i     l     g         8    58 #> 8 h     j     l     h         7    59  d |> binom_contingency(dv, iv, iv3) #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 8 × 4 #>   iv    iv3      pn    qn #> * <fct> <fct> <int> <int> #> 1 a     k        24    42 #> 2 b     k        28    38 #> 3 c     k        26    40 #> 4 d     k        25    41 #> 5 e     l        18    48 #> 6 f     l        12    54 #> 7 g     l         8    58 #> 8 h     l         7    59  d |> binom_contingency(dv, !c(iv2, iv4)) #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 8 × 4 #>   iv    iv3      pn    qn #> * <fct> <fct> <int> <int> #> 1 a     k        24    42 #> 2 b     k        28    38 #> 3 c     k        26    40 #> 4 d     k        25    41 #> 5 e     l        18    48 #> 6 f     l        12    54 #> 7 g     l         8    58 #> 8 h     l         7    59  d |> binom_contingency(dv, !!!expl_fcts(d)) #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 8 × 6 #>   iv    iv2   iv3   iv4      pn    qn #> * <fct> <fct> <fct> <fct> <int> <int> #> 1 a     i     k     k        24    42 #> 2 b     j     k     k        28    38 #> 3 c     i     k     l        26    40 #> 4 d     j     k     l        25    41 #> 5 e     i     l     m        18    48 #> 6 f     j     l     m        12    54 #> 7 g     i     l     g         8    58 #> 8 h     j     l     h         7    59  d |> binom_contingency(dv, .propci = TRUE) #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 8 × 10 #>   iv    iv2   iv3   iv4      pn    qn     n     p  lower upper #> * <fct> <fct> <fct> <fct> <int> <int> <int> <dbl>  <dbl> <dbl> #> 1 a     i     k     k        24    42    66 0.364 0.258  0.484 #> 2 b     j     k     k        28    38    66 0.424 0.312  0.544 #> 3 c     i     k     l        26    40    66 0.394 0.285  0.515 #> 4 d     j     k     l        25    41    66 0.379 0.271  0.499 #> 5 e     i     l     m        18    48    66 0.273 0.180  0.390 #> 6 f     j     l     m        12    54    66 0.182 0.107  0.291 #> 7 g     i     l     g         8    58    66 0.121 0.0627 0.221 #> 8 h     j     l     h         7    59    66 0.106 0.0523 0.203 #> \tConfidence level 0.95   d |> binom_contingency(dv, .drop_zero = TRUE) #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 8 × 6 #>   iv    iv2   iv3   iv4      pn    qn #> * <fct> <fct> <fct> <fct> <int> <int> #> 1 a     i     k     k        24    42 #> 2 b     j     k     k        28    38 #> 3 c     i     k     l        26    40 #> 4 d     j     k     l        25    41 #> 5 e     i     l     m        18    48 #> 6 f     j     l     m        12    54 #> 7 g     i     l     g         8    58 #> 8 h     j     l     h         7    59  d |>    binom_contingency(dv, iv2, iv3, .drop_zero = TRUE) |>    glm(cbind(pn, qn) ~ ., binomial, data = _) |>    summary() #>  #> Call: #> glm(formula = cbind(pn, qn) ~ ., family = binomial, data = binom_contingency(d,  #>     dv, iv2, iv3, .drop_zero = TRUE)) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)  -0.4069     0.1605  -2.536   0.0112 *   #> iv2j         -0.0799     0.1999  -0.400   0.6894     #> iv3l         -1.1361     0.2067  -5.496 3.88e-08 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 33.6983  on 3  degrees of freedom #> Residual deviance:  1.3006  on 1  degrees of freedom #> AIC: 27.397 #>  #> Number of Fisher Scoring iterations: 3 #>   d |>    binom_contingency(dv, iv2, iv3, .drop_zero = TRUE) |>    glm(cbind(pn, qn) ~ ., binomial, data = _) |>    odds_ratio() #>  #> Call:  glm(formula = cbind(pn, qn) ~ ., family = binomial, data = binom_contingency(d,  #>     dv, iv2, iv3, .drop_zero = TRUE)) #>  #> Waiting for profiling to be done... #> ____________________________ #> Estimates and Odds Ratios: - #>  #> # A tibble: 3 × 7 #>   parameter   estimate    se  p_val odds_ratio ci[,\"2.5%\"] [,\"97.5%\"] sig   #>   <chr>          <dbl> <dbl>  <dbl>      <dbl>       <dbl>      <dbl> <fct> #> 1 (Intercept)  -0.407  0.160 0.0112      1          NA         NA     *     #> 2 iv2j         -0.0799 0.200 0.689       0.923       0.623      1.37  NS    #> 3 iv3l         -1.14   0.207 0           0.321       0.213      0.479 ***    ## Use {dplyr} selection helpers e.g., last_col(), num_range() and starts_with() d |> binom_contingency(dv, last_col(1L))  ## Offset of 1L used, since last column of d is dv #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 5 × 3 #>   iv4      pn    qn #> * <fct> <int> <int> #> 1 k        52    80 #> 2 l        51    81 #> 3 m        30   102 #> 4 g         8    58 #> 5 h         7    59  d |> binom_contingency(dv, !last_col(1L)) #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 8 × 5 #>   iv    iv2   iv3      pn    qn #> * <fct> <fct> <fct> <int> <int> #> 1 a     i     k        24    42 #> 2 b     j     k        28    38 #> 3 c     i     k        26    40 #> 4 d     j     k        25    41 #> 5 e     i     l        18    48 #> 6 f     j     l        12    54 #> 7 g     i     l         8    58 #> 8 h     j     l         7    59  d |> binom_contingency(dv, num_range(\"iv\", 2:3)) #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 4 × 4 #>   iv2   iv3      pn    qn #> * <fct> <fct> <int> <int> #> 1 i     k        50    82 #> 2 j     k        53    79 #> 3 i     l        26   106 #> 4 j     l        19   113  d |> binom_contingency(dv, !num_range(\"iv\", 2:3)) #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 8 × 4 #>   iv    iv4      pn    qn #> * <fct> <fct> <int> <int> #> 1 a     k        24    42 #> 2 b     k        28    38 #> 3 c     l        26    40 #> 4 d     l        25    41 #> 5 e     m        18    48 #> 6 f     m        12    54 #> 7 g     g         8    58 #> 8 h     h         7    59  d |> binom_contingency(dv, starts_with(\"iv\")) #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 8 × 6 #>   iv    iv2   iv3   iv4      pn    qn #> * <fct> <fct> <fct> <fct> <int> <int> #> 1 a     i     k     k        24    42 #> 2 b     j     k     k        28    38 #> 3 c     i     k     l        26    40 #> 4 d     j     k     l        25    41 #> 5 e     i     l     m        18    48 #> 6 f     j     l     m        12    54 #> 7 g     i     l     g         8    58 #> 8 h     j     l     h         7    59  d |> binom_contingency(dv, !starts_with(\"iv\")) ## Here, negation excludes all explanatory factors #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 1 × 2 #>      pn    qn #> * <int> <int> #> 1   148   380  ## as_binom_contingency()  (d <- data.frame(         iv = letters[1:5],         s = c(34, 31, 16, 0, 10),         f = c(32, 35, 50, 66, 56)     )) #>   iv  s  f #> 1  a 34 32 #> 2  b 31 35 #> 3  c 16 50 #> 4  d  0 66 #> 5  e 10 56  as_binom_contingency(d, .pn = \"s\", .qn = \"f\") #> Coercing `.pn` and/or `.qn` to integer #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 5 × 3 #>   iv       pn    qn #> * <chr> <int> <int> #> 1 a        34    32 #> 2 b        31    35 #> 3 c        16    50 #> 4 d         0    66 #> 5 e        10    56  as_binom_contingency(d, .pn = \"s\", .qn = \"f\", .drop_zero = TRUE) #> Coercing `.pn` and/or `.qn` to integer #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 4 × 3 #>   iv       pn    qn #> * <chr> <int> <int> #> 1 a        34    32 #> 2 b        31    35 #> 3 c        16    50 #> 4 e        10    56  (d <- binom_data()) #> __________________________ #> Simulated Binomial Data: - #>  #> # A tibble: 5 × 3 #>   iv       pn    qn #> * <fct> <int> <int> #> 1 a        35    31 #> 2 b        26    40 #> 3 c        17    49 #> 4 d        17    49 #> 5 e        10    56  d |> as_binom_contingency() #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 5 × 3 #>   iv       pn    qn #> * <fct> <int> <int> #> 1 a        35    31 #> 2 b        26    40 #> 3 c        17    49 #> 4 d        17    49 #> 5 e        10    56  d |> as_binom_contingency(.propci = TRUE) #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 5 × 7 #>   iv       pn    qn     n     p  lower upper #> * <fct> <int> <int> <int> <dbl>  <dbl> <dbl> #> 1 a        35    31    66 0.530 0.412  0.646 #> 2 b        26    40    66 0.394 0.285  0.515 #> 3 c        17    49    66 0.258 0.167  0.374 #> 4 d        17    49    66 0.258 0.167  0.374 #> 5 e        10    56    66 0.152 0.0844 0.257 #> \tConfidence level 0.95   rm(d)"},{"path":"https://mark-eis.github.io/ParaAnita/reference/budworm.html","id":null,"dir":"Reference","previous_headings":"","what":"Budworm Data — budworm","title":"Budworm Data — budworm","text":"Venables Ripley (2002) state: \"Collett (1991, p. 75) reports experiment toxicity tobacco budworm Heliothis virescens doses pyrethroid trans-cypermethrin moths beginning show resistance. Batches 20 moths sex exposed three days pyrethroid number batch dead knocked recorded.\" Collett, D. (1991) Modelling Binary Data. London: Chapman & Hall.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/budworm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Budworm Data — budworm","text":"","code":"budworm"},{"path":[]},{"path":"https://mark-eis.github.io/ParaAnita/reference/budworm.html","id":"","dir":"Reference","previous_headings":"","what":"Budworm Data — budworm","title":"Budworm Data — budworm","text":"data.frame 12 rows 4 columns: – ldose Dose pyrethroid trans-cypermethrin. sex Sex budworm. numdead Number dead knocked . numalive Number alive.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/budworm.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Budworm Data — budworm","text":"W.N. Venables B.D. Ripley (2002). Modern Applied Statistics S. Fourth Edition 2002. Statistics Computing, © 2002 Springer Science+Business Media New York. doi:10.1007/978-0-387-21706-2 . Chapter 7: Generalized Linear Models, p. 190.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/chsqfish.html","id":null,"dir":"Reference","previous_headings":"","what":"Chi-Squared or Fisher's Exact Test — chsqfish","title":"Chi-Squared or Fisher's Exact Test — chsqfish","text":"Test input data using Chi-squared Fisher's exact test appropriate.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/chsqfish.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Chi-Squared or Fisher's Exact Test — chsqfish","text":"","code":"chsqfish(...)"},{"path":"https://mark-eis.github.io/ParaAnita/reference/chsqfish.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Chi-Squared or Fisher's Exact Test — chsqfish","text":"... vector, matrix, data frame valid input chisq.test","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/chsqfish.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Chi-Squared or Fisher's Exact Test — chsqfish","text":"list containing observed expected values result either chisq.test() fisher.test(), appropriate.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/chsqfish.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Chi-Squared or Fisher's Exact Test — chsqfish","text":"Uses chisq.test() calculate expected values applies Chi-squared test expected values 5 greater, otherwise applies fisher.test().","code":""},{"path":[]},{"path":"https://mark-eis.github.io/ParaAnita/reference/chsqfish.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Chi-Squared or Fisher's Exact Test — chsqfish","text":"","code":"(t <- bernoulli_data(2, 50, c(0.6, 0.4)) |>   contingency_table(dv, iv, .rownames = TRUE)) #>    1  0 #> a 37 13 #> b 20 30  t |> chsqfish() #> $observed #>    1  0 #> a 37 13 #> b 20 30 #>  #> $expected #>      1    0 #> a 28.5 21.5 #> b 28.5 21.5 #>  #> $test #>  #> \tPearson's Chi-squared test with Yates' continuity correction #>  #> data:  t #> X-squared = 10.445, df = 1, p-value = 0.00123 #>  #>  #> attr(,\"class\") #> [1] \"chsqfish\"  (t <- bernoulli_data(3, 10, c(0.8, 0.5, 0.2)) |>   contingency_table(dv, iv, .rownames = TRUE)) #>   1 0 #> a 9 1 #> b 2 8 #> c 3 7  t |> chsqfish() #> Warning: Chi-squared approximation may be incorrect #> $observed #>   1 0 #> a 9 1 #> b 2 8 #> c 3 7 #>  #> $expected #>          1        0 #> a 4.666667 5.333333 #> b 4.666667 5.333333 #> c 4.666667 5.333333 #>  #> $test #>  #> \tFisher's Exact Test for Count Data with simulated p-value (based on #> \t2000 replicates) #>  #> data:  chsq$observed #> p-value = 0.002499 #> alternative hypothesis: two.sided #>  #>  #> attr(,\"class\") #> [1] \"chsqfish\"  rm(t)"},{"path":"https://mark-eis.github.io/ParaAnita/reference/comp_glm.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare Series of Nested GLMs — comp_glm","title":"Compare Series of Nested GLMs — comp_glm","text":"Compare series nested Bernoulli binomial GLMs supplying data, dependent variable list terms representing right-hand side series model formulae.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/comp_glm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare Series of Nested GLMs — comp_glm","text":"","code":"comp_glm(.data, .dep_var, ..., .family = binomial, .arrange_by = desc(AIC))"},{"path":"https://mark-eis.github.io/ParaAnita/reference/comp_glm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare Series of Nested GLMs — comp_glm","text":".data data frame, data frame extension (e.g. tibble). .dep_var <data-masking> quoted name binary dependent variable used LHS model formula; numeric values 0 1, two-column matrix columns giving numbers successes failures e.g., cbind(pn, qn). ... <dynamic-dots> RHS number model formulae compared, based independent variables .data. .family description error distribution link function used model. Can character string naming family function, family function result call family function; default binomial. .arrange_by <data-masking> quoted name column ordering results. Use desc sort variable descending order; default desc(AIC).","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/comp_glm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare Series of Nested GLMs — comp_glm","text":"object classes \"comp_glm\", \"announce\", inheriting tibble hence \"data.frame\", columns including RHS model formula, glm object eight goodness--fit measures output glance.glm(), follows: - f_rhs right-hand side formula supplied ... argument. .glm list-column containing glm model objects. AIC Akaike's Information Criterion. BIC Bayesian Information Criterion. deviance Deviance model. df.null Degrees freedom null model. df.residual Residual degrees freedom. logLik log-likelihood model. nobs Number observations. null.deviance Deviance null model.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/comp_glm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compare Series of Nested GLMs — comp_glm","text":"comp_glm() builds formulas dependent variable formula right-hand side, calls glm, saves resulting objects class \"glm\" list column tibble, together model fit information obtained using glance.glm broom package. output may ordered selected column, otherwise default descending order Akaike's Information Criterion (AIC). comp_glm() may used conveniently compare series related binomial GLMs based different groupings factors added .data using add_grps.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/comp_glm.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Compare Series of Nested GLMs — comp_glm","text":"user's responsibility check models suitably nested ensure meaningful comparisons.","code":""},{"path":[]},{"path":"https://mark-eis.github.io/ParaAnita/reference/comp_glm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare Series of Nested GLMs — comp_glm","text":"","code":"## Simulate Bernoulli data  (d <- list(         iv2 = list(g = c(\"a\", \"c\", \"e\"), h = c(\"b\", \"d\", \"f\")),         iv3 = list(i = c(\"a\", \"b\", \"c\"), j = c(\"d\", \"e\", \"f\")),         iv4 = list(k = c(\"a\", \"b\"), l = c(\"c\", \"d\"), m = c(\"e\", \"f\"))     ) |> add_grps(bernoulli_data(levels = 6), iv, .key = _)) #> ___________________________ #> Simulated Bernoulli Data: - #>  #> # A tibble: 396 × 5 #>    iv    iv2   iv3   iv4      dv #>    <fct> <fct> <fct> <fct> <int> #>  1 a     g     i     k         0 #>  2 a     g     i     k         0 #>  3 a     g     i     k         1 #>  4 a     g     i     k         0 #>  5 a     g     i     k         1 #>  6 a     g     i     k         1 #>  7 a     g     i     k         0 #>  8 a     g     i     k         0 #>  9 a     g     i     k         1 #> 10 a     g     i     k         1 #> # ℹ 386 more rows  ## Models arranged in descending order of AIC by default. d |> comp_glm(dv, iv, iv2, iv3, iv4) #> ______________________ #> Compare Nested GLMs: - #>  #> # A tibble: 4 × 10 #>   f_rhs .glm       null.deviance df.null logLik   AIC   BIC deviance df.residual #> * <chr> <named li>         <dbl>   <int>  <dbl> <dbl> <dbl>    <dbl>       <int> #> 1 iv2   <glm>               479.     395  -236.  476.  484.     472.         394 #> 2 iv3   <glm>               479.     395  -229.  461.  469.     457.         394 #> 3 iv4   <glm>               479.     395  -227.  461.  473.     455.         393 #> 4 iv    <glm>               479.     395  -223.  459.  483.     447.         390 #> # ℹ 1 more variable: nobs <int>  ## Arrange models by formula right-hand side  (comps <- d |> comp_glm(dv, iv, iv2, iv3, iv4, .arrange_by = f_rhs)) #> ______________________ #> Compare Nested GLMs: - #>  #> # A tibble: 4 × 10 #>   f_rhs .glm       null.deviance df.null logLik   AIC   BIC deviance df.residual #> * <chr> <named li>         <dbl>   <int>  <dbl> <dbl> <dbl>    <dbl>       <int> #> 1 iv    <glm>               479.     395  -223.  459.  483.     447.         390 #> 2 iv2   <glm>               479.     395  -236.  476.  484.     472.         394 #> 3 iv3   <glm>               479.     395  -229.  461.  469.     457.         394 #> 4 iv4   <glm>               479.     395  -227.  461.  473.     455.         393 #> # ℹ 1 more variable: nobs <int>  ## Inspect components of .glm list-column lapply(comps$.glm, formula) #> $iv #> dv ~ iv #> <environment: 0x56553a51e340> #>  #> $iv2 #> dv ~ iv2 #> <environment: 0x56553a729bd8> #>  #> $iv3 #> dv ~ iv3 #> <environment: 0x56553a7ef728> #>  #> $iv4 #> dv ~ iv4 #> <environment: 0x5655390ae348> #>   lapply(comps$.glm, summary) #> $iv #>  #> Call: #> glm(formula = inject(!!.dep_var ~ !!x), family = .family, data = .data) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)  0.06062    0.24630   0.246 0.805570     #> ivb         -0.68633    0.35693  -1.923 0.054493 .   #> ivc         -0.75377    0.35895  -2.100 0.035733 *   #> ivd         -1.20006    0.37837  -3.172 0.001516 **  #> ive         -1.37281    0.38900  -3.529 0.000417 *** #> ivf         -2.19225    0.46953  -4.669 3.03e-06 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 478.96  on 395  degrees of freedom #> Residual deviance: 446.76  on 390  degrees of freedom #> AIC: 458.76 #>  #> Number of Fisher Scoring iterations: 4 #>  #>  #> $iv2 #>  #> Call: #> glm(formula = inject(!!.dep_var ~ !!x), family = .family, data = .data) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)  -0.6035     0.1487  -4.060 4.91e-05 *** #> iv2h         -0.5917     0.2245  -2.635  0.00841 **  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 478.96  on 395  degrees of freedom #> Residual deviance: 471.90  on 394  degrees of freedom #> AIC: 475.9 #>  #> Number of Fisher Scoring iterations: 4 #>  #>  #> $iv3 #>  #> Call: #> glm(formula = inject(!!.dep_var ~ !!x), family = .family, data = .data) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)  -0.4097     0.1451  -2.823  0.00476 **  #> iv3j         -1.0608     0.2330  -4.552  5.3e-06 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 478.96  on 395  degrees of freedom #> Residual deviance: 457.08  on 394  degrees of freedom #> AIC: 461.08 #>  #> Number of Fisher Scoring iterations: 4 #>  #>  #> $iv4 #>  #> Call: #> glm(formula = inject(!!.dep_var ~ !!x), family = .family, data = .data) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)  -0.2744     0.1757  -1.562   0.1183     #> iv4l         -0.6313     0.2604  -2.424   0.0154 *   #> iv4m         -1.3906     0.2958  -4.701 2.59e-06 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 478.96  on 395  degrees of freedom #> Residual deviance: 454.67  on 393  degrees of freedom #> AIC: 460.67 #>  #> Number of Fisher Scoring iterations: 4 #>  #>   ## Convert to binomial data using binom_contingency() (d <- d |> binom_contingency(dv)) #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 6 × 6 #>   iv    iv2   iv3   iv4      pn    qn #> * <fct> <fct> <fct> <fct> <int> <int> #> 1 a     g     i     k        34    32 #> 2 b     h     i     k        23    43 #> 3 c     g     i     l        22    44 #> 4 d     h     j     l        16    50 #> 5 e     g     j     m        14    52 #> 6 f     h     j     m         7    59  (comps <- d |> comp_glm(cbind(pn, qn), iv, iv2, iv3, iv4)) #> ______________________ #> Compare Nested GLMs: - #>  #> # A tibble: 4 × 10 #>   f_rhs .glm       null.deviance df.null logLik   AIC   BIC deviance df.residual #> * <chr> <named li>         <dbl>   <int>  <dbl> <dbl> <dbl>    <dbl>       <int> #> 1 iv2   <glm>               32.2       5  -25.6  55.2  54.8 2.51e+ 1           4 #> 2 iv3   <glm>               32.2       5  -18.2  40.4  39.9 1.03e+ 1           4 #> 3 iv4   <glm>               32.2       5  -17.0  39.9  39.3 7.91e+ 0           3 #> 4 iv    <glm>               32.2       5  -13.0  38.0  36.8 2.26e-14           0 #> # ℹ 1 more variable: nobs <int>  ## Inspect components of .glm list-column lapply(comps$.glm, formula) #> $iv2 #> cbind(pn, qn) ~ iv2 #> <environment: 0x565539535328> #>  #> $iv3 #> cbind(pn, qn) ~ iv3 #> <environment: 0x5655397d6c38> #>  #> $iv4 #> cbind(pn, qn) ~ iv4 #> <environment: 0x565539a6bb48> #>  #> $iv #> cbind(pn, qn) ~ iv #> <environment: 0x56553930a270> #>   lapply(comps$.glm, summary) #> $iv2 #>  #> Call: #> glm(formula = inject(!!.dep_var ~ !!x), family = .family, data = .data) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)  -0.6035     0.1487  -4.060 4.91e-05 *** #> iv2h         -0.5917     0.2245  -2.635  0.00841 **  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 32.209  on 5  degrees of freedom #> Residual deviance: 25.148  on 4  degrees of freedom #> AIC: 55.172 #>  #> Number of Fisher Scoring iterations: 4 #>  #>  #> $iv3 #>  #> Call: #> glm(formula = inject(!!.dep_var ~ !!x), family = .family, data = .data) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)  -0.4097     0.1451  -2.823  0.00476 **  #> iv3j         -1.0608     0.2330  -4.552  5.3e-06 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 32.209  on 5  degrees of freedom #> Residual deviance: 10.327  on 4  degrees of freedom #> AIC: 40.352 #>  #> Number of Fisher Scoring iterations: 4 #>  #>  #> $iv4 #>  #> Call: #> glm(formula = inject(!!.dep_var ~ !!x), family = .family, data = .data) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)  -0.2744     0.1757  -1.562   0.1183     #> iv4l         -0.6313     0.2604  -2.424   0.0154 *   #> iv4m         -1.3906     0.2958  -4.701 2.59e-06 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 32.2088  on 5  degrees of freedom #> Residual deviance:  7.9103  on 3  degrees of freedom #> AIC: 39.935 #>  #> Number of Fisher Scoring iterations: 4 #>  #>  #> $iv #>  #> Call: #> glm(formula = inject(!!.dep_var ~ !!x), family = .family, data = .data) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)  0.06062    0.24630   0.246 0.805570     #> ivb         -0.68633    0.35693  -1.923 0.054493 .   #> ivc         -0.75377    0.35895  -2.100 0.035733 *   #> ivd         -1.20006    0.37837  -3.172 0.001516 **  #> ive         -1.37281    0.38900  -3.529 0.000417 *** #> ivf         -2.19225    0.46954  -4.669 3.03e-06 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 3.2209e+01  on 5  degrees of freedom #> Residual deviance: 2.2649e-14  on 0  degrees of freedom #> AIC: 38.025 #>  #> Number of Fisher Scoring iterations: 3 #>  #>   rm(comps, d)"},{"path":"https://mark-eis.github.io/ParaAnita/reference/contingency_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Contingency Tables for Two or More Categorical Variables — contingency_table","title":"Contingency Tables for Two or More Categorical Variables — contingency_table","text":"contingency_table() compiles contingency table two categorical variables, first typically outcome (dependent) varable used column headings, remainder typically explanatory (independent) variables appear contingency table either factors optionally row headings. xcontingency_table() compiles contingency table categorical outcome varable multiple categorical explanatory variables “crossed” obtain single explanatory factor.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/contingency_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Contingency Tables for Two or More Categorical Variables — contingency_table","text":"","code":"contingency_table(.data, .dep_var, ..., .wt = NULL, .rownames = FALSE)  xcontingency_table(   .data,   .dep_var,   ...,   .crossname = NULL,   .wt = NULL,   .rownames = FALSE )"},{"path":"https://mark-eis.github.io/ParaAnita/reference/contingency_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Contingency Tables for Two or More Categorical Variables — contingency_table","text":".data data frame, data frame extension (e.g. tibble). .dep_var <data-masking> quoted name dependent variable, may character vector, factor, numeric. ... <tidy-select> quoted name(s) one factors character vectors .data, included (excluded ) output. .wt <data-masking> quoted name numeric column .data containing frequency weights; default NULL. .rownames logical. TRUE, value data frame levels first (crossed) independent variable row names, rather tibble; default FALSE. .crossname character string used name column crossed variables. omitted, names crossed variables used combined “snake case”.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/contingency_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Contingency Tables for Two or More Categorical Variables — contingency_table","text":"contingency_table(), object class \"contingency_table\", \"announce\", inheriting tibble, data.frame, depending whether .rownames = FALSE (default) TRUE. Similarly xcontingency_table(), object class \"xcontingency_table\", \"announce\" inheriting tibble data.frame, depending value rownames.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/contingency_table.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Contingency Tables for Two or More Categorical Variables — contingency_table","text":"Categorical variables (.e. factors character vectors) .data required factors resulting contingency table may selected inclusion exclusion using ... argument <tidy-select> syntax package dplyr, including use “selection helpers”. ... arguments supplied, categorical variables .data (.dep_var) used. list defused R expressions, instance created expl_fcts(), may used ... arguments injected using splice-operator, !!!, see examples. .wt = NULL, number rows unique combination dependent independent variables counted. .wt quoted name numeric variable representing frequency weights, summated unique combination dependent independent variables. .rownames = TRUE, resulting contingency table conventional data.frame rather tibble first categorical variable (.dep_var) used row headings rather factor. row headings allows result passed argument chisq.test(), fisher.test() chsqfish(), e.g., conveniently using |> piped sequence (see examples). However, using .rownames = TRUE contingency table one explanatory (independent) variable likely result error message “duplicate 'row.names' allowed”, case xcontingency_table() used instead. Multiple categorical explanatory variables contingency table compiled xcontingency_table() “crossed” using fct_cross().","code":""},{"path":[]},{"path":"https://mark-eis.github.io/ParaAnita/reference/contingency_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Contingency Tables for Two or More Categorical Variables — contingency_table","text":"","code":"(d <- tibble(     iv = letters[1:4] |> sample(10, replace = TRUE),     dv = c(0L:3L) |> sample(10, replace = TRUE) )) #> # A tibble: 10 × 2 #>    iv       dv #>    <chr> <int> #>  1 b         2 #>  2 a         1 #>  3 b         0 #>  4 b         2 #>  5 d         2 #>  6 b         0 #>  7 d         2 #>  8 c         3 #>  9 a         3 #> 10 d         1  d |> contingency_table(dv) #> ____________________ #> Contingency Table: - #>  #> # A tibble: 4 × 5 #>   iv      `2`   `1`   `0`   `3` #> * <chr> <int> <int> <int> <int> #> 1 b         2     0     2     0 #> 2 a         0     1     0     1 #> 3 d         2     1     0     0 #> 4 c         0     0     0     1  d |> contingency_table(dv, .rownames = TRUE) #>   2 1 0 3 #> b 2 0 2 0 #> a 0 1 0 1 #> d 2 1 0 0 #> c 0 0 0 1  ## Use .data pronoun for more informative error messages d |> contingency_table(.data$dv) #> ____________________ #> Contingency Table: - #>  #> # A tibble: 4 × 5 #>   iv      `2`   `1`   `0`   `3` #> * <chr> <int> <int> <int> <int> #> 1 b         2     0     2     0 #> 2 a         0     1     0     1 #> 3 d         2     1     0     0 #> 4 c         0     0     0     1  try(d |> contingency_table(dx)) #> Error : object 'dx' not found  try(d |> contingency_table(.data$dx)) #> Error in .data$dx : Column `dx` not found in `.data`.  (d <- tibble(     iv = letters[1:4] |> sample(10, replace = TRUE) |> as.factor(),     dv = c(\"Success\", \"Fail\", \"Borderline\")  |> sample(10, replace = TRUE)   )) #> # A tibble: 10 × 2 #>    iv    dv         #>    <fct> <chr>      #>  1 d     Borderline #>  2 b     Borderline #>  3 d     Borderline #>  4 d     Fail       #>  5 d     Fail       #>  6 d     Borderline #>  7 b     Fail       #>  8 a     Success    #>  9 c     Success    #> 10 c     Borderline  d |> contingency_table(dv) #> ____________________ #> Contingency Table: - #>  #> # A tibble: 4 × 4 #>   iv    Borderline  Fail Success #> * <fct>      <int> <int>   <int> #> 1 d              3     2       0 #> 2 b              1     1       0 #> 3 a              0     0       1 #> 4 c              1     0       1  d |> contingency_table(dv, .rownames = TRUE) #>   Borderline Fail Success #> d          3    2       0 #> b          1    1       0 #> a          0    0       1 #> c          1    0       1  (d <- tibble(     iv = letters[1:4] |> sample(100, replace = TRUE),     dv = c(\"Success\", \"Fail\", \"Borderline\")  |> sample(100, replace = TRUE)   ) |> count(iv, dv)) #> # A tibble: 12 × 3 #>    iv    dv             n #>    <chr> <chr>      <int> #>  1 a     Borderline    14 #>  2 a     Fail           8 #>  3 a     Success       13 #>  4 b     Borderline     7 #>  5 b     Fail           9 #>  6 b     Success        7 #>  7 c     Borderline     7 #>  8 c     Fail           1 #>  9 c     Success        8 #> 10 d     Borderline     9 #> 11 d     Fail           5 #> 12 d     Success       12  d |> contingency_table(dv, .wt = n) #> ____________________ #> Contingency Table: - #>  #> # A tibble: 4 × 4 #>   iv    Borderline  Fail Success #> * <chr>      <int> <int>   <int> #> 1 a             14     8      13 #> 2 b              7     9       7 #> 3 c              7     1       8 #> 4 d              9     5      12  d |> contingency_table(dv, .wt = n, .rownames = TRUE) |>     print_lf() |>     chisq.test() #>   Borderline Fail Success #> a         14    8      13 #> b          7    9       7 #> c          7    1       8 #> d          9    5      12 #>  #> Warning: Chi-squared approximation may be incorrect #>  #> \tPearson's Chi-squared test #>  #> data:  print_lf(contingency_table(d, dv, .wt = n, .rownames = TRUE)) #> X-squared = 6.5483, df = 6, p-value = 0.3646 #>   ## Use .data pronoun for more informative error messages d |> contingency_table(dv, .wt = .data$n) #> ____________________ #> Contingency Table: - #>  #> # A tibble: 4 × 4 #>   iv    Borderline  Fail Success #> * <chr>      <int> <int>   <int> #> 1 a             14     8      13 #> 2 b              7     9       7 #> 3 c              7     1       8 #> 4 d              9     5      12  try(d |> contingency_table(dv, .wt = .data$x)) #> Error in .data$x : Column `x` not found in `.data`.  rm(d)  ## Using gss_cat dataset from {forcats} package # \\dontshow{   if (!requireNamespace(\"forcats\", quietly = TRUE))      warning(\"package 'forcats' must be installed\")   try(gss_cat <- forcats::gss_cat) # }  gss_cat |> contingency_table(race, relig, denom) #> ____________________ #> Contingency Table: - #>  #> # A tibble: 47 × 5 #>    relig              denom             White Black Other #>  * <fct>              <fct>             <int> <int> <int> #>  1 Protestant         Southern baptist   1151   355    30 #>  2 Protestant         Baptist-dk which    723   697    37 #>  3 Protestant         No denomination    1020   149    55 #>  4 Orthodox-christian Not applicable       92     2     1 #>  5 None               Not applicable     2816   384   323 #>  6 Christian          Not applicable      147    49    28 #>  7 Protestant         Lutheran-mo synod   208     2     2 #>  8 Protestant         Other              1886   468   180 #>  9 Protestant         United methodist   1007    49    11 #> 10 Jewish             Not applicable      370    10     8 #> # ℹ 37 more rows  gss_cat |> contingency_table(race, !c(marital, rincome:partyid)) #> ____________________ #> Contingency Table: - #>  #> # A tibble: 47 × 5 #>    relig              denom             White Black Other #>  * <fct>              <fct>             <int> <int> <int> #>  1 Protestant         Southern baptist   1151   355    30 #>  2 Protestant         Baptist-dk which    723   697    37 #>  3 Protestant         No denomination    1020   149    55 #>  4 Orthodox-christian Not applicable       92     2     1 #>  5 None               Not applicable     2816   384   323 #>  6 Christian          Not applicable      147    49    28 #>  7 Protestant         Lutheran-mo synod   208     2     2 #>  8 Protestant         Other              1886   468   180 #>  9 Protestant         United methodist   1007    49    11 #> 10 Jewish             Not applicable      370    10     8 #> # ℹ 37 more rows  ## Invokes warning and error message about duplicate 'row.names' try(gss_cat |> contingency_table(race, relig, denom, .rownames = TRUE))  #> Warning: non-unique values when setting 'row.names': ‘Christian’, ‘Other’, ‘Protestant’ #> Error in `.rowNamesDF<-`(x, value = value) :  #>   duplicate 'row.names' are not allowed  ## Using xcontingency_table() avoids warning and error gss_cat |> xcontingency_table(race, relig, denom) #> ____________________________ #> Crossed Contingency Table: - #>  #> # A tibble: 47 × 4 #>    relig_denom                       White Black Other #>  * <fct>                             <int> <int> <int> #>  1 Protestant:Southern baptist        1151   355    30 #>  2 Protestant:Baptist-dk which         723   697    37 #>  3 Protestant:No denomination         1020   149    55 #>  4 Orthodox-christian:Not applicable    92     2     1 #>  5 None:Not applicable                2816   384   323 #>  6 Christian:Not applicable            147    49    28 #>  7 Protestant:Lutheran-mo synod        208     2     2 #>  8 Protestant:Other                   1886   468   180 #>  9 Protestant:United methodist        1007    49    11 #> 10 Jewish:Not applicable               370    10     8 #> # ℹ 37 more rows  gss_cat |> xcontingency_table(race, !c(marital, rincome:partyid)) #> ____________________________ #> Crossed Contingency Table: - #>  #> # A tibble: 47 × 4 #>    relig_denom                       White Black Other #>  * <fct>                             <int> <int> <int> #>  1 Protestant:Southern baptist        1151   355    30 #>  2 Protestant:Baptist-dk which         723   697    37 #>  3 Protestant:No denomination         1020   149    55 #>  4 Orthodox-christian:Not applicable    92     2     1 #>  5 None:Not applicable                2816   384   323 #>  6 Christian:Not applicable            147    49    28 #>  7 Protestant:Lutheran-mo synod        208     2     2 #>  8 Protestant:Other                   1886   468   180 #>  9 Protestant:United methodist        1007    49    11 #> 10 Jewish:Not applicable               370    10     8 #> # ℹ 37 more rows  gss_cat |> xcontingency_table(race, relig, denom, .crossname = \"Denomination\") #> ____________________________ #> Crossed Contingency Table: - #>  #> # A tibble: 47 × 4 #>    Denomination                      White Black Other #>  * <fct>                             <int> <int> <int> #>  1 Protestant:Southern baptist        1151   355    30 #>  2 Protestant:Baptist-dk which         723   697    37 #>  3 Protestant:No denomination         1020   149    55 #>  4 Orthodox-christian:Not applicable    92     2     1 #>  5 None:Not applicable                2816   384   323 #>  6 Christian:Not applicable            147    49    28 #>  7 Protestant:Lutheran-mo synod        208     2     2 #>  8 Protestant:Other                   1886   468   180 #>  9 Protestant:United methodist        1007    49    11 #> 10 Jewish:Not applicable               370    10     8 #> # ℹ 37 more rows  gss_cat |>     xcontingency_table(race, relig, denom, .rownames = TRUE) |>     head(10) #>                                   White Black Other #> Protestant:Southern baptist        1151   355    30 #> Protestant:Baptist-dk which         723   697    37 #> Protestant:No denomination         1020   149    55 #> Orthodox-christian:Not applicable    92     2     1 #> None:Not applicable                2816   384   323 #> Christian:Not applicable            147    49    28 #> Protestant:Lutheran-mo synod        208     2     2 #> Protestant:Other                   1886   468   180 #> Protestant:United methodist        1007    49    11 #> Jewish:Not applicable               370    10     8  ## Two more esoteric examples ivars <- exprs(relig, denom) gss_cat |> contingency_table(race, !!!ivars) #> ____________________ #> Contingency Table: - #>  #> # A tibble: 47 × 5 #>    relig              denom             White Black Other #>  * <fct>              <fct>             <int> <int> <int> #>  1 Protestant         Southern baptist   1151   355    30 #>  2 Protestant         Baptist-dk which    723   697    37 #>  3 Protestant         No denomination    1020   149    55 #>  4 Orthodox-christian Not applicable       92     2     1 #>  5 None               Not applicable     2816   384   323 #>  6 Christian          Not applicable      147    49    28 #>  7 Protestant         Lutheran-mo synod   208     2     2 #>  8 Protestant         Other              1886   468   180 #>  9 Protestant         United methodist   1007    49    11 #> 10 Jewish             Not applicable      370    10     8 #> # ℹ 37 more rows  ivars <- c(\"relig\", \"denom\") gss_cat |> contingency_table(race, any_of(ivars)) #> ____________________ #> Contingency Table: - #>  #> # A tibble: 47 × 5 #>    relig              denom             White Black Other #>  * <fct>              <fct>             <int> <int> <int> #>  1 Protestant         Southern baptist   1151   355    30 #>  2 Protestant         Baptist-dk which    723   697    37 #>  3 Protestant         No denomination    1020   149    55 #>  4 Orthodox-christian Not applicable       92     2     1 #>  5 None               Not applicable     2816   384   323 #>  6 Christian          Not applicable      147    49    28 #>  7 Protestant         Lutheran-mo synod   208     2     2 #>  8 Protestant         Other              1886   468   180 #>  9 Protestant         United methodist   1007    49    11 #> 10 Jewish             Not applicable      370    10     8 #> # ℹ 37 more rows  rm(ivars)  # \\dontshow{   rm(gss_cat) # }"},{"path":"https://mark-eis.github.io/ParaAnita/reference/contr_colnames.html","id":null,"dir":"Reference","previous_headings":"","what":"Get and Set Contrast Matrix Column Names — contr_colnames","title":"Get and Set Contrast Matrix Column Names — contr_colnames","text":"Set view column names contrasts associated factor.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/contr_colnames.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get and Set Contrast Matrix Column Names — contr_colnames","text":"","code":"contr_colnames(x)  contr_colnames(x) <- value  contr_colpfx(x) <- value"},{"path":"https://mark-eis.github.io/ParaAnita/reference/contr_colnames.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get and Set Contrast Matrix Column Names — contr_colnames","text":"x factor contrast column headings set viewed. value character vector containing contrast column names, length equal number contrasts; case contr_colpfx()<- character string used prefix existing contrast column names.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/contr_colnames.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get and Set Contrast Matrix Column Names — contr_colnames","text":"contr_colnames() returns current column names contrasts factor. contr_colnames()<- sets column names contrasts factor. cntr_pfx()<- prefixes current column names contrasts factor character string provided. can useful factor levels elided factor name , instance, printed output summary.glm. contrasts set x, contr_colnames()<- cntr_pfx()<- set contrast attribute using default function options(\"contrasts\") modifying column names.","code":""},{"path":[]},{"path":"https://mark-eis.github.io/ParaAnita/reference/contr_colnames.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get and Set Contrast Matrix Column Names — contr_colnames","text":"","code":"(d <- data.frame(   f = gl(5, 5, labels = LETTERS[1:5]),   dv = sample(c(0,1), 25, replace = TRUE) )) #>    f dv #> 1  A  1 #> 2  A  0 #> 3  A  1 #> 4  A  1 #> 5  A  1 #> 6  B  1 #> 7  B  0 #> 8  B  0 #> 9  B  0 #> 10 B  1 #> 11 C  0 #> 12 C  0 #> 13 C  1 #> 14 C  0 #> 15 C  1 #> 16 D  1 #> 17 D  1 #> 18 D  1 #> 19 D  1 #> 20 D  0 #> 21 E  1 #> 22 E  0 #> 23 E  1 #> 24 E  1 #> 25 E  0  contrasts(d$f) <- contr.helmert contrasts(d$f) #>   [,1] [,2] [,3] [,4] #> A   -1   -1   -1   -1 #> B    1   -1   -1   -1 #> C    0    2   -1   -1 #> D    0    0    3   -1 #> E    0    0    0    4 contr_colnames(d$f) #> NULL glm(dv ~ f, family = binomial, data = d) |> summary() #>  #> Call: #> glm(formula = dv ~ f, family = binomial, data = d) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|) #> (Intercept)  0.47342    0.44721   1.059    0.290 #> f1          -0.89588    0.72169  -1.241    0.214 #> f2          -0.29863    0.38790  -0.770    0.441 #> f3           0.29863    0.31366   0.952    0.341 #> f4          -0.01699    0.20916  -0.081    0.935 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 33.651  on 24  degrees of freedom #> Residual deviance: 30.198  on 20  degrees of freedom #> AIC: 40.198 #>  #> Number of Fisher Scoring iterations: 4 #>   contr_colnames(d$f) <- c(\"A v. B\", \"AB v. C\", \"ABC v. D\", \"ABCD v. E\") contr_colnames(d$f) #> [1] \"A v. B\"    \"AB v. C\"   \"ABC v. D\"  \"ABCD v. E\" contrasts(d$f) #>   A v. B AB v. C ABC v. D ABCD v. E #> A     -1      -1       -1        -1 #> B      1      -1       -1        -1 #> C      0       2       -1        -1 #> D      0       0        3        -1 #> E      0       0        0         4 glm(dv ~ f, family = binomial, data = d) |> summary() #>  #> Call: #> glm(formula = dv ~ f, family = binomial, data = d) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|) #> (Intercept)  0.47342    0.44721   1.059    0.290 #> fA v. B     -0.89588    0.72169  -1.241    0.214 #> fAB v. C    -0.29863    0.38790  -0.770    0.441 #> fABC v. D    0.29863    0.31366   0.952    0.341 #> fABCD v. E  -0.01699    0.20916  -0.081    0.935 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 33.651  on 24  degrees of freedom #> Residual deviance: 30.198  on 20  degrees of freedom #> AIC: 40.198 #>  #> Number of Fisher Scoring iterations: 4 #>   contr_colpfx(d$f) <- \": \" contr_colnames(d$f) #> [1] \": A v. B\"    \": AB v. C\"   \": ABC v. D\"  \": ABCD v. E\" glm(dv ~ f, family = binomial, data = d) |> summary() #>  #> Call: #> glm(formula = dv ~ f, family = binomial, data = d) #>  #> Coefficients: #>              Estimate Std. Error z value Pr(>|z|) #> (Intercept)   0.47342    0.44721   1.059    0.290 #> f: A v. B    -0.89588    0.72169  -1.241    0.214 #> f: AB v. C   -0.29863    0.38790  -0.770    0.441 #> f: ABC v. D   0.29863    0.31366   0.952    0.341 #> f: ABCD v. E -0.01699    0.20916  -0.081    0.935 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 33.651  on 24  degrees of freedom #> Residual deviance: 30.198  on 20  degrees of freedom #> AIC: 40.198 #>  #> Number of Fisher Scoring iterations: 4 #>   rm(d)"},{"path":"https://mark-eis.github.io/ParaAnita/reference/expl_fcts.html","id":null,"dir":"Reference","previous_headings":"","what":"Explanatory Factors in Data as List of Expressions — expl_fcts","title":"Explanatory Factors in Data as List of Expressions — expl_fcts","text":"Create list defused expressions representing names selection explanatory factors character vectors dataset.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/expl_fcts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Explanatory Factors in Data as List of Expressions — expl_fcts","text":"","code":"expl_fcts(   .data,   ...,   .named = FALSE,   .val = c(\"syms\", \"data_syms\", \"character\") )"},{"path":"https://mark-eis.github.io/ParaAnita/reference/expl_fcts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Explanatory Factors in Data as List of Expressions — expl_fcts","text":".data data frame, data frame extension (e.g. tibble). ... <tidy-select> quoted name(s) one factors character vectors .data, included (excluded ) output. .named logical, whether name elements list. TRUE, unnamed inputs automatically named set_names(); default FALSE. .val type output required. default \"syms\" returns list symbols; alternative \"data_syms\" returns list symbols prefixed .data pronoun. \"character\" option returns character vector.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/expl_fcts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Explanatory Factors in Data as List of Expressions — expl_fcts","text":"list symbols representing names selected explanatory factors character vectors .data; unless .val = \"data_syms\", case symbols prefixed .data pronoun .val = \"character\" whereupon selected names returned character vector instead.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/expl_fcts.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Explanatory Factors in Data as List of Expressions — expl_fcts","text":"default, expl_fcts() creates list symbols .e., defused R expressions, representing names selection explanatory factors (character vectors) .data, using syms() package rlang. Alternatively, .val = \"data_syms\", list symbols prefixed .data pronoun returned instead. Finally, .val = \"character\", expl_fcts() returns character vector names explanatory factors (character vectors) .data Variables .data may selected inclusion exclusion using ... argument <tidy-select> syntax package dplyr, including use “selection helpers”. ... arguments supplied, categorical variables .data included list. list symbols returned expl_fcts() may “injected” ... arguments contingency_table(), xcontingency_table(), binom_contingency() similar functions, using splice-operator !!!. .val = \"character\", functions all_of() any_of() used wrap resulting character vector names instead using !!!. list symbols returned expl_fcts() may also used provide list argument injection support lapply() (purrr package map() functions), using injection-operator !! (see examples).","code":""},{"path":[]},{"path":"https://mark-eis.github.io/ParaAnita/reference/expl_fcts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Explanatory Factors in Data as List of Expressions — expl_fcts","text":"","code":"(d <- list(     iv2 = list(g = c(\"a\", \"c\", \"e\"), h = c(\"b\", \"d\", \"f\")),     iv3 = list(i = c(\"a\", \"b\", \"c\"), j = c(\"d\", \"e\", \"f\")),     iv4 = list(k = c(\"a\", \"b\"), l = c(\"c\", \"d\"), m = c(\"e\", \"f\")) ) |> add_grps(bernoulli_data(levels = 6), iv, .key = _)) #> ___________________________ #> Simulated Bernoulli Data: - #>  #> # A tibble: 396 × 5 #>    iv    iv2   iv3   iv4      dv #>    <fct> <fct> <fct> <fct> <int> #>  1 a     g     i     k         0 #>  2 a     g     i     k         0 #>  3 a     g     i     k         0 #>  4 a     g     i     k         0 #>  5 a     g     i     k         1 #>  6 a     g     i     k         0 #>  7 a     g     i     k         0 #>  8 a     g     i     k         0 #>  9 a     g     i     k         1 #> 10 a     g     i     k         0 #> # ℹ 386 more rows  d |> expl_fcts() #> [[1]] #> iv #>  #> [[2]] #> iv2 #>  #> [[3]] #> iv3 #>  #> [[4]] #> iv4 #>   d |> expl_fcts(.named = TRUE) #> $iv #> iv #>  #> $iv2 #> iv2 #>  #> $iv3 #> iv3 #>  #> $iv4 #> iv4 #>   d |> expl_fcts(.val = \"data_syms\") #> [[1]] #> .data$iv #>  #> [[2]] #> .data$iv2 #>  #> [[3]] #> .data$iv3 #>  #> [[4]] #> .data$iv4 #>   d |> expl_fcts(.named = TRUE, .val = \"data_syms\") #> $iv #> .data$iv #>  #> $iv2 #> .data$iv2 #>  #> $iv3 #> .data$iv3 #>  #> $iv4 #> .data$iv4 #>   d |> expl_fcts(.val = \"character\") #> [1] \"iv\"  \"iv2\" \"iv3\" \"iv4\"  d |> expl_fcts(.named = TRUE, .val = \"character\") #>    iv   iv2   iv3   iv4  #>  \"iv\" \"iv2\" \"iv3\" \"iv4\"   ## Select or exclude factors d |> expl_fcts(iv, iv3) #> [[1]] #> iv #>  #> [[2]] #> iv3 #>   d |> expl_fcts(!c(iv, iv3)) #> [[1]] #> iv2 #>  #> [[2]] #> iv4 #>   ## Use {dplyr} selection helpers e.g., last_col(), num_range() and starts_with() d |> expl_fcts(last_col(1L))  ## Offset of 1L used, since last column of d is dv #> [[1]] #> iv4 #>   d |> expl_fcts(!last_col()) #> [[1]] #> iv #>  #> [[2]] #> iv2 #>  #> [[3]] #> iv3 #>  #> [[4]] #> iv4 #>   d |> expl_fcts(num_range(\"iv\", 2:3)) #> [[1]] #> iv2 #>  #> [[2]] #> iv3 #>   d |> expl_fcts(!num_range(\"iv\", 2:3)) #> [[1]] #> iv #>  #> [[2]] #> iv4 #>   d |> expl_fcts(starts_with(\"iv\")) #> [[1]] #> iv #>  #> [[2]] #> iv2 #>  #> [[3]] #> iv3 #>  #> [[4]] #> iv4 #>   ## Negation of selection helper excludes all explanatory factors d |> expl_fcts(!starts_with(\"iv\")) #> list()  ## In following three examples, each triplet should give identical results ## Include all explanatory factors d |> binom_contingency(dv) #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 6 × 6 #>   iv    iv2   iv3   iv4      pn    qn #> * <fct> <fct> <fct> <fct> <int> <int> #> 1 a     g     i     k        28    38 #> 2 b     h     i     k        27    39 #> 3 c     g     i     l        19    47 #> 4 d     h     j     l        23    43 #> 5 e     g     j     m         7    59 #> 6 f     h     j     m         3    63  d |> binom_contingency(dv, !!!expl_fcts(d)) #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 6 × 6 #>   iv    iv2   iv3   iv4      pn    qn #> * <fct> <fct> <fct> <fct> <int> <int> #> 1 a     g     i     k        28    38 #> 2 b     h     i     k        27    39 #> 3 c     g     i     l        19    47 #> 4 d     h     j     l        23    43 #> 5 e     g     j     m         7    59 #> 6 f     h     j     m         3    63  d |> binom_contingency(dv, all_of(expl_fcts(d, .val = \"character\"))) #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 6 × 6 #>   iv    iv2   iv3   iv4      pn    qn #> * <fct> <fct> <fct> <fct> <int> <int> #> 1 a     g     i     k        28    38 #> 2 b     h     i     k        27    39 #> 3 c     g     i     l        19    47 #> 4 d     h     j     l        23    43 #> 5 e     g     j     m         7    59 #> 6 f     h     j     m         3    63  ## Include only iv and iv3 d |> binom_contingency(dv, iv, iv3) #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 6 × 4 #>   iv    iv3      pn    qn #> * <fct> <fct> <int> <int> #> 1 a     i        28    38 #> 2 b     i        27    39 #> 3 c     i        19    47 #> 4 d     j        23    43 #> 5 e     j         7    59 #> 6 f     j         3    63  d |> binom_contingency(dv, !!!expl_fcts(d, iv, iv3)) #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 6 × 4 #>   iv    iv3      pn    qn #> * <fct> <fct> <int> <int> #> 1 a     i        28    38 #> 2 b     i        27    39 #> 3 c     i        19    47 #> 4 d     j        23    43 #> 5 e     j         7    59 #> 6 f     j         3    63  d |> binom_contingency(dv, all_of(expl_fcts(d, iv, iv3, .val = \"character\"))) #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 6 × 4 #>   iv    iv3      pn    qn #> * <fct> <fct> <int> <int> #> 1 a     i        28    38 #> 2 b     i        27    39 #> 3 c     i        19    47 #> 4 d     j        23    43 #> 5 e     j         7    59 #> 6 f     j         3    63  ## Exclude iv and iv3 d |> binom_contingency(dv, !c(iv, iv3)) #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 6 × 4 #>   iv2   iv4      pn    qn #> * <fct> <fct> <int> <int> #> 1 g     k        28    38 #> 2 h     k        27    39 #> 3 g     l        19    47 #> 4 h     l        23    43 #> 5 g     m         7    59 #> 6 h     m         3    63  d |> binom_contingency(dv, !!!expl_fcts(d, !c(iv, iv3))) #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 6 × 4 #>   iv2   iv4      pn    qn #> * <fct> <fct> <int> <int> #> 1 g     k        28    38 #> 2 h     k        27    39 #> 3 g     l        19    47 #> 4 h     l        23    43 #> 5 g     m         7    59 #> 6 h     m         3    63  d |> binom_contingency(dv, all_of(expl_fcts(d, !c(iv, iv3), .val = \"character\"))) #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 6 × 4 #>   iv2   iv4      pn    qn #> * <fct> <fct> <int> <int> #> 1 g     k        28    38 #> 2 h     k        27    39 #> 3 g     l        19    47 #> 4 h     l        23    43 #> 5 g     m         7    59 #> 6 h     m         3    63  ## Use with lapply, binom_contingency(), glm() and odds_ratio() expl_fcts(d, .named = TRUE) |>     lapply(\\(x) binom_contingency(d, dv, !!x)) #> $iv #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 6 × 3 #>   iv       pn    qn #> * <fct> <int> <int> #> 1 a        28    38 #> 2 b        27    39 #> 3 c        19    47 #> 4 d        23    43 #> 5 e         7    59 #> 6 f         3    63 #>  #> $iv2 #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 2 × 3 #>   iv2      pn    qn #> * <fct> <int> <int> #> 1 g        54   144 #> 2 h        53   145 #>  #> $iv3 #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 2 × 3 #>   iv3      pn    qn #> * <fct> <int> <int> #> 1 i        74   124 #> 2 j        33   165 #>  #> $iv4 #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 3 × 3 #>   iv4      pn    qn #> * <fct> <int> <int> #> 1 k        55    77 #> 2 l        42    90 #> 3 m        10   122 #>   expl_fcts(d, .named = TRUE) |>     lapply(\\(x)         binom_contingency(d, dv, !!x) |>         glm(cbind(pn, qn) ~ ., binomial, data = _)     ) #> $iv #>  #> Call:  glm(formula = cbind(pn, qn) ~ ., family = binomial, data = binom_contingency(d,  #>     dv, !!x)) #>  #> Coefficients: #> (Intercept)          ivb          ivc          ivd          ive          ivf   #>    -0.30538     -0.06234     -0.60033     -0.32032     -1.82625     -2.73914   #>  #> Degrees of Freedom: 5 Total (i.e. Null);  0 Residual #> Null Deviance:\t    49.2  #> Residual Deviance: 1.754e-14 \tAIC: 36.89 #>  #> $iv2 #>  #> Call:  glm(formula = cbind(pn, qn) ~ ., family = binomial, data = binom_contingency(d,  #>     dv, !!x)) #>  #> Coefficients: #> (Intercept)         iv2h   #>    -0.98083     -0.02561   #>  #> Degrees of Freedom: 1 Total (i.e. Null);  0 Residual #> Null Deviance:\t    0.01281  #> Residual Deviance: 4.441e-16 \tAIC: 15.01 #>  #> $iv3 #>  #> Call:  glm(formula = cbind(pn, qn) ~ ., family = binomial, data = binom_contingency(d,  #>     dv, !!x)) #>  #> Coefficients: #> (Intercept)         iv3j   #>     -0.5162      -1.0932   #>  #> Degrees of Freedom: 1 Total (i.e. Null);  0 Residual #> Null Deviance:\t    21.96  #> Residual Deviance: 6.595e-14 \tAIC: 14.83 #>  #> $iv4 #>  #> Call:  glm(formula = cbind(pn, qn) ~ ., family = binomial, data = binom_contingency(d,  #>     dv, !!x)) #>  #> Coefficients: #> (Intercept)         iv4l         iv4m   #>     -0.3365      -0.4257      -2.1650   #>  #> Degrees of Freedom: 2 Total (i.e. Null);  0 Residual #> Null Deviance:\t    46.84  #> Residual Deviance: -6.706e-14 \tAIC: 20.59 #>   expl_fcts(d, .named = TRUE) |>     lapply(\\(x)         binom_contingency(d, dv, !!x, .drop_zero = TRUE) |>         odds_ratio(.ind_var = !!x)     ) #> Waiting for profiling to be done... #> Waiting for profiling to be done... #> Waiting for profiling to be done... #> Waiting for profiling to be done... #> $iv #> ____________________________ #> Estimates and Odds Ratios: - #>  #> # A tibble: 6 × 7 #>   parameter   estimate    se     p_val odds_ratio ci[,\"2.5%\"] [,\"97.5%\"] sig   #>   <chr>          <dbl> <dbl>     <dbl>      <dbl>       <dbl>      <dbl> <fct> #> 1 (Intercept)  -0.305  0.249 0.220         1          NA          NA     NS    #> 2 ivb          -0.0623 0.353 0.860         0.940       0.469       1.88  NS    #> 3 ivc          -0.600  0.369 0.103         0.549       0.263       1.12  NS    #> 4 ivd          -0.320  0.359 0.372         0.726       0.357       1.46  NS    #> 5 ive          -1.83   0.471 0.000106      0.161       0.0597      0.387 ***   #> 6 ivf          -2.74   0.641 0.0000194     0.0646      0.0147      0.198 ***   #>  #> $iv2 #> ____________________________ #> Estimates and Odds Ratios: - #>  #> # A tibble: 2 × 7 #>   parameter   estimate    se p_val odds_ratio ci[,\"2.5%\"] [,\"97.5%\"] sig   #>   <chr>          <dbl> <dbl> <dbl>      <dbl>       <dbl>      <dbl> <fct> #> 1 (Intercept)  -0.981  0.160 0          1          NA          NA    ***   #> 2 iv2h         -0.0256 0.226 0.910      0.975       0.625       1.52 NS    #>  #> $iv3 #> ____________________________ #> Estimates and Odds Ratios: - #>  #> # A tibble: 2 × 7 #>   parameter   estimate    se     p_val odds_ratio ci[,\"2.5%\"] [,\"97.5%\"] sig   #>   <chr>          <dbl> <dbl>     <dbl>      <dbl>       <dbl>      <dbl> <fct> #> 1 (Intercept)   -0.516 0.147 0.000441       1          NA         NA     ***   #> 2 iv3j          -1.09  0.241 0.0000056      0.335       0.207      0.533 ***   #>  #> $iv4 #> ____________________________ #> Estimates and Odds Ratios: - #>  #> # A tibble: 3 × 7 #>   parameter   estimate    se  p_val odds_ratio ci[,\"2.5%\"] [,\"97.5%\"] sig   #>   <chr>          <dbl> <dbl>  <dbl>      <dbl>       <dbl>      <dbl> <fct> #> 1 (Intercept)   -0.336 0.177 0.0567      1         NA          NA     .     #> 2 iv4l          -0.426 0.257 0.0978      0.653      0.393       1.08  .     #> 3 iv4m          -2.16  0.373 0           0.115      0.0524      0.229 ***   #>   rm(d)"},{"path":"https://mark-eis.github.io/ParaAnita/reference/fct_to_num.html","id":null,"dir":"Reference","previous_headings":"","what":"Factor as Numeric — fct_to_num","title":"Factor as Numeric — fct_to_num","text":"Transform factor approximately original numeric values.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/fct_to_num.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Factor as Numeric — fct_to_num","text":"","code":"fct_to_num(f)"},{"path":"https://mark-eis.github.io/ParaAnita/reference/fct_to_num.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Factor as Numeric — fct_to_num","text":"f factor converted numeric values","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/fct_to_num.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Factor as Numeric — fct_to_num","text":"Numeric","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/fct_to_num.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Factor as Numeric — fct_to_num","text":"See ‘Warning’ section factor: “particular, .numeric applied factor meaningless, may happen implicit coercion. transform factor f approximately original numeric values, .numeric(levels(f))[f] recommended slightly efficient .numeric(.character(f)).”","code":""},{"path":[]},{"path":"https://mark-eis.github.io/ParaAnita/reference/fct_to_num.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Factor as Numeric — fct_to_num","text":"","code":"f <- factor(2001:2020)  f #>  [1] 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 #> [16] 2016 2017 2018 2019 2020 #> 20 Levels: 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 ... 2020  f |> as.numeric()  # Returns codes for factor levels, not what is required #>  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20  f |> fct_to_num()  # Returns approximate numeric values, as required #>  [1] 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 #> [16] 2016 2017 2018 2019 2020  rm(f)"},{"path":"https://mark-eis.github.io/ParaAnita/reference/get_contr_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Get and Set Treatment Contrasts for Independent Variables in Data — get_contr_data","title":"Get and Set Treatment Contrasts for Independent Variables in Data — get_contr_data","text":"get_contr_data() shows \"contrasts\" attributes selected factors within data frame. set_contr_treat() sets \"contrasts\" attribute selected factors within data frame treatment contrast matrix individually specified baseline levels. set_contr_treat()<- replacement function form.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/get_contr_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get and Set Treatment Contrasts for Independent Variables in Data — get_contr_data","text":"","code":"get_contr_data(data, ...)  set_contr_treat(data, ..., .baseline = NULL, .verbose = TRUE)  set_contr_treat(data, ..., .verbose = FALSE) <- value"},{"path":"https://mark-eis.github.io/ParaAnita/reference/get_contr_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get and Set Treatment Contrasts for Independent Variables in Data — get_contr_data","text":"data data frame, data frame extension (e.g. tibble). ... <tidy-select> selection one factors data getting setting contrasts. .baseline numeric vector length equal number contrasts set specifying level considered baseline. .verbose logical, whether print \"\" contrast matrices factors data. value numeric, see .baseline argument.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/get_contr_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get and Set Treatment Contrasts for Independent Variables in Data — get_contr_data","text":"original dataframe tibble \"contrasts\" attributes set selected factors.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/get_contr_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get and Set Treatment Contrasts for Independent Variables in Data — get_contr_data","text":"get_contr_data() returns \"contrasts\" attributes selected factors. Factors .data may selected getting setting contrasts using ... argument <tidy-select> syntax package dplyr, including use selection helpers.  ... arguments supplied, categorical variables data (.e., character factor columns) selected. \"contrasts\" attribute factors selected ... set using contrast function contr.treatment baseline factor levels specified numerically argument .baseline value argument case replacement function form set_contrasts()<-. .baseline argument supplied, default first factor level used baseline. individual .baseline (.value) argument values capped greater nlevels corresponding factors selected .... Hence, ensure last level reference level, baseline value can specified large integer (e.g., 99L), may convenient using set_contr_treat() programmatically.","code":""},{"path":[]},{"path":"https://mark-eis.github.io/ParaAnita/reference/get_contr_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get and Set Treatment Contrasts for Independent Variables in Data — get_contr_data","text":"","code":"# Coming soon!"},{"path":"https://mark-eis.github.io/ParaAnita/reference/get_contrasts.html","id":null,"dir":"Reference","previous_headings":"","what":"Get and Set Contrasts Matrix for an Independent Variable in Data — get_contrasts","title":"Get and Set Contrasts Matrix for an Independent Variable in Data — get_contrasts","text":"get_contrasts() returns \"contrasts\" attribute selected factor within data frame. set_contrasts() sets \"contrasts\" attribute selected factor within data frame; set_contrasts()<- replacement function form.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/get_contrasts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get and Set Contrasts Matrix for an Independent Variable in Data — get_contrasts","text":"","code":"get_contrasts(data, .f)  set_contrasts(data, .f, how.many = NULL, ..., contr)  set_contrasts(data, .f, how.many = NULL, ...) <- value"},{"path":"https://mark-eis.github.io/ParaAnita/reference/get_contrasts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get and Set Contrasts Matrix for an Independent Variable in Data — get_contrasts","text":"data data frame, data frame extension (e.g. tibble). .f <data-masking> quoted name factor data. .many number contrasts set, default one less     nlevels(object). ... additional arguments function contr. contr contrasts use. Can matrix one row     level factor suitable function like     contr.poly character string giving name function value either numeric matrix (sparse dense matrix     class extending dMatrix     package Matrix)  whose columns give coefficients     contrasts levels x, (quoted name )     function computes matrices.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/get_contrasts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get and Set Contrasts Matrix for an Independent Variable in Data — get_contrasts","text":"dataframe tibble \"contrasts\" attribute set .f.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/get_contrasts.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get and Set Contrasts Matrix for an Independent Variable in Data — get_contrasts","text":"\"contrasts\" attribute .f may set using either numeric matrix (quoted name ) function computes matrices, supplied set_contrasts() using contr argument value argument case replacement function form set_contrasts()<-. suitable contrast matrix may obtained using contrast function contr.helmert, contr.poly, contr.sum, contr.treatment contr.SAS, (quoted) name function may supplied. Additional arguments, base = x, may supplied contrast function using ... argument set_contrasts() set_contrasts()<-. base argument supplied contr = contr.treatment, value capped greater nlevels(.f), hence can specified large integer (e.g., 99L) ensure last level reference level. may convenient using set_contrasts() programmatically. NULL supplied contr value argument, existing \"contrasts\" attribute removed .f.","code":""},{"path":[]},{"path":"https://mark-eis.github.io/ParaAnita/reference/get_contrasts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get and Set Contrasts Matrix for an Independent Variable in Data — get_contrasts","text":"","code":"## Create data frame with a factor iv (d <- binom_data()) #> __________________________ #> Simulated Binomial Data: - #>  #> # A tibble: 5 × 3 #>   iv       pn    qn #> * <fct> <int> <int> #> 1 a        37    29 #> 2 b        24    42 #> 3 c        21    45 #> 4 d        13    53 #> 5 e         5    61  ## set_contrasts() d |> set_contrasts(iv, contr = contr.helmert) |> get_contrasts(iv) #>   [,1] [,2] [,3] [,4] #> a   -1   -1   -1   -1 #> b    1   -1   -1   -1 #> c    0    2   -1   -1 #> d    0    0    3   -1 #> e    0    0    0    4  d |> set_contrasts(iv, contr = contr.poly) |> get_contrasts(iv) #>           .L         .Q         .C         ^4 #> a -0.6324555  0.5345225 -0.3162278  0.1195229 #> b -0.3162278 -0.2672612  0.6324555 -0.4780914 #> c  0.0000000 -0.5345225  0.0000000  0.7171372 #> d  0.3162278 -0.2672612 -0.6324555 -0.4780914 #> e  0.6324555  0.5345225  0.3162278  0.1195229  d |> set_contrasts(iv, contr = contr.sum) |> get_contrasts(iv) #>   [,1] [,2] [,3] [,4] #> a    1    0    0    0 #> b    0    1    0    0 #> c    0    0    1    0 #> d    0    0    0    1 #> e   -1   -1   -1   -1  d |> set_contrasts(iv, contr = contr.treatment) |> get_contrasts(iv) #>   b c d e #> a 0 0 0 0 #> b 1 0 0 0 #> c 0 1 0 0 #> d 0 0 1 0 #> e 0 0 0 1  d |> set_contrasts(iv, contr = contr.SAS) |> get_contrasts(iv) #>   a b c d #> a 1 0 0 0 #> b 0 1 0 0 #> c 0 0 1 0 #> d 0 0 0 1 #> e 0 0 0 0  ## how.many argument d |> set_contrasts(iv, 3, contr = contr.poly) |> get_contrasts(iv) #>           .L         .Q         .C #> a -0.6324555  0.5345225 -0.3162278 #> b -0.3162278 -0.2672612  0.6324555 #> c  0.0000000 -0.5345225  0.0000000 #> d  0.3162278 -0.2672612 -0.6324555 #> e  0.6324555  0.5345225  0.3162278  ## base argument of contr.treatment d |> set_contrasts(iv, base = 1, contr = contr.treatment) |> get_contrasts(iv) #>   b c d e #> a 0 0 0 0 #> b 1 0 0 0 #> c 0 1 0 0 #> d 0 0 1 0 #> e 0 0 0 1  d |> set_contrasts(iv, base = 3, contr = contr.treatment) |> get_contrasts(iv) #>   a b d e #> a 1 0 0 0 #> b 0 1 0 0 #> c 0 0 0 0 #> d 0 0 1 0 #> e 0 0 0 1  ## base argument of contr.treatment limited to nlevels(d$iv)  d |> set_contrasts(iv, base = 99L, contr = contr.treatment) |> get_contrasts(iv) #>   a b c d #> a 1 0 0 0 #> b 0 1 0 0 #> c 0 0 1 0 #> d 0 0 0 1 #> e 0 0 0 0  ## Remove \"contrasts\" attribute using NULL d |> set_contrasts(iv, contr = NULL) |> get_contrasts(iv) #> NULL  ## set_contrasts()<- replacement form set_contrasts(d, iv) <- contr.helmert d |> get_contrasts(iv) #>   [,1] [,2] [,3] [,4] #> a   -1   -1   -1   -1 #> b    1   -1   -1   -1 #> c    0    2   -1   -1 #> d    0    0    3   -1 #> e    0    0    0    4  set_contrasts(d, iv) <- contr.poly d |> get_contrasts(iv) #>           .L         .Q         .C         ^4 #> a -0.6324555  0.5345225 -0.3162278  0.1195229 #> b -0.3162278 -0.2672612  0.6324555 -0.4780914 #> c  0.0000000 -0.5345225  0.0000000  0.7171372 #> d  0.3162278 -0.2672612 -0.6324555 -0.4780914 #> e  0.6324555  0.5345225  0.3162278  0.1195229  set_contrasts(d, iv) <- contr.sum d |> get_contrasts(iv) #>   [,1] [,2] [,3] [,4] #> a    1    0    0    0 #> b    0    1    0    0 #> c    0    0    1    0 #> d    0    0    0    1 #> e   -1   -1   -1   -1  set_contrasts(d, iv) <- contr.treatment d |> get_contrasts(iv) #>   b c d e #> a 0 0 0 0 #> b 1 0 0 0 #> c 0 1 0 0 #> d 0 0 1 0 #> e 0 0 0 1  set_contrasts(d, iv) <- contr.SAS d |> get_contrasts(iv) #>   a b c d #> a 1 0 0 0 #> b 0 1 0 0 #> c 0 0 1 0 #> d 0 0 0 1 #> e 0 0 0 0  ## how.many argument set_contrasts(d, iv, 3) <- contr.poly d |> get_contrasts(iv) #>           .L         .Q         .C #> a -0.6324555  0.5345225 -0.3162278 #> b -0.3162278 -0.2672612  0.6324555 #> c  0.0000000 -0.5345225  0.0000000 #> d  0.3162278 -0.2672612 -0.6324555 #> e  0.6324555  0.5345225  0.3162278  ## base argument of contr.treatment set_contrasts(d, iv, base = 2) <- contr.treatment d |> get_contrasts(iv) #>   a c d e #> a 1 0 0 0 #> b 0 0 0 0 #> c 0 1 0 0 #> d 0 0 1 0 #> e 0 0 0 1  set_contrasts(d, iv, base = 4) <- contr.treatment d |> get_contrasts(iv) #>   a b c e #> a 1 0 0 0 #> b 0 1 0 0 #> c 0 0 1 0 #> d 0 0 0 0 #> e 0 0 0 1  ## base argument of contr.treatment limited to nlevels(d$iv)  set_contrasts(d, iv, base = 99L) <- contr.treatment d |> get_contrasts(iv) #>   a b c d #> a 1 0 0 0 #> b 0 1 0 0 #> c 0 0 1 0 #> d 0 0 0 1 #> e 0 0 0 0  rm(d)"},{"path":"https://mark-eis.github.io/ParaAnita/reference/glm_plotdata.html","id":null,"dir":"Reference","previous_headings":"","what":"Collate Data for Plotting Univariable GLM Predictions with Error Bars — glm_plotdata","title":"Collate Data for Plotting Univariable GLM Predictions with Error Bars — glm_plotdata","text":"glm_plotdata() outputs data based predictions univariable general linear models (GLMs) suitably collated easy creation standardised plots error bars representing confidence intervals standard errors.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/glm_plotdata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Collate Data for Plotting Univariable GLM Predictions with Error Bars — glm_plotdata","text":"","code":"glm_plotdata(object, ...)  # S3 method for binom_contingency glm_plotdata(   object,   ...,   .ind_var,   .ungroup = NULL,   conf_level = 0.95,   type = c(\"link\", \"response\") )  # S3 method for data.frame glm_plotdata(   object,   ...,   .dep_var,   .ind_var,   .ungroup = NULL,   conf_level = 0.95,   type = c(\"link\", \"response\") )  # S3 method for formula glm_plotdata(   object,   ...,   .family = binomial,   .data,   .ungroup = NULL,   conf_level = 0.95,   type = c(\"link\", \"response\") )  # S3 method for glm glm_plotdata(object, ..., conf_level = 0.95, type = c(\"link\", \"response\"))"},{"path":"https://mark-eis.github.io/ParaAnita/reference/glm_plotdata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Collate Data for Plotting Univariable GLM Predictions with Error Bars — glm_plotdata","text":"object object odds ratios calculated, may binom_contingency table, data frame (data frame extension e.g., tibble), formula glm. ... arguments passed methods. currently used. .ind_var <data-masking> quoted name independent variable. .ungroup <data-masking> quoted name column containing ungrouped levels .ind_var, see details; default NULL. conf_level confidence level required error bars; default 0.95. NA, error bars standard error. type type prediction required. default scale linear predictors; alternative \"response\" scale response variable; default \"link\". .dep_var quoted name response variable data representing number successes failures respectively, see Details; default cbind(pn, qn). .family description error distribution link function used model. can character string naming family function, family function result call family function. (See family details family functions.) .data data frame, data frame extension (e.g. tibble).","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/glm_plotdata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Collate Data for Plotting Univariable GLM Predictions with Error Bars — glm_plotdata","text":"object class \"glm_plotdata\", \"announce\", inheriting tibble, values linear predictor response scale (depending type) columns follows: - level Level independent variable. grouped Grouped levels independent variable (NA ungrouped). n Number observations. obs Observed values. pred Values predicted model. lower Lower extent error bar. upper Upper extent error bar. also attributes \"conf_level\", signifying confidence level, \"ind_var\", name independent variable, \"type\" (see argument type).","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/glm_plotdata.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Collate Data for Plotting Univariable GLM Predictions with Error Bars — glm_plotdata","text":"function works univariable binomial GLMs numeric dependent variable ones zeros representing numbers successes failures, two-column matrix columns giving numbers successes failures, see glm(), independent variable multiple levels. output may plotted conveniently using ggplot() package ggplot2; ParaAnita provides suitable S3 method ggplot.glm_plotdata() purpose. glm_plotdata() allows exploration proposed groupings levels independent variable, obtained using add_grps() fct_collapse(), include grouped ungrouped levels output. cases, .ind_var contain groupings .ungroup argument name column object's data containing ungrouped levels, see examples. grouped levels used independent variable GLM shown within output object column grouped ungrouped levels shown column level. .ungroup NULL (default), levels .ind_var appear column level grouped column output contain NA. conf_level 0.95 (default) similar value, lower upper columns output delimit prediction intervals confidence level. conf_level NA, lower upper model predictions ±standard error. type = \"link\", linear predictors confidence intervals ±standard errors obtained. type = \"response\", linear predictors confidence intervals ±standard errors transformed back response scale using link inverse function.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/glm_plotdata.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Collate Data for Plotting Univariable GLM Predictions with Error Bars — glm_plotdata","text":"Confidence intervals calculated standard errors parameter estimates using quantiles t distribution n - 1 degrees freedom, probability given conf_level. confidence intervals generally conservative .e., little wider, obtained \"profiling\" (e.g., using confint.glm). conf_level argument NA, standard error shown rather confidence interval.","code":""},{"path":[]},{"path":"https://mark-eis.github.io/ParaAnita/reference/glm_plotdata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Collate Data for Plotting Univariable GLM Predictions with Error Bars — glm_plotdata","text":"","code":"(d <- binom_data()) #> __________________________ #> Simulated Binomial Data: - #>  #> # A tibble: 5 × 3 #>   iv       pn    qn #> * <fct> <int> <int> #> 1 a        32    34 #> 2 b        33    33 #> 3 c        25    41 #> 4 d        13    53 #> 5 e         6    60  ## ___________________________________________________ ## Ungrouped data, 95% Confidence interval (default)  ## On linear predictor scale (default) d |> glm_plotdata(.dep_var = cbind(pn, qn), .ind_var = iv) #> ________________ #> GLM Plot Data: - #>  #> # A tibble: 5 × 7 #>   level grouped     n     obs    pred  lower    upper #> * <fct> <fct>   <int>   <dbl>   <dbl>  <dbl>    <dbl> #> 1 a     NA         66 -0.0606 -0.0606 -0.545  0.424   #> 2 b     NA         66  0       0      -0.484  0.484   #> 3 c     NA         66 -0.495  -0.495  -0.994  0.00449 #> 4 d     NA         66 -1.41   -1.41   -2.01  -0.796   #> 5 e     NA         66 -2.30   -2.30   -3.14  -1.46     ## On response scale d |> glm_plotdata(.dep_var = cbind(pn, qn), .ind_var = iv, type = \"response\") #> ________________ #> GLM Plot Data: - #>  #> # A tibble: 5 × 7 #>   level grouped     n    obs   pred  lower upper #> * <fct> <fct>   <int>  <dbl>  <dbl>  <dbl> <dbl> #> 1 a     NA         66 0.485  0.485  0.367  0.604 #> 2 b     NA         66 0.5    0.5    0.381  0.619 #> 3 c     NA         66 0.379  0.379  0.270  0.501 #> 4 d     NA         66 0.197  0.197  0.118  0.311 #> 5 e     NA         66 0.0909 0.0909 0.0413 0.188  ## ________________________________ ## Ungrouped data, standard error  ## On linear predictor scale (default) d |> glm_plotdata(.dep_var = cbind(pn, qn), .ind_var = iv, conf_level = NA) #> ________________ #> GLM Plot Data: - #>  #> # A tibble: 5 × 7 #>   level grouped     n     obs    pred  lower  upper #> * <fct> <fct>   <int>   <dbl>   <dbl>  <dbl>  <dbl> #> 1 a     NA         66 -0.0606 -0.0606 -0.307  0.186 #> 2 b     NA         66  0       0      -0.246  0.246 #> 3 c     NA         66 -0.495  -0.495  -0.748 -0.241 #> 4 d     NA         66 -1.41   -1.41   -1.71  -1.10  #> 5 e     NA         66 -2.30   -2.30   -2.73  -1.87   ## On response scale d |> glm_plotdata(.dep_var = cbind(pn, qn), .ind_var = iv, conf_level = NA, type = \"response\") #> ________________ #> GLM Plot Data: - #>  #> # A tibble: 5 × 7 #>   level grouped     n    obs   pred  lower upper #> * <fct> <fct>   <int>  <dbl>  <dbl>  <dbl> <dbl> #> 1 a     NA         66 0.485  0.485  0.424  0.546 #> 2 b     NA         66 0.5    0.5    0.439  0.561 #> 3 c     NA         66 0.379  0.379  0.321  0.440 #> 4 d     NA         66 0.197  0.197  0.153  0.251 #> 5 e     NA         66 0.0909 0.0909 0.0612 0.133  (d <- list(iv2 = list(ab = c(\"a\", \"b\"), cd = c(\"c\", \"d\"))) |>     add_grps(d, iv, .key = _)) #> __________________________ #> Simulated Binomial Data: - #>  #> # A tibble: 5 × 4 #>   iv    iv2      pn    qn #>   <fct> <fct> <int> <int> #> 1 a     ab       32    34 #> 2 b     ab       33    33 #> 3 c     cd       25    41 #> 4 d     cd       13    53 #> 5 e     e         6    60  ## _________________________________________________ ## Grouped data, 95% Confidence interval (default)  ## On linear predictor scale (default) d |> glm_plotdata(.dep_var = cbind(pn, qn), .ind_var = iv2, .ungroup = iv) #> ________________ #> GLM Plot Data: - #>  #> # A tibble: 5 × 7 #>   level grouped     n     obs    pred  lower  upper #> * <fct> <fct>   <int>   <dbl>   <dbl>  <dbl>  <dbl> #> 1 a     ab         66 -0.0606 -0.0303 -0.373  0.312 #> 2 b     ab         66  0      -0.0303 -0.373  0.312 #> 3 c     cd         66 -0.495  -0.906  -1.28  -0.528 #> 4 d     cd         66 -1.41   -0.906  -1.28  -0.528 #> 5 e     e          66 -2.30   -2.30   -3.14  -1.46   ## On response scale d |> glm_plotdata(.dep_var = cbind(pn, qn), .ind_var = iv2, .ungroup = iv, type = \"response\") #> ________________ #> GLM Plot Data: - #>  #> # A tibble: 5 × 7 #>   level grouped     n    obs   pred  lower upper #> * <fct> <fct>   <int>  <dbl>  <dbl>  <dbl> <dbl> #> 1 a     ab         66 0.485  0.492  0.408  0.577 #> 2 b     ab         66 0.5    0.492  0.408  0.577 #> 3 c     cd         66 0.379  0.288  0.217  0.371 #> 4 d     cd         66 0.197  0.288  0.217  0.371 #> 5 e     e          66 0.0909 0.0909 0.0413 0.188  ## ______________________________ ## Grouped data, standard error  ## On linear predictor scale (default) d |> glm_plotdata(.dep_var = cbind(pn, qn), .ind_var = iv2, .ungroup = iv, conf_level = NA) #> ________________ #> GLM Plot Data: - #>  #> # A tibble: 5 × 7 #>   level grouped     n     obs    pred  lower  upper #> * <fct> <fct>   <int>   <dbl>   <dbl>  <dbl>  <dbl> #> 1 a     ab         66 -0.0606 -0.0303 -0.204  0.144 #> 2 b     ab         66  0      -0.0303 -0.204  0.144 #> 3 c     cd         66 -0.495  -0.906  -1.10  -0.713 #> 4 d     cd         66 -1.41   -0.906  -1.10  -0.713 #> 5 e     e          66 -2.30   -2.30   -2.73  -1.87   ## On response scale d |> glm_plotdata(         .dep_var = cbind(pn, qn), .ind_var = iv2,         .ungroup = iv, conf_level = NA, type = \"response\"      ) #> ________________ #> GLM Plot Data: - #>  #> # A tibble: 5 × 7 #>   level grouped     n    obs   pred  lower upper #> * <fct> <fct>   <int>  <dbl>  <dbl>  <dbl> <dbl> #> 1 a     ab         66 0.485  0.492  0.449  0.536 #> 2 b     ab         66 0.5    0.492  0.449  0.536 #> 3 c     cd         66 0.379  0.288  0.250  0.329 #> 4 d     cd         66 0.197  0.288  0.250  0.329 #> 5 e     e          66 0.0909 0.0909 0.0612 0.133  rm(d)"},{"path":"https://mark-eis.github.io/ParaAnita/reference/glm_plotlist.html","id":null,"dir":"Reference","previous_headings":"","what":"Data for Plotting Univariable GLM Predictions and Error Bars for Multiple Independent Variables — glm_plotlist","title":"Data for Plotting Univariable GLM Predictions and Error Bars for Multiple Independent Variables — glm_plotlist","text":"glm_plotlist() formats data plotting univariable GLM predictions error bars number independent variables.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/glm_plotlist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data for Plotting Univariable GLM Predictions and Error Bars for Multiple Independent Variables — glm_plotlist","text":"","code":"glm_plotlist(   data,   .dep_var,   ...,   .ungroups = NULL,   .conf_level = 0.95,   .type = c(\"link\", \"response\"),   .facet_by = NULL )"},{"path":"https://mark-eis.github.io/ParaAnita/reference/glm_plotlist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data for Plotting Univariable GLM Predictions and Error Bars for Multiple Independent Variables — glm_plotlist","text":"data data frame, data frame extension (e.g. tibble). .dep_var quoted name response variable data representing number successes failures respectively, see Details; default cbind(pn, qn). ... <tidy-select> independent variables included plot data. .ungroups named character vector ungrouped levels independent variables specified .ind_var, see details; default NULL. .conf_level confidence level required error bars; default 0.95. NA, error bars standard error. .type type prediction required. default scale linear predictors; alternative \"response\" scale response variable; default \"link\". .facet_by NULL, default; , output combined single object used faceted plot, character vector length one used name additional column containing names independent variables.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/glm_plotlist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data for Plotting Univariable GLM Predictions and Error Bars for Multiple Independent Variables — glm_plotlist","text":"argument .facet_by NULL, list \"glm_plotdata\" objects suitable producing multiple plots using ggplot(). Otherwise, single \"glm_plotdata\" object additional column taking name .facet_by containing names independent variables.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/glm_plotlist.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Data for Plotting Univariable GLM Predictions and Error Bars for Multiple Independent Variables — glm_plotlist","text":"glm_plotlist() invokes glm_plotdata() create list \"glm_plotdata\" objects plotting univariable GLM predictions error bars number independent variables data. Independent variables included selected using ... argument <tidy-select> syntax package dplyr, including use “selection helpers”. Like glm_plotdata(), glm_plotlist() allows exploration proposed groupings levels independent variables (e.g. obtained using add_grps() fct_collapse()) inclusion grouped ungrouped levels \"glm_plotdata\" objects comprising output list. cases, .ungroups argument used provide named character vector names corresponding factors data giving grouped ungrouped levels form ungrouped_name = \"grouped_name\"; levels otherwise mentioned left . grouped levels used independent variable GLM invoked glm_plotdata() output column grouped within corresponding \"glm_plotdata\" object, ungrouped levels shown column level, see glm_plotdata(). .conf_level .type arguments handled glm_plotdata(). glm_plotlist() may used conjunction lapply() (purrr package map()) rapidly obtain multiple plots univariable GLMs number independent variables. Levels independent variables observed values zero one included output, although taken consideration calculating denominators case grouped levels.","code":""},{"path":[]},{"path":"https://mark-eis.github.io/ParaAnita/reference/glm_plotlist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data for Plotting Univariable GLM Predictions and Error Bars for Multiple Independent Variables — glm_plotlist","text":"","code":"# Coming soon!"},{"path":"https://mark-eis.github.io/ParaAnita/reference/good_levels.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove Levels of Independent Variable where Dependent Variable All Success or All Failure — good_levels","title":"Remove Levels of Independent Variable where Dependent Variable All Success or All Failure — good_levels","text":"good_levels() identifies levels independent variable values Bernoulli dependent variable neither zero one .e., \\(0 < p < 1\\). drop_null() drops data levels independent variable Bernoulli dependent variable values either zero one .e., identified good_levels(). drop_zero() drops data levels independent variable binomial dependent variable either successes failures. levels_data returns levels factors data. nlevels_data returns number levels factors data.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/good_levels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove Levels of Independent Variable where Dependent Variable All Success or All Failure — good_levels","text":"","code":"good_levels(.data, .dep_var, .ind_var)  drop_null(.data, .dep_var, .ind_var)  drop_zero(.data, .ind_var, .dep_var = cbind(.data$pn, .data$qn))"},{"path":"https://mark-eis.github.io/ParaAnita/reference/good_levels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove Levels of Independent Variable where Dependent Variable All Success or All Failure — good_levels","text":".data data frame, data frame extension (e.g. tibble). .dep_var <data-masking> quoted name Bernoulli dependent variable numeric values 0 1; case drop zero(), binomial dependent variable, default cbind(.data$pn, .data$qn), representing number successes failures respectively, see glm(). .ind_var <data-masking> quoted name independent variable, may factor, character vector.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/good_levels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove Levels of Independent Variable where Dependent Variable All Success or All Failure — good_levels","text":"good_levels() returns character vector comprising levels .ind_var corresponding values .dep_var neither zero one. drop_null() drop_zero() return data frame data frame extension e.g., tibble, equivalent data, including rows levels .ind_var .dep_var values neither zero one, neither successes failures respectively.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/good_levels.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Remove Levels of Independent Variable where Dependent Variable All Success or All Failure — good_levels","text":"Bernoulli trial dataset numeric dependent variable coded 0 1, good_levels() identifies  levels independent variable values dependent variable neither zero one .e., \\(0 < p < 1\\). similar dataset, drop_null() drops rows data levels independent variable identified good_levels(). Unused factor levels dropped independent variable. binomial dataset, drop_zero() drops rows data either successes failures, successes failures.","code":""},{"path":[]},{"path":"https://mark-eis.github.io/ParaAnita/reference/good_levels.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remove Levels of Independent Variable where Dependent Variable All Success or All Failure — good_levels","text":"","code":"d <- bernoulli_data(probs = c(0.8, 0.4, 0, 0.3, 0.6 )) d |> binom_contingency(dv) #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 5 × 3 #>   iv       pn    qn #> * <fct> <int> <int> #> 1 a        50    16 #> 2 b        24    42 #> 3 c         0    66 #> 4 d        20    46 #> 5 e        50    16 d |> levels_data() #> $iv #> [1] \"a\" \"b\" \"c\" \"d\" \"e\" #>  d |> good_levels(dv, iv) #> [1] \"a\" \"b\" \"d\" \"e\" d |> drop_null(dv, iv) |> levels_data() #> $iv #> [1] \"a\" \"b\" \"d\" \"e\" #>  d |> drop_null(dv, iv) |> binom_contingency(dv) #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 4 × 3 #>   iv       pn    qn #> * <fct> <int> <int> #> 1 a        50    16 #> 2 b        24    42 #> 3 d        20    46 #> 4 e        50    16 d |> binom_contingency(dv) |> drop_zero(iv) #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 4 × 3 #>   iv       pn    qn #>   <fct> <int> <int> #> 1 a        50    16 #> 2 b        24    42 #> 3 d        20    46 #> 4 e        50    16  identical(   d |> drop_null(dv, iv) |> binom_contingency(dv),   d |> binom_contingency(dv) |> drop_zero(iv) ) #> [1] TRUE  d_ls <- map2(c(0.5, 0.4, 1, 1), c(0.1, 0, 0.6, 0), seq, length.out = 5) |>     lapply(\\(x) bernoulli_data(probs = x)) |>     (\\(x) setNames(x, paste0(\"data\", seq_along(x))))()  d_ls |> lapply(\\(d) d |> binom_contingency(dv)) #> $data1 #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 5 × 3 #>   iv       pn    qn #> * <fct> <int> <int> #> 1 a        36    30 #> 2 b        29    37 #> 3 c        23    43 #> 4 d        10    56 #> 5 e        11    55 #>  #> $data2 #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 5 × 3 #>   iv       pn    qn #> * <fct> <int> <int> #> 1 a        27    39 #> 2 b        24    42 #> 3 c        11    55 #> 4 d         5    61 #> 5 e         0    66 #>  #> $data3 #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 5 × 3 #>   iv       pn    qn #> * <fct> <int> <int> #> 1 a        66     0 #> 2 b        59     7 #> 3 c        45    21 #> 4 d        41    25 #> 5 e        40    26 #>  #> $data4 #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 5 × 3 #>   iv       pn    qn #> * <fct> <int> <int> #> 1 a        66     0 #> 2 b        56    10 #> 3 c        32    34 #> 4 d         9    57 #> 5 e         0    66 #>  d_ls |> lapply(levels_data) #> $data1 #> $data1$iv #> [1] \"a\" \"b\" \"c\" \"d\" \"e\" #>  #>  #> $data2 #> $data2$iv #> [1] \"a\" \"b\" \"c\" \"d\" \"e\" #>  #>  #> $data3 #> $data3$iv #> [1] \"a\" \"b\" \"c\" \"d\" \"e\" #>  #>  #> $data4 #> $data4$iv #> [1] \"a\" \"b\" \"c\" \"d\" \"e\" #>  #>  d_ls |> lapply(\\(d) d |> good_levels(dv, iv)) #> $data1 #> [1] \"a\" \"b\" \"c\" \"d\" \"e\" #>  #> $data2 #> [1] \"a\" \"b\" \"c\" \"d\" #>  #> $data3 #> [1] \"b\" \"c\" \"d\" \"e\" #>  #> $data4 #> [1] \"b\" \"c\" \"d\" #>  d_ls |> lapply(\\(d) d |> drop_null(dv, iv) |> binom_contingency(dv)) #> $data1 #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 5 × 3 #>   iv       pn    qn #> * <fct> <int> <int> #> 1 a        36    30 #> 2 b        29    37 #> 3 c        23    43 #> 4 d        10    56 #> 5 e        11    55 #>  #> $data2 #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 4 × 3 #>   iv       pn    qn #> * <fct> <int> <int> #> 1 a        27    39 #> 2 b        24    42 #> 3 c        11    55 #> 4 d         5    61 #>  #> $data3 #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 4 × 3 #>   iv       pn    qn #> * <fct> <int> <int> #> 1 b        59     7 #> 2 c        45    21 #> 3 d        41    25 #> 4 e        40    26 #>  #> $data4 #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 3 × 3 #>   iv       pn    qn #> * <fct> <int> <int> #> 1 b        56    10 #> 2 c        32    34 #> 3 d         9    57 #>  d_ls |> lapply(\\(d) d |> binom_contingency(dv) |> drop_zero(iv)) #> $data1 #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 5 × 3 #>   iv       pn    qn #>   <fct> <int> <int> #> 1 a        36    30 #> 2 b        29    37 #> 3 c        23    43 #> 4 d        10    56 #> 5 e        11    55 #>  #> $data2 #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 4 × 3 #>   iv       pn    qn #>   <fct> <int> <int> #> 1 a        27    39 #> 2 b        24    42 #> 3 c        11    55 #> 4 d         5    61 #>  #> $data3 #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 4 × 3 #>   iv       pn    qn #>   <fct> <int> <int> #> 1 b        59     7 #> 2 c        45    21 #> 3 d        41    25 #> 4 e        40    26 #>  #> $data4 #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 3 × 3 #>   iv       pn    qn #>   <fct> <int> <int> #> 1 b        56    10 #> 2 c        32    34 #> 3 d         9    57 #>   identical(   d_ls |> lapply(\\(d) d |> drop_null(dv, iv) |> binom_contingency(dv)),    d_ls |> lapply(\\(d) d |> binom_contingency(dv) |> drop_zero(iv)) ) #> [1] TRUE  rm(d, d_ls)  ## Using gss_cat dataset from {forcats} package # \\dontshow{    if (!requireNamespace(\"forcats\", quietly = TRUE))         warning(\"package 'forcats' must be installed\")    try(gss_cat <- forcats::gss_cat) # }  gss_cat |> names() #> [1] \"year\"    \"marital\" \"age\"     \"race\"    \"rincome\" \"partyid\" \"relig\"   #> [8] \"denom\"   \"tvhours\" gss_cat |> levels_data() #> $marital #> [1] \"No answer\"     \"Never married\" \"Separated\"     \"Divorced\"      #> [5] \"Widowed\"       \"Married\"       #>  #> $race #> [1] \"Other\"          \"Black\"          \"White\"          \"Not applicable\" #>  #> $rincome #>  [1] \"No answer\"      \"Don't know\"     \"Refused\"        \"$25000 or more\" #>  [5] \"$20000 - 24999\" \"$15000 - 19999\" \"$10000 - 14999\" \"$8000 to 9999\"  #>  [9] \"$7000 to 7999\"  \"$6000 to 6999\"  \"$5000 to 5999\"  \"$4000 to 4999\"  #> [13] \"$3000 to 3999\"  \"$1000 to 2999\"  \"Lt $1000\"       \"Not applicable\" #>  #> $partyid #>  [1] \"No answer\"          \"Don't know\"         \"Other party\"        #>  [4] \"Strong republican\"  \"Not str republican\" \"Ind,near rep\"       #>  [7] \"Independent\"        \"Ind,near dem\"       \"Not str democrat\"   #> [10] \"Strong democrat\"    #>  #> $relig #>  [1] \"No answer\"               \"Don't know\"              #>  [3] \"Inter-nondenominational\" \"Native american\"         #>  [5] \"Christian\"               \"Orthodox-christian\"      #>  [7] \"Moslem/islam\"            \"Other eastern\"           #>  [9] \"Hinduism\"                \"Buddhism\"                #> [11] \"Other\"                   \"None\"                    #> [13] \"Jewish\"                  \"Catholic\"                #> [15] \"Protestant\"              \"Not applicable\"          #>  #> $denom #>  [1] \"No answer\"            \"Don't know\"           \"No denomination\"      #>  [4] \"Other\"                \"Episcopal\"            \"Presbyterian-dk wh\"   #>  [7] \"Presbyterian, merged\" \"Other presbyterian\"   \"United pres ch in us\" #> [10] \"Presbyterian c in us\" \"Lutheran-dk which\"    \"Evangelical luth\"     #> [13] \"Other lutheran\"       \"Wi evan luth synod\"   \"Lutheran-mo synod\"    #> [16] \"Luth ch in america\"   \"Am lutheran\"          \"Methodist-dk which\"   #> [19] \"Other methodist\"      \"United methodist\"     \"Afr meth ep zion\"     #> [22] \"Afr meth episcopal\"   \"Baptist-dk which\"     \"Other baptists\"       #> [25] \"Southern baptist\"     \"Nat bapt conv usa\"    \"Nat bapt conv of am\"  #> [28] \"Am bapt ch in usa\"    \"Am baptist asso\"      \"Not applicable\"       #>  gss_cat |> nlevels_data() #> marital    race rincome partyid   relig   denom  #>       6       4      16      10      16      30   # \\dontshow{     rm(gss_cat) # }"},{"path":"https://mark-eis.github.io/ParaAnita/reference/helm_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Create and Set Names for Helmert Contrasts — helm_names","title":"Create and Set Names for Helmert Contrasts — helm_names","text":"Create set column names Helmert contrasts associated factor.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/helm_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create and Set Names for Helmert Contrasts — helm_names","text":"","code":"helm_names(x)  helm_names(x) <- value"},{"path":"https://mark-eis.github.io/ParaAnita/reference/helm_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create and Set Names for Helmert Contrasts — helm_names","text":"x factor contrast column headings named. value character vector list length two (subsequent elements ignored), separators used creating headings; first \"within\" separator second \"\" separator, see examples.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/helm_names.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create and Set Names for Helmert Contrasts — helm_names","text":"Helmert contrasts factor contrast second level first, third average first two, . contrasts matrix can set attribute factor using function contrasts<-, using contrasts function contr.helmert argument .e., contrasts(f)<- contr.helmert, create set appropriate Helmert contrasts matrix attribute. However columns resulting Helmert contrasts matrix unnamed. helm_names()<- creates column names based names levels factor x. factor x associated Helmert contrast matrix, helm_names()<- set one, giving message. names levels factor x need fairly short function helpful. function helm_names() alias contr_colnames included simply completeness optimise help searches.","code":""},{"path":[]},{"path":"https://mark-eis.github.io/ParaAnita/reference/helm_names.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create and Set Names for Helmert Contrasts — helm_names","text":"","code":"(f <- gl(5, 5, labels = LETTERS[1:5])) #>  [1] A A A A A B B B B B C C C C C D D D D D E E E E E #> Levels: A B C D E  contrasts(f)<- contr.helmert f #>  [1] A A A A A B B B B B C C C C C D D D D D E E E E E #> attr(,\"contrasts\") #>   [,1] [,2] [,3] [,4] #> A   -1   -1   -1   -1 #> B    1   -1   -1   -1 #> C    0    2   -1   -1 #> D    0    0    3   -1 #> E    0    0    0    4 #> Levels: A B C D E helm_names(f) #> NULL  helm_names(f)<- c(\":\", \"v\") f #>  [1] A A A A A B B B B B C C C C C D D D D D E E E E E #> attr(,\"contrasts\") #>   A v B A:B v C A:C v D A:D v E #> A    -1      -1      -1      -1 #> B     1      -1      -1      -1 #> C     0       2      -1      -1 #> D     0       0       3      -1 #> E     0       0       0       4 #> Levels: A B C D E helm_names(f) #> [1] \"A v B\"   \"A:B v C\" \"A:C v D\" \"A:D v E\"  contrasts(f)<- NULL f #>  [1] A A A A A B B B B B C C C C C D D D D D E E E E E #> Levels: A B C D E  helm_names(f)<- c(\"-\", \"vs.\") #> Setting Helmert contrasts for factor x with `helm_names()<-`. f #>  [1] A A A A A B B B B B C C C C C D D D D D E E E E E #> attr(,\"contrasts\") #>   A vs. B A-B vs. C A-C vs. D A-D vs. E #> A      -1        -1        -1        -1 #> B       1        -1        -1        -1 #> C       0         2        -1        -1 #> D       0         0         3        -1 #> E       0         0         0         4 #> Levels: A B C D E helm_names(f) #> [1] \"A vs. B\"   \"A-B vs. C\" \"A-C vs. D\" \"A-D vs. E\"  rm(f)"},{"path":"https://mark-eis.github.io/ParaAnita/reference/levels_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Levels of all Factors in Data — levels_data","title":"Levels of all Factors in Data — levels_data","text":"levels_data() returns levels factors data. nlevels_data() returns number levels factors data.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/levels_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Levels of all Factors in Data — levels_data","text":"","code":"levels_data(data)  nlevels_data(data)"},{"path":"https://mark-eis.github.io/ParaAnita/reference/levels_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Levels of all Factors in Data — levels_data","text":"data data frame, data frame extension (e.g. tibble).","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/levels_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Levels of all Factors in Data — levels_data","text":"levels_data() returns named list comprising levels factor data. nlevels_data() returns named integer vector comprising number levels factor data.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/levels_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Levels of all Factors in Data — levels_data","text":"says tin.","code":""},{"path":[]},{"path":"https://mark-eis.github.io/ParaAnita/reference/levels_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Levels of all Factors in Data — levels_data","text":"","code":"## Using gss_cat dataset from {forcats} package # \\dontshow{    if (!requireNamespace(\"forcats\", quietly = TRUE))         warning(\"package 'forcats' must be installed\")    try(gss_cat <- forcats::gss_cat) # }  gss_cat |> names() #> [1] \"year\"    \"marital\" \"age\"     \"race\"    \"rincome\" \"partyid\" \"relig\"   #> [8] \"denom\"   \"tvhours\" gss_cat |> levels_data() #> $marital #> [1] \"No answer\"     \"Never married\" \"Separated\"     \"Divorced\"      #> [5] \"Widowed\"       \"Married\"       #>  #> $race #> [1] \"Other\"          \"Black\"          \"White\"          \"Not applicable\" #>  #> $rincome #>  [1] \"No answer\"      \"Don't know\"     \"Refused\"        \"$25000 or more\" #>  [5] \"$20000 - 24999\" \"$15000 - 19999\" \"$10000 - 14999\" \"$8000 to 9999\"  #>  [9] \"$7000 to 7999\"  \"$6000 to 6999\"  \"$5000 to 5999\"  \"$4000 to 4999\"  #> [13] \"$3000 to 3999\"  \"$1000 to 2999\"  \"Lt $1000\"       \"Not applicable\" #>  #> $partyid #>  [1] \"No answer\"          \"Don't know\"         \"Other party\"        #>  [4] \"Strong republican\"  \"Not str republican\" \"Ind,near rep\"       #>  [7] \"Independent\"        \"Ind,near dem\"       \"Not str democrat\"   #> [10] \"Strong democrat\"    #>  #> $relig #>  [1] \"No answer\"               \"Don't know\"              #>  [3] \"Inter-nondenominational\" \"Native american\"         #>  [5] \"Christian\"               \"Orthodox-christian\"      #>  [7] \"Moslem/islam\"            \"Other eastern\"           #>  [9] \"Hinduism\"                \"Buddhism\"                #> [11] \"Other\"                   \"None\"                    #> [13] \"Jewish\"                  \"Catholic\"                #> [15] \"Protestant\"              \"Not applicable\"          #>  #> $denom #>  [1] \"No answer\"            \"Don't know\"           \"No denomination\"      #>  [4] \"Other\"                \"Episcopal\"            \"Presbyterian-dk wh\"   #>  [7] \"Presbyterian, merged\" \"Other presbyterian\"   \"United pres ch in us\" #> [10] \"Presbyterian c in us\" \"Lutheran-dk which\"    \"Evangelical luth\"     #> [13] \"Other lutheran\"       \"Wi evan luth synod\"   \"Lutheran-mo synod\"    #> [16] \"Luth ch in america\"   \"Am lutheran\"          \"Methodist-dk which\"   #> [19] \"Other methodist\"      \"United methodist\"     \"Afr meth ep zion\"     #> [22] \"Afr meth episcopal\"   \"Baptist-dk which\"     \"Other baptists\"       #> [25] \"Southern baptist\"     \"Nat bapt conv usa\"    \"Nat bapt conv of am\"  #> [28] \"Am bapt ch in usa\"    \"Am baptist asso\"      \"Not applicable\"       #>  gss_cat |> nlevels_data() #> marital    race rincome partyid   relig   denom  #>       6       4      16      10      16      30   # \\dontshow{     rm(gss_cat) # }"},{"path":"https://mark-eis.github.io/ParaAnita/reference/lf.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe-Friendly Line Feeds and Printing — lf","title":"Pipe-Friendly Line Feeds and Printing — lf","text":"lf() outputs one line feeds piped sequence.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/lf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe-Friendly Line Feeds and Printing — lf","text":"","code":"lf(x, n = 1)  print_lf(x, n = 1)"},{"path":"https://mark-eis.github.io/ParaAnita/reference/lf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe-Friendly Line Feeds and Printing — lf","text":"x Object piped. n Number line feeds; default 1.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/lf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe-Friendly Line Feeds and Printing — lf","text":"Invisibly returns first argument.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/lf.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Pipe-Friendly Line Feeds and Printing — lf","text":"print_lf() prints object piped sequence outputs one line feeds. object passed argument piped sequence printed /one line feeds output piped sequence using cat(). can useful separate lines printed output, see examples.","code":""},{"path":[]},{"path":"https://mark-eis.github.io/ParaAnita/reference/lf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pipe-Friendly Line Feeds and Printing — lf","text":"","code":"obj <- \"Lorem ipsum dolor sit amet\" obj |> lf()               # line feed, object returned invisibly #>  obj |> lf(3)              # three line feeds, object returned invisibly #>  #>   #>   (obj |> lf(3))            # three line feeds, returned object rendered visible #>  #>   #>   #> [1] \"Lorem ipsum dolor sit amet\" obj |> lf(3) |> paste(\"consectetur adipiscing elit\", sep = \", \") #>  #>   #>   #> [1] \"Lorem ipsum dolor sit amet, consectetur adipiscing elit\"  obj |> print() |> lf(3)   # line feeds are unexpectedly before printed output. #>  #>   #>   #> [1] \"Lorem ipsum dolor sit amet\"  ## Use print_lf() instead obj |> print_lf()         # object printed with line feed and returned invisibly #> [1] \"Lorem ipsum dolor sit amet\" #>  obj |> print_lf(3)        # object printed with three line feeds and returned invisibly #> [1] \"Lorem ipsum dolor sit amet\" #>  #>   #>   (obj |> print_lf(3))      # Ditto, then rendered visible #> [1] \"Lorem ipsum dolor sit amet\" #>  #>   #>   #> [1] \"Lorem ipsum dolor sit amet\" obj |> print_lf(3) |> paste(\"consectetur adipiscing elit\", sep = \", \") #> [1] \"Lorem ipsum dolor sit amet\" #>  #>   #>   #> [1] \"Lorem ipsum dolor sit amet, consectetur adipiscing elit\"  rm(obj)"},{"path":"https://mark-eis.github.io/ParaAnita/reference/odds_ratio.html","id":null,"dir":"Reference","previous_headings":"","what":"Odds Ratios, Standard Errors, Confidence Intervals and P-Values for Binomial GLMs — odds_ratio","title":"Odds Ratios, Standard Errors, Confidence Intervals and P-Values for Binomial GLMs — odds_ratio","text":"odds_ratio() calculates odds ratios profiled confidence intervals GLMs outputs together estimates regression coefficients, standard errors probabilities.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/odds_ratio.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Odds Ratios, Standard Errors, Confidence Intervals and P-Values for Binomial GLMs — odds_ratio","text":"","code":"odds_ratio(object, ...)  # S3 method for binom_contingency odds_ratio(   object,   ...,   .ind_var,   .level = 0.95,   .print_call = FALSE,   .stat = FALSE,   .print_contr = FALSE )  # S3 method for data.frame odds_ratio(   object,   ...,   .dep_var,   .ind_var,   .level = 0.95,   .print_call = FALSE,   .stat = FALSE,   .print_contr = FALSE )  # S3 method for formula odds_ratio(   object,   ...,   .family = binomial,   .data,   .level = 0.95,   .print_call = FALSE,   .stat = FALSE,   .print_contr = FALSE )  # S3 method for glm odds_ratio(   object,   ...,   .level = 0.95,   .print_call = TRUE,   .stat = FALSE,   .print_contr = FALSE )"},{"path":"https://mark-eis.github.io/ParaAnita/reference/odds_ratio.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Odds Ratios, Standard Errors, Confidence Intervals and P-Values for Binomial GLMs — odds_ratio","text":"object object odds ratios calculated, may binom_contingency table, data frame (data frame extension e.g., tibble), formula glm. ... arguments passed methods. .ind_var <data-masking> quoted name independent variable, may either character vector factor. .level confidence level required; default 0.95. .print_call logical, whether print call GLM. .stat logical, whether print z t statistic GLM; default FALSE. .print_contr logical. TRUE, .ind_var contrast attribute set, contrast matrix printed; default FALSE. .dep_var <data-masking> quoted name numeric response variable data, either vector values 1 0, representing number successes failures respectively, two-column matrix columns giving numbers successes failures see glm(). .family description error distribution link function used model. can character string naming family function, family function result call family function. (See family details family functions.) .data data frame, data frame extension (e.g. tibble).","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/odds_ratio.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Odds Ratios, Standard Errors, Confidence Intervals and P-Values for Binomial GLMs — odds_ratio","text":"object classes \"odds_ratio\", \"announce\", inheriting tibble, containing following columns: - parameter names model parameters. estimate estimate regression coefficient. se standard error estimate. z (t) value Optionally, value z (t) statistic estimate. p_val p-value estimate. odds_ratio odds ratio. ci lower upper confidence intervals odds ratio, default 2.5% 97.5% levels. sig Stars statistical significance.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/odds_ratio.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Odds Ratios, Standard Errors, Confidence Intervals and P-Values for Binomial GLMs — odds_ratio","text":"odds_ratio() generic function used calculate odds ratios profiled confidence intervals univariable GLMs single categorical independent variable, multivariable GLMs, output together estimates regression coefficients, standard errors probabilities. function invokes particular methods depend class first argument. S3 method objects class \"formula\" \"glm\" can used either unvariable GLMs, multivariable GLMs calculate \"adjusted\" odds ratios. Currently, S3 methods classes \"data.frame\" \"binom_contingency\" can used univariable GLMs. Optionally, print_call = TRUE call glm() may retrieved printed. .print_contr = TRUE factor independent variables contrast attribute set, contrast matrix printed. Contrasts may set conveniently factors data using set_contrasts(), see examples. Confidence intervals odds ratios based profile likelihood calculated using confint.glm(). confidence level may adjusted using .level, otherwise default value 0.95 used.","code":""},{"path":[]},{"path":"https://mark-eis.github.io/ParaAnita/reference/odds_ratio.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Odds Ratios, Standard Errors, Confidence Intervals and P-Values for Binomial GLMs — odds_ratio","text":"","code":"## Create simulated Bernoulli data (d <- bernoulli_data()) #> ___________________________ #> Simulated Bernoulli Data: - #>  #> # A tibble: 330 × 2 #>    iv       dv #>  * <fct> <int> #>  1 a         0 #>  2 a         0 #>  3 a         0 #>  4 a         0 #>  5 a         1 #>  6 a         1 #>  7 a         1 #>  8 a         1 #>  9 a         1 #> 10 a         1 #> # ℹ 320 more rows  ## Invoking the S3 method for class \"data.frame\" and using the default ## contrasts from options(\"contrasts\") ## — contrasts not printed  d |> odds_ratio(.dep_var = dv, .ind_var = iv) #> Waiting for profiling to be done... #> ____________________________ #> Estimates and Odds Ratios: - #>  #> # A tibble: 5 × 7 #>   parameter   estimate    se     p_val odds_ratio ci[,\"2.5%\"] [,\"97.5%\"] sig   #>   <chr>          <dbl> <dbl>     <dbl>      <dbl>       <dbl>      <dbl> <fct> #> 1 (Intercept)    0.182 0.247 0.461         1          NA          NA     NS    #> 2 ivb           -0.550 0.352 0.118         0.577       0.287       1.15  NS    #> 3 ivc           -1.41  0.384 0.000250      0.245       0.113       0.512 ***   #> 4 ivd           -1.91  0.423 0.0000067     0.149       0.0623      0.331 ***   #> 5 ive           -2.48  0.494 0.0000005     0.0833      0.0289      0.207 ***    ## Using the default contrasts from options(\"contrasts\") ## — adjust confidence level, contrasts are printed  d |> odds_ratio(.dep_var = dv, .ind_var = iv, .level = 0.99, .print_contr = TRUE) #> Waiting for profiling to be done... #> ____________________________ #> Estimates and Odds Ratios: - #>  #> # A tibble: 5 × 7 #>   parameter   estimate    se     p_val odds_ratio ci[,\"0.5%\"] [,\"99.5%\"] sig   #>   <chr>          <dbl> <dbl>     <dbl>      <dbl>       <dbl>      <dbl> <fct> #> 1 (Intercept)    0.182 0.247 0.461         1          NA          NA     NS    #> 2 ivb           -0.550 0.352 0.118         0.577       0.230       1.42  NS    #> 3 ivc           -1.41  0.384 0.000250      0.245       0.0876      0.642 ***   #> 4 ivd           -1.91  0.423 0.0000067     0.149       0.0463      0.421 ***   #> 5 ive           -2.48  0.494 0.0000005     0.0833      0.0198      0.269 ***   #> ____________ #> Contrasts: - #>  #> $iv #> [1] \"contr.treatment\" #>   ## Specifying treatment contrasts, with last level as base ## — contrasts not printed d |> set_contrasts(iv, base =  99L, contr = contr.treatment) |>     odds_ratio(.dep_var = dv, .ind_var = iv) #> Waiting for profiling to be done... #> ____________________________ #> Estimates and Odds Ratios: - #>  #> # A tibble: 5 × 7 #>   parameter   estimate    se     p_val odds_ratio ci[,\"2.5%\"] [,\"97.5%\"] sig   #>   <chr>          <dbl> <dbl>     <dbl>      <dbl>       <dbl>      <dbl> <fct> #> 1 (Intercept)   -2.30  0.428 0.0000001       1         NA          NA    ***   #> 2 iva            2.48  0.494 0.0000005      12.0        4.84       34.5  ***   #> 3 ivb            1.93  0.496 0.0000956       6.92       2.77       19.9  ***   #> 4 ivc            1.08  0.519 0.0377          2.94       1.11        8.76 *     #> 5 ivd            0.580 0.549 0.291           1.79       0.621       5.55 NS     ## Specifying treatment contrasts, with last level as base ## — contrasts printed d |> set_contrasts(iv, base =  99L, contr = contr.treatment) |>     odds_ratio(.dep_var = dv, .ind_var = iv, .print_contr = TRUE) #> Waiting for profiling to be done... #> ____________________________ #> Estimates and Odds Ratios: - #>  #> # A tibble: 5 × 7 #>   parameter   estimate    se     p_val odds_ratio ci[,\"2.5%\"] [,\"97.5%\"] sig   #>   <chr>          <dbl> <dbl>     <dbl>      <dbl>       <dbl>      <dbl> <fct> #> 1 (Intercept)   -2.30  0.428 0.0000001       1         NA          NA    ***   #> 2 iva            2.48  0.494 0.0000005      12.0        4.84       34.5  ***   #> 3 ivb            1.93  0.496 0.0000956       6.92       2.77       19.9  ***   #> 4 ivc            1.08  0.519 0.0377          2.94       1.11        8.76 *     #> 5 ivd            0.580 0.549 0.291           1.79       0.621       5.55 NS    #> ____________ #> Contrasts: - #>  #> $iv #>   a b c d #> a 1 0 0 0 #> b 0 1 0 0 #> c 0 0 1 0 #> d 0 0 0 1 #> e 0 0 0 0 #>   ## Helmert contrasts specified ## — contrasts printed d |> set_contrasts(iv, contr = contr.helmert) |>     odds_ratio(.dep_var = dv, .ind_var = iv, .print_contr = TRUE) #> Waiting for profiling to be done... #> ____________________________ #> Estimates and Odds Ratios: - #>  #> # A tibble: 5 × 7 #>   parameter   estimate     se    p_val odds_ratio ci[,\"2.5%\"] [,\"97.5%\"] sig   #>   <chr>          <dbl>  <dbl>    <dbl>      <dbl>       <dbl>      <dbl> <fct> #> 1 (Intercept)   -1.09  0.143  0             1          NA         NA     ***   #> 2 iv1           -0.275 0.176  0.118         0.760       0.536      1.07  NS    #> 3 iv2           -0.377 0.114  0.000954      0.686       0.544      0.852 ***   #> 4 iv3           -0.313 0.0939 0.000854      0.731       0.600      0.871 ***   #> 5 iv4           -0.304 0.0903 0.000761      0.738       0.606      0.868 ***   #> ____________ #> Contrasts: - #>  #> $iv #>   [,1] [,2] [,3] [,4] #> a   -1   -1   -1   -1 #> b    1   -1   -1   -1 #> c    0    2   -1   -1 #> d    0    0    3   -1 #> e    0    0    0    4 #>   # Set default unordered contrasts in options(\"contrasts\") to Helmert options(\"contrasts\" =  c(unordered = \"contr.helmert\", ordered = \"contr.poly\")) getOption(\"contrasts\") #>       unordered         ordered  #> \"contr.helmert\"    \"contr.poly\"   ## Using the default, unordered Helmert contrasts ## — contrasts printed d |> odds_ratio(.dep_var = dv, .ind_var = iv, .print_contr = TRUE) #> Waiting for profiling to be done... #> ____________________________ #> Estimates and Odds Ratios: - #>  #> # A tibble: 5 × 7 #>   parameter   estimate     se    p_val odds_ratio ci[,\"2.5%\"] [,\"97.5%\"] sig   #>   <chr>          <dbl>  <dbl>    <dbl>      <dbl>       <dbl>      <dbl> <fct> #> 1 (Intercept)   -1.09  0.143  0             1          NA         NA     ***   #> 2 iv1           -0.275 0.176  0.118         0.760       0.536      1.07  NS    #> 3 iv2           -0.377 0.114  0.000954      0.686       0.544      0.852 ***   #> 4 iv3           -0.313 0.0939 0.000854      0.731       0.600      0.871 ***   #> 5 iv4           -0.304 0.0903 0.000761      0.738       0.606      0.868 ***   #> ____________ #> Contrasts: - #>  #> $iv #> [1] \"contr.helmert\" #>   ## Specify treatment contrasts ## — contrasts printed d |> set_contrasts(iv, contr = contr.treatment) |>     odds_ratio(.dep_var = dv, .ind_var = iv, .print_contr = TRUE) #> Waiting for profiling to be done... #> ____________________________ #> Estimates and Odds Ratios: - #>  #> # A tibble: 5 × 7 #>   parameter   estimate    se     p_val odds_ratio ci[,\"2.5%\"] [,\"97.5%\"] sig   #>   <chr>          <dbl> <dbl>     <dbl>      <dbl>       <dbl>      <dbl> <fct> #> 1 (Intercept)    0.182 0.247 0.461         1          NA          NA     NS    #> 2 ivb           -0.550 0.352 0.118         0.577       0.287       1.15  NS    #> 3 ivc           -1.41  0.384 0.000250      0.245       0.113       0.512 ***   #> 4 ivd           -1.91  0.423 0.0000067     0.149       0.0623      0.331 ***   #> 5 ive           -2.48  0.494 0.0000005     0.0833      0.0289      0.207 ***   #> ____________ #> Contrasts: - #>  #> $iv #>   b c d e #> a 0 0 0 0 #> b 1 0 0 0 #> c 0 1 0 0 #> d 0 0 1 0 #> e 0 0 0 1 #>   # Restore default contrasts in options(\"contrasts\") options(\"contrasts\" =  c(unordered = \"contr.treatment\", ordered = \"contr.poly\")) options(\"contrasts\") #> $contrasts #>         unordered           ordered  #> \"contr.treatment\"      \"contr.poly\"  #>   ## Invoking the S3 method for class \"binom_contingency\"  d |> binom_contingency(dv, iv) |> odds_ratio(.ind_var = iv) #> Waiting for profiling to be done... #> ____________________________ #> Estimates and Odds Ratios: - #>  #> # A tibble: 5 × 7 #>   parameter   estimate    se     p_val odds_ratio ci[,\"2.5%\"] [,\"97.5%\"] sig   #>   <chr>          <dbl> <dbl>     <dbl>      <dbl>       <dbl>      <dbl> <fct> #> 1 (Intercept)    0.182 0.247 0.461         1          NA          NA     NS    #> 2 ivb           -0.550 0.352 0.118         0.577       0.287       1.15  NS    #> 3 ivc           -1.41  0.384 0.000250      0.245       0.113       0.512 ***   #> 4 ivd           -1.91  0.423 0.0000067     0.149       0.0623      0.331 ***   #> 5 ive           -2.48  0.494 0.0000005     0.0833      0.0289      0.207 ***    ## Create multivariable glm object and specify treatment contrasts (d <- list(     iv2 = list(g = c(\"a\", \"c\", \"e\"), h = c(\"b\", \"d\", \"f\")),     iv3 = list(i = c(\"a\", \"b\", \"c\"), j = c(\"d\", \"e\", \"f\")) ) |> add_grps(binom_data(levels = 6), iv, .key = _)) #> __________________________ #> Simulated Binomial Data: - #>  #> # A tibble: 6 × 5 #>   iv    iv2   iv3      pn    qn #>   <fct> <fct> <fct> <int> <int> #> 1 a     g     i        39    27 #> 2 b     h     i        30    36 #> 3 c     g     i        19    47 #> 4 d     h     j        17    49 #> 5 e     g     j         9    57 #> 6 f     h     j         3    63  set_contr_treat(d, num_range(\"iv\", 2:3)) <- c(1L, 2L) get_contr_data(d) #> $iv #> NULL #>  #> $iv2 #>   h #> g 0 #> h 1 #>  #> $iv3 #>   i #> i 1 #> j 0 #>   glm1 <- glm(cbind(pn, qn) ~ iv2 + iv3, family = binomial, data = d)  glm1 |> summary() #>  #> Call: #> glm(formula = cbind(pn, qn) ~ iv2 + iv3, family = binomial, data = d) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept) -1.81758    0.26222  -6.931 4.17e-12 *** #> iv2h         0.08168    0.24783   0.330    0.742     #> iv3i         1.56713    0.26105   6.003 1.93e-09 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 68.942  on 5  degrees of freedom #> Residual deviance: 25.099  on 3  degrees of freedom #> AIC: 56.045 #>  #> Number of Fisher Scoring iterations: 4 #>   ## Invoking the S3 method for class \"glm\" glm1 |> odds_ratio() #>  #> Call:  glm(formula = cbind(pn, qn) ~ iv2 + iv3, family = binomial, data = d) #>  #> Waiting for profiling to be done... #> ____________________________ #> Estimates and Odds Ratios: - #>  #> # A tibble: 3 × 7 #>   parameter   estimate    se p_val odds_ratio ci[,\"2.5%\"] [,\"97.5%\"] sig   #>   <chr>          <dbl> <dbl> <dbl>      <dbl>       <dbl>      <dbl> <fct> #> 1 (Intercept)  -1.82   0.262 0           1         NA          NA    ***   #> 2 iv2h          0.0817 0.248 0.742       1.09       0.669       1.77 NS    #> 3 iv3i          1.57   0.261 0           4.79       2.91        8.11 ***    glm1 |> odds_ratio(.print_call = FALSE, .stat = TRUE, .print_contr = TRUE) #> Waiting for profiling to be done... #> ____________________________ #> Estimates and Odds Ratios: - #>  #> # A tibble: 3 × 8 #>   parameter   estimate    se `z value` p_val odds_ratio ci[,\"2.5%\"] sig   #>   <chr>          <dbl> <dbl>     <dbl> <dbl>      <dbl>       <dbl> <fct> #> 1 (Intercept)  -1.82   0.262    -6.93  0           1         NA     ***   #> 2 iv2h          0.0817 0.248     0.330 0.742       1.09       0.669 NS    #> 3 iv3i          1.57   0.261     6.00  0           4.79       2.91  ***   #> # ℹ 1 more variable: ci[2] <dbl> #> ____________ #> Contrasts: - #>  #> $iv2 #>   h #> g 0 #> h 1 #>  #> $iv3 #>   i #> i 1 #> j 0 #>   ## Compare S3 method for class \"glm\" to that for \"data.frame\" ## — only possible for univariable analyses (d <- binom_data()) #> __________________________ #> Simulated Binomial Data: - #>  #> # A tibble: 5 × 3 #>   iv       pn    qn #> * <fct> <int> <int> #> 1 a        25    41 #> 2 b        27    39 #> 3 c        23    43 #> 4 d        17    49 #> 5 e         5    61  glm(cbind(pn, qn) ~ iv, family = binomial, data = d) |>     odds_ratio() #>  #> Call:  glm(formula = cbind(pn, qn) ~ iv, family = binomial, data = d) #>  #> Waiting for profiling to be done... #> ____________________________ #> Estimates and Odds Ratios: - #>  #> # A tibble: 5 × 7 #>   parameter   estimate    se    p_val odds_ratio ci[,\"2.5%\"] [,\"97.5%\"] sig   #>   <chr>          <dbl> <dbl>    <dbl>      <dbl>       <dbl>      <dbl> <fct> #> 1 (Intercept)   -0.495 0.254 0.0512        1         NA          NA     .     #> 2 ivb            0.127 0.356 0.722         1.14       0.564       2.29  NS    #> 3 ivc           -0.131 0.362 0.718         0.877      0.430       1.78  NS    #> 4 ivd           -0.564 0.379 0.137         0.569      0.267       1.19  NS    #> 5 ive           -2.01  0.530 0.000152      0.134      0.0426      0.353 ***    d |> odds_ratio(.dep_var = cbind(pn, qn), .ind_var = iv) #> Waiting for profiling to be done... #> ____________________________ #> Estimates and Odds Ratios: - #>  #> # A tibble: 5 × 7 #>   parameter   estimate    se    p_val odds_ratio ci[,\"2.5%\"] [,\"97.5%\"] sig   #>   <chr>          <dbl> <dbl>    <dbl>      <dbl>       <dbl>      <dbl> <fct> #> 1 (Intercept)   -0.495 0.254 0.0512        1         NA          NA     .     #> 2 ivb            0.127 0.356 0.722         1.14       0.564       2.29  NS    #> 3 ivc           -0.131 0.362 0.718         0.877      0.430       1.78  NS    #> 4 ivd           -0.564 0.379 0.137         0.569      0.267       1.19  NS    #> 5 ive           -2.01  0.530 0.000152      0.134      0.0426      0.353 ***    ## Helmert contrasts given more easily readable names d |> set_contrasts(iv) <- contr.helmert helm_names(d$iv) <- c(\":\", \"v\") d |> get_contrasts(iv) #>   a v b a:b v c a:c v d a:d v e #> a    -1      -1      -1      -1 #> b     1      -1      -1      -1 #> c     0       2      -1      -1 #> d     0       0       3      -1 #> e     0       0       0       4  ## Add separator as last little tweak ;-) contr_colpfx(d$iv) <- \": \"  glm(cbind(pn, qn) ~ iv, family = binomial, data = d) |>     odds_ratio() #>  #> Call:  glm(formula = cbind(pn, qn) ~ iv, family = binomial, data = d) #>  #> Waiting for profiling to be done... #> ____________________________ #> Estimates and Odds Ratios: - #>  #> # A tibble: 5 × 7 #>   parameter   estimate     se    p_val odds_ratio ci[,\"2.5%\"] [,\"97.5%\"] sig   #>   <chr>          <dbl>  <dbl>    <dbl>      <dbl>       <dbl>      <dbl> <fct> #> 1 (Intercept)  -1.01   0.140  0             1          NA         NA     ***   #> 2 iv: a v b     0.0635 0.178  0.722         1.07        0.751      1.51  NS    #> 3 iv: a:b v c  -0.0648 0.105  0.535         0.937       0.761      1.15  NS    #> 4 iv: a:c v d  -0.141  0.0794 0.0764        0.869       0.740      1.01  .     #> 5 iv: a:d v e  -0.373  0.0966 0.000114      0.689       0.555      0.817 ***    d |> odds_ratio(.dep_var = cbind(pn, qn), .ind_var = iv) #> Waiting for profiling to be done... #> ____________________________ #> Estimates and Odds Ratios: - #>  #> # A tibble: 5 × 7 #>   parameter   estimate     se    p_val odds_ratio ci[,\"2.5%\"] [,\"97.5%\"] sig   #>   <chr>          <dbl>  <dbl>    <dbl>      <dbl>       <dbl>      <dbl> <fct> #> 1 (Intercept)  -1.01   0.140  0             1          NA         NA     ***   #> 2 iv: a v b     0.0635 0.178  0.722         1.07        0.751      1.51  NS    #> 3 iv: a:b v c  -0.0648 0.105  0.535         0.937       0.761      1.15  NS    #> 4 iv: a:c v d  -0.141  0.0794 0.0764        0.869       0.740      1.01  .     #> 5 iv: a:d v e  -0.373  0.0966 0.000114      0.689       0.555      0.817 ***    ## Printing lengthier output with print_all() binom_data(26, 100) |>     odds_ratio(.dep_var = cbind(pn, qn), .ind_var = iv, .print_contr = TRUE) |>     print_all() #> Waiting for profiling to be done... #> ____________________________ #> Estimates and Odds Ratios: - #>  #> # A tibble: 26 × 7 #>    parameter   estimate    se     p_val odds_ratio ci[,\"2.5%\"] [,\"97.5%\"] sig   #>    <chr>          <dbl> <dbl>     <dbl>      <dbl>       <dbl>      <dbl> <fct> #>  1 (Intercept)    0.201 0.201 0.318         1          NA          NA     NS    #>  2 ivb           -0.690 0.288 0.0165        0.501       0.284       0.878 *     #>  3 ivc            0     0.284 1             1           0.572       1.75  NS    #>  4 ivd           -0.241 0.284 0.396         0.786       0.450       1.37  NS    #>  5 ive           -0.483 0.285 0.0904        0.617       0.352       1.08  .     #>  6 ivf           -0.442 0.285 0.121         0.643       0.367       1.12  NS    #>  7 ivg           -0.606 0.286 0.0344        0.545       0.310       0.953 *     #>  8 ivh           -0.733 0.289 0.0111        0.481       0.271       0.843 *     #>  9 ivi           -0.776 0.289 0.00735       0.460       0.259       0.808 **    #> 10 ivj           -0.483 0.285 0.0904        0.617       0.352       1.08  .     #> 11 ivk           -0.864 0.291 0.00304       0.421       0.236       0.743 **    #> 12 ivl           -1.53  0.317 0.0000015     0.217       0.115       0.400 ***   #> 13 ivm           -0.864 0.291 0.00304       0.421       0.236       0.743 **    #> 14 ivn           -0.909 0.293 0.00190       0.403       0.225       0.711 **    #> 15 ivo           -1.25  0.304 0.000041      0.287       0.157       0.517 ***   #> 16 ivp           -1.30  0.306 0.000022      0.273       0.148       0.492 ***   #> 17 ivq           -1.20  0.302 0.0000752     0.303       0.166       0.542 ***   #> 18 ivr           -1.05  0.297 0.000412      0.351       0.194       0.623 ***   #> 19 ivs           -1.53  0.317 0.0000015     0.217       0.115       0.400 ***   #> 20 ivt           -1.86  0.339 0             0.156       0.0782      0.297 ***   #> 21 ivu           -2.29  0.378 0             0.101       0.0462      0.205 ***   #> 22 ivv           -2.10  0.359 0             0.122       0.0585      0.241 ***   #> 23 ivw           -1.59  0.321 0.0000008     0.205       0.107       0.378 ***   #> 24 ivx           -2.19  0.368 0             0.112       0.0523      0.223 ***   #> 25 ivy           -2.40  0.389 0             0.0909      0.0404      0.188 ***   #> 26 ivz           -2.95  0.467 0             0.0522      0.0190      0.122 ***   #> ____________ #> Contrasts: - #>  #> $iv #> [1] \"contr.treatment\" #>   rm(d, glm1)"},{"path":"https://mark-eis.github.io/ParaAnita/reference/plot_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Model Predictions with Error Bars for Univariable GLM — Plot_Model","title":"Plot Model Predictions with Error Bars for Univariable GLM — Plot_Model","text":"S3 method enable ggplot() package ggplot2 plot \"glm_plotdata\" objects ouptut glm_plotdata().","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/plot_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Model Predictions with Error Bars for Univariable GLM — Plot_Model","text":"","code":"# S3 method for glm_plotdata ggplot(   data = NULL,   mapping = aes(),   as_percent = FALSE,   rev_y = FALSE,   ...,   environment = parent.frame() )"},{"path":"https://mark-eis.github.io/ParaAnita/reference/plot_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Model Predictions with Error Bars for Univariable GLM — Plot_Model","text":"data data frame, data frame extension (e.g. tibble). mapping Default list aesthetic mappings use plot. specified, must supplied layer added plot. as_percent logical. TRUE, y-axis uses percentage scale; default FALSE. rev_y logical. TRUE, direction y-axis reversed, may useful plotting linear predictors; default FALSE. ... arguments passed methods. currently used. environment Used prior tidy evaluation.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/plot_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Model Predictions with Error Bars for Univariable GLM — Plot_Model","text":"ggplot object.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/plot_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Model Predictions with Error Bars for Univariable GLM — Plot_Model","text":"S3 method plots model predictions error bars representing confidence intervals standard errors univariable glm categorical independent variable, optionally allowing representation groupings levels independent variable faceting number plots. ggplot.glm_plotdata() recognises factor character column data named grouped plotting grouped levels independent variable grouped within underlying model. levels indeed grouped model, data bars plotted colour-coded borders representing groups, ungrouped observed values contained data column level plotted symbols. ungrouped levels plotted, grouped column contain NA values character column data containing names independent variables used faceting may identified setting attribute \"facet_by\" data. Names variables used faceting may converted informative facet labels using user-defined, vectorised labeller() function named var_labs(), see labeller facet_wrap(). individual plot, rather faceted plot, printed, name independent variable, converted var_labs() (provided), used  plot title. plot title, subtitle axis labels may overridden using usual ggplot() syntax, see examples.","code":""},{"path":[]},{"path":"https://mark-eis.github.io/ParaAnita/reference/plot_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Model Predictions with Error Bars for Univariable GLM — Plot_Model","text":"","code":"## Example uses randomly generated data; re-running may be worthwhile.    oldtheme <- theme_get()   ## Save ggplot defaults for later restoration  ## Set ggplot defaults for pretty printing theme_update(   plot.title = element_text(color = \"black\", size = 20, hjust = 0.5),   plot.subtitle = element_text(color = \"black\", size = 18, hjust = 0.5),   axis.text.x = element_text(color = \"black\", size = 15),   axis.text.y = element_text(color = \"black\", size = 15),   axis.title.x = element_text(color = \"black\", size = 15),   axis.title.y = element_text(color = \"black\", size = 15),   strip.text.x = element_text(color = \"black\", size = 15),   legend.position = \"none\" )  ## \"labeller()\" function to provide plot titles - see var_labs() var_labs <- as_labeller(     c(iv = \"Risk Factor (Ungrouped Levels)\",       iv2 = \"Risk Factor (Grouped Levels)\") )  ## Create binomial data with groupings (d <- list(iv2 = list(ab = c(\"a\", \"b\"), cd = c(\"c\", \"d\"))) |>     add_grps(binom_data(), iv, .key = _)) #> __________________________ #> Simulated Binomial Data: - #>  #> # A tibble: 5 × 4 #>   iv    iv2      pn    qn #>   <fct> <fct> <int> <int> #> 1 a     ab       30    36 #> 2 b     ab       29    37 #> 3 c     cd       19    47 #> 4 d     cd       12    54 #> 5 e     e         4    62  ## Ungrouped GLM plot data on linear predictor scale (dp <- glm_plotdata(d, .dep_var = cbind(pn, qn), .ind_var = iv)) #> ________________ #> GLM Plot Data: - #>  #> # A tibble: 5 × 7 #>   level grouped     n    obs   pred  lower  upper #> * <fct> <fct>   <int>  <dbl>  <dbl>  <dbl>  <dbl> #> 1 a     NA         66 -0.182 -0.182 -0.669  0.304 #> 2 b     NA         66 -0.244 -0.244 -0.732  0.244 #> 3 c     NA         66 -0.906 -0.906 -1.44  -0.371 #> 4 d     NA         66 -1.50  -1.50  -2.13  -0.876 #> 5 e     NA         66 -2.74  -2.74  -3.76  -1.73   ## Plot model predictions and CI error bars dp |> ggplot()   ## Plot model predictions and CI error bars with reversed y-axis dp |> ggplot(rev_y = TRUE)   ## Grouped GLM plot data on linear predictor scale (dp <- glm_plotdata(d, .dep_var = cbind(pn, qn), .ind_var = iv2, .ungroup = iv)) #> ________________ #> GLM Plot Data: - #>  #> # A tibble: 5 × 7 #>   level grouped     n    obs   pred  lower  upper #> * <fct> <fct>   <int>  <dbl>  <dbl>  <dbl>  <dbl> #> 1 a     ab         66 -0.182 -0.213 -0.557  0.131 #> 2 b     ab         66 -0.244 -0.213 -0.557  0.131 #> 3 c     cd         66 -0.906 -1.18  -1.59  -0.777 #> 4 d     cd         66 -1.50  -1.18  -1.59  -0.777 #> 5 e     e          66 -2.74  -2.74  -3.76  -1.73   ## Plot model predictions and CI error bars with reversed y-axis dp |> ggplot(rev_y = TRUE)   ## Ungrouped GLM plot data on reponse scale (dp <- glm_plotdata(d, .dep_var = cbind(pn, qn), .ind_var = iv, type = \"response\")) #> ________________ #> GLM Plot Data: - #>  #> # A tibble: 5 × 7 #>   level grouped     n    obs   pred  lower upper #> * <fct> <fct>   <int>  <dbl>  <dbl>  <dbl> <dbl> #> 1 a     NA         66 0.455  0.455  0.339  0.575 #> 2 b     NA         66 0.439  0.439  0.325  0.561 #> 3 c     NA         66 0.288  0.288  0.191  0.408 #> 4 d     NA         66 0.182  0.182  0.106  0.294 #> 5 e     NA         66 0.0606 0.0606 0.0229 0.151  ## Plot model predictions and CI error bars dp |> ggplot()   ## Plot model predictions and CI error bars, with y-axis as percentage dp |> ggplot(as_percent = TRUE)   ## Grouped GLM plot data on reponse scale (dp <- glm_plotdata(d, .dep_var = cbind(pn, qn), .ind_var = iv2, .ungroup = iv, type = \"response\")) #> ________________ #> GLM Plot Data: - #>  #> # A tibble: 5 × 7 #>   level grouped     n    obs   pred  lower upper #> * <fct> <fct>   <int>  <dbl>  <dbl>  <dbl> <dbl> #> 1 a     ab         66 0.455  0.447  0.364  0.533 #> 2 b     ab         66 0.439  0.447  0.364  0.533 #> 3 c     cd         66 0.288  0.235  0.170  0.315 #> 4 d     cd         66 0.182  0.235  0.170  0.315 #> 5 e     e          66 0.0606 0.0606 0.0229 0.151  ## Plot model predictions and CI error bars dp |> ggplot(as_percent = TRUE)   ## Grouped GLM plot data on reponse scale with standard errors  (dp <- glm_plotdata(                     d, .dep_var = cbind(pn, qn), .ind_var = iv2,                     .ungroup = iv, conf_level = NA, type = \"response\"                    )) #> ________________ #> GLM Plot Data: - #>  #> # A tibble: 5 × 7 #>   level grouped     n    obs   pred  lower  upper #> * <fct> <fct>   <int>  <dbl>  <dbl>  <dbl>  <dbl> #> 1 a     ab         66 0.455  0.447  0.404  0.491  #> 2 b     ab         66 0.439  0.447  0.404  0.491  #> 3 c     cd         66 0.288  0.235  0.200  0.274  #> 4 d     cd         66 0.182  0.235  0.200  0.274  #> 5 e     e          66 0.0606 0.0606 0.0371 0.0975  ## Plot model predictions and standard error bars dp |> ggplot(as_percent = TRUE)   ## Add x-axis label and bespoke titles dp |> ggplot(as_percent = TRUE) + labs(     x = \"Level\",     title = \"Example for ggplot.glm_plotdata()\",     subtitle = \"Fascinating Results\" )   theme_set(oldtheme)    ## Restore original ggplot defaults rm(d, dp, oldtheme)"},{"path":"https://mark-eis.github.io/ParaAnita/reference/print_all.html","id":null,"dir":"Reference","previous_headings":"","what":"Print All (or More) of an Object — print_all","title":"Print All (or More) of an Object — print_all","text":"print_all() generic function extended printing object, instance printing rows tibble, derived class even regular data frame, optionally following printing specified number linefeeds. generic function, new printing methods can easily added new class.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/print_all.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print All (or More) of an Object — print_all","text":"","code":"print_all(x, ...)  # S3 method for data.frame print_all(   x,   linefeeds = NULL,   ...,   digits = NULL,   quote = FALSE,   right = TRUE,   row.names = TRUE,   max = NULL )  # S3 method for tbl print_all(   x,   linefeeds = NULL,   width = NULL,   ...,   max_extra_cols = NULL,   max_footer_lines = NULL )  # S3 method for tbl_df print_all(   x,   linefeeds = NULL,   width = NULL,   ...,   max_extra_cols = NULL,   max_footer_lines = NULL )  # S3 method for odds_ratio print_all(x, linefeeds = NULL, ...)  # S3 method for htest print_all(x, ...)"},{"path":"https://mark-eis.github.io/ParaAnita/reference/print_all.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print All (or More) of an Object — print_all","text":"x object tibble data frame. ... arguments passed methods. linefeeds positive integer specifying number linefeeds follow printed output; default NULL. digits minimal number significant digits, see     print.default. quote logical, indicating whether strings     printed surrounding quotes. right logical, indicating whether strings     right aligned. row.names logical (character vector), indicating whether (    ) row names printed. max numeric NULL, specifying maximal number     entries printed.  default, NULL,     getOption(\"max.print\") used. width used max.levels NULL, see . max_extra_cols Number extra columns print abbreviated information , width small entire tibble. NULL, max_extra_cols option used. previously defined n_extra argument soft-deprecated. max_footer_lines Maximum number footer lines. NULL, max_footer_lines option used.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/print_all.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print All (or More) of an Object — print_all","text":"Invisibly returns argument.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/print_all.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print All (or More) of an Object — print_all","text":"tibble x, print_all(x) equivalent print(x, n = nrow(x)), followed required n linefeeds generated using cat(rep(\"\\n\", n)). linefeeds argument may useful within piped sequence separate output subsequent printing. vector length > 1 entered linefeeds, first element used, negative integers converted zero .e., line feeds.","code":""},{"path":[]},{"path":"https://mark-eis.github.io/ParaAnita/reference/print_all.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print All (or More) of an Object — print_all","text":"","code":"(tib <- tibble(x = 1:26, y = LETTERS[x], z = paste0(x, y))) #> # A tibble: 26 × 3 #>        x y     z     #>    <int> <chr> <chr> #>  1     1 A     1A    #>  2     2 B     2B    #>  3     3 C     3C    #>  4     4 D     4D    #>  5     5 E     5E    #>  6     6 F     6F    #>  7     7 G     7G    #>  8     8 H     8H    #>  9     9 I     9I    #> 10    10 J     10J   #> # ℹ 16 more rows tib |> print_all() #> # A tibble: 26 × 3 #>        x y     z     #>    <int> <chr> <chr> #>  1     1 A     1A    #>  2     2 B     2B    #>  3     3 C     3C    #>  4     4 D     4D    #>  5     5 E     5E    #>  6     6 F     6F    #>  7     7 G     7G    #>  8     8 H     8H    #>  9     9 I     9I    #> 10    10 J     10J   #> 11    11 K     11K   #> 12    12 L     12L   #> 13    13 M     13M   #> 14    14 N     14N   #> 15    15 O     15O   #> 16    16 P     16P   #> 17    17 Q     17Q   #> 18    18 R     18R   #> 19    19 S     19S   #> 20    20 T     20T   #> 21    21 U     21U   #> 22    22 V     22V   #> 23    23 W     23W   #> 24    24 X     24X   #> 25    25 Y     25Y   #> 26    26 Z     26Z   tib |> print_all() |> names() #> # A tibble: 26 × 3 #>        x y     z     #>    <int> <chr> <chr> #>  1     1 A     1A    #>  2     2 B     2B    #>  3     3 C     3C    #>  4     4 D     4D    #>  5     5 E     5E    #>  6     6 F     6F    #>  7     7 G     7G    #>  8     8 H     8H    #>  9     9 I     9I    #> 10    10 J     10J   #> 11    11 K     11K   #> 12    12 L     12L   #> 13    13 M     13M   #> 14    14 N     14N   #> 15    15 O     15O   #> 16    16 P     16P   #> 17    17 Q     17Q   #> 18    18 R     18R   #> 19    19 S     19S   #> 20    20 T     20T   #> 21    21 U     21U   #> 22    22 V     22V   #> 23    23 W     23W   #> 24    24 X     24X   #> 25    25 Y     25Y   #> 26    26 Z     26Z   #> [1] \"x\" \"y\" \"z\" tib |> print_all(linefeeds = 3) |> names() #> # A tibble: 26 × 3 #>        x y     z     #>    <int> <chr> <chr> #>  1     1 A     1A    #>  2     2 B     2B    #>  3     3 C     3C    #>  4     4 D     4D    #>  5     5 E     5E    #>  6     6 F     6F    #>  7     7 G     7G    #>  8     8 H     8H    #>  9     9 I     9I    #> 10    10 J     10J   #> 11    11 K     11K   #> 12    12 L     12L   #> 13    13 M     13M   #> 14    14 N     14N   #> 15    15 O     15O   #> 16    16 P     16P   #> 17    17 Q     17Q   #> 18    18 R     18R   #> 19    19 S     19S   #> 20    20 T     20T   #> 21    21 U     21U   #> 22    22 V     22V   #> 23    23 W     23W   #> 24    24 X     24X   #> 25    25 Y     25Y   #> 26    26 Z     26Z   #>  #>   #>   #> [1] \"x\" \"y\" \"z\"  df <- tib |> as.data.frame() df |> print_all()                         ## Does nothing more than regular print() #>     x y   z #> 1   1 A  1A #> 2   2 B  2B #> 3   3 C  3C #> 4   4 D  4D #> 5   5 E  5E #> 6   6 F  6F #> 7   7 G  7G #> 8   8 H  8H #> 9   9 I  9I #> 10 10 J 10J #> 11 11 K 11K #> 12 12 L 12L #> 13 13 M 13M #> 14 14 N 14N #> 15 15 O 15O #> 16 16 P 16P #> 17 17 Q 17Q #> 18 18 R 18R #> 19 19 S 19S #> 20 20 T 20T #> 21 21 U 21U #> 22 22 V 22V #> 23 23 W 23W #> 24 24 X 24X #> 25 25 Y 25Y #> 26 26 Z 26Z df |> print_all(linefeeds = 2) |> names() ## Regular data frame printing, with line feeds #>     x y   z #> 1   1 A  1A #> 2   2 B  2B #> 3   3 C  3C #> 4   4 D  4D #> 5   5 E  5E #> 6   6 F  6F #> 7   7 G  7G #> 8   8 H  8H #> 9   9 I  9I #> 10 10 J 10J #> 11 11 K 11K #> 12 12 L 12L #> 13 13 M 13M #> 14 14 N 14N #> 15 15 O 15O #> 16 16 P 16P #> 17 17 Q 17Q #> 18 18 R 18R #> 19 19 S 19S #> 20 20 T 20T #> 21 21 U 21U #> 22 22 V 22V #> 23 23 W 23W #> 24 24 X 24X #> 25 25 Y 25Y #> 26 26 Z 26Z #>  #>   #> [1] \"x\" \"y\" \"z\"  binom_data(26, 100) |>     odds_ratio(.dep_var = cbind(pn, qn), .ind_var = iv) |>     print_all() #> Waiting for profiling to be done... #> ____________________________ #> Estimates and Odds Ratios: - #>  #> # A tibble: 26 × 7 #>    parameter   estimate    se     p_val odds_ratio ci[,\"2.5%\"] [,\"97.5%\"] sig   #>    <chr>          <dbl> <dbl>     <dbl>      <dbl>       <dbl>      <dbl> <fct> #>  1 (Intercept)   0.160  0.201 0.424         1          NA          NA     NS    #>  2 ivb          -0.0402 0.284 0.887         0.961       0.550       1.68  NS    #>  3 ivc          -0.650  0.288 0.0238        0.522       0.296       0.914 *     #>  4 ivd          -0.524  0.286 0.0664        0.592       0.337       1.03  .     #>  5 ive          -0.240  0.283 0.396         0.786       0.450       1.37  NS    #>  6 ivf          -0.608  0.287 0.0342        0.545       0.309       0.953 *     #>  7 ivg          -0.483  0.285 0.0902        0.617       0.351       1.08  .     #>  8 ivh          -0.869  0.292 0.00297       0.420       0.235       0.740 **    #>  9 ivi          -0.608  0.287 0.0342        0.545       0.309       0.953 *     #> 10 ivj          -1.01   0.296 0.000676      0.365       0.202       0.649 ***   #> 11 ivk          -0.693  0.288 0.0163        0.500       0.283       0.877 *     #> 12 ivl          -1.37   0.311 0.0000108     0.254       0.136       0.463 ***   #> 13 ivm          -1.15   0.302 0.000129      0.315       0.173       0.565 ***   #> 14 ivn          -1.15   0.302 0.000129      0.315       0.173       0.565 ***   #> 15 ivo          -1.21   0.304 0.0000713     0.299       0.163       0.538 ***   #> 16 ivp          -1.31   0.308 0.0000206     0.269       0.145       0.487 ***   #> 17 ivq          -1.49   0.317 0.0000028     0.226       0.120       0.416 ***   #> 18 ivr          -0.869  0.292 0.00297       0.420       0.235       0.740 **    #> 19 ivs          -1.75   0.333 0.0000002     0.174       0.0887      0.330 ***   #> 20 ivt          -1.61   0.324 0.0000007     0.200       0.104       0.372 ***   #> 21 ivu          -1.43   0.314 0.0000055     0.240       0.128       0.439 ***   #> 22 ivv          -1.75   0.333 0.0000002     0.174       0.0887      0.330 ***   #> 23 ivw          -2.47   0.403 0             0.0842      0.0361      0.178 ***   #> 24 ivx          -2.15   0.367 0             0.116       0.0544      0.232 ***   #> 25 ivy          -2.15   0.367 0             0.116       0.0544      0.232 ***   #> 26 ivz          -2.25   0.377 0             0.105       0.0481      0.214 ***    rm(df, tib)"},{"path":"https://mark-eis.github.io/ParaAnita/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. dplyr count, mutate, rename forcats fct_count, fct_recode ggplot2 as_labeller, element_text, ggplot, labs, theme_get, theme_set, theme_update purrr list_rbind, list_transpose, map_chr, map_dbl, map_int, map2, map2_chr rlang %@%, %|%, %||%, eval_tidy, exprs, set_names stringr str_to_title tibble tibble tidyselect all_of, any_of, contains, ends_with, everything, last_col, matches, num_range, starts_with, ","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/rm_objects.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove Sequentially Numbered Objects from Workspace — rm_objects","title":"Remove Sequentially Numbered Objects from Workspace — rm_objects","text":"Remove series sequentially named objects workspace another specified environment. example, conveniently remove series sequentially numbered models.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/rm_objects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove Sequentially Numbered Objects from Workspace — rm_objects","text":"","code":"rm_objects(basename, suffixes, envir = parent.frame())"},{"path":"https://mark-eis.github.io/ParaAnita/reference/rm_objects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove Sequentially Numbered Objects from Workspace — rm_objects","text":"basename Common base name (quoted) series objects. suffixes numeric character vector representing suffixes series objects. envir environment remove objects. Use .GlobalEnv workspace; default parent.frame() .e., environment rm_objects() called.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/rm_objects.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove Sequentially Numbered Objects from Workspace — rm_objects","text":"character vector matching names remaining calling environment, usually workspace unless rm_objects() called within function, another specified environment, returned invisibly.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/rm_objects.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Remove Sequentially Numbered Objects from Workspace — rm_objects","text":"rm_objects() lists objects workspace (another specified  environment) whose names start basename, removes basename followed element included suffixes, finally lists remaining objects names matching basename. #GF","code":""},{"path":[]},{"path":"https://mark-eis.github.io/ParaAnita/reference/rm_objects.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remove Sequentially Numbered Objects from Workspace — rm_objects","text":"","code":"## Note: running outside example() will be more informative   ## Create some sequentially numbered objects  model1 <- model2 <- model3 <- model4 <- lm(1~1)  ls(pattern = \"model\") #> [1] \"model1\" \"model2\" \"model3\" \"model4\"   ## Remove three of them  rm_objects(model, 1:3) #> Objects matching \"model…\" found in (unnamed) environment: – #> \t model1 model2 model3 model4  #> Objects matching \"model…\" remaining in (unnamed) environment: – #> \t model4    ## Create some sequentially named objects  model_a <- model_b <- model_c <- model_d <- lm(1~1)  ls(pattern = \"model_\") #> [1] \"model_a\" \"model_b\" \"model_c\" \"model_d\"   ## Remove three of them  rm_objects(model_, letters[1:3]) #> Objects matching \"model_…\" found in (unnamed) environment: – #> \t model_a model_b model_c model_d  #> Objects matching \"model_…\" remaining in (unnamed) environment: – #> \t model_d    ## Use within a function  (\\() {                  ## Anonymous function, but doesn't have to be    model1 <- model2 <- model3 <- model4 <- model5 <- lm(1~1)    rm_objects(model, 1:5)  })() #> Objects matching \"model…\" found in (unnamed) environment: – #> \t model1 model2 model3 model4 model5  #> Objects matching \"model…\" remaining in (unnamed) environment: – #> \t All gone!    ls(pattern = \"model\") #> [1] \"model4\"  \"model_d\"   rm_objects(model, c(4, \"_d\")) #> Objects matching \"model…\" found in (unnamed) environment: – #> \t model4 model_d  #> Objects matching \"model…\" remaining in (unnamed) environment: – #> \t All gone!"},{"path":"https://mark-eis.github.io/ParaAnita/reference/starsig.html","id":null,"dir":"Reference","previous_headings":"","what":"Stars for Statistical Significance — starsig","title":"Stars for Statistical Significance — starsig","text":"Stars statistical significance levels usual R. vectorised function.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/starsig.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stars for Statistical Significance — starsig","text":"","code":"starsig(p)"},{"path":"https://mark-eis.github.io/ParaAnita/reference/starsig.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stars for Statistical Significance — starsig","text":"p numeric vector probabilities.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/starsig.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stars for Statistical Significance — starsig","text":"character vector, length p.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/starsig.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stars for Statistical Significance — starsig","text":"","code":"(test_seq <- c(0.0003, 0.0010, 0.0032, 0.0100, 0.0316, 0.0500, 0.0631, 0.1000, 0.3162)) #> [1] 0.0003 0.0010 0.0032 0.0100 0.0316 0.0500 0.0631 0.1000 0.3162 starsig(test_seq) #> [1] *** **  **  *   *   .   .   NS  NS  #> Levels: *** ** * . NS rbind(test_seq, as.character(starsig(test_seq))) #>          [,1]    [,2]    [,3]     [,4]   [,5]     [,6]   [,7]     [,8]  #> test_seq \"3e-04\" \"0.001\" \"0.0032\" \"0.01\" \"0.0316\" \"0.05\" \"0.0631\" \"0.1\" #>          \"***\"   \"**\"    \"**\"     \"*\"    \"*\"      \".\"    \".\"      \"NS\"  #>          [,9]     #> test_seq \"0.3162\" #>          \"NS\"     data.frame(val = test_seq, sig = starsig(test_seq)) #>      val sig #> 1 0.0003 *** #> 2 0.0010  ** #> 3 0.0032  ** #> 4 0.0100   * #> 5 0.0316   * #> 6 0.0500   . #> 7 0.0631   . #> 8 0.1000  NS #> 9 0.3162  NS  rm(test_seq)"},{"path":"https://mark-eis.github.io/ParaAnita/reference/summanov.html","id":null,"dir":"Reference","previous_headings":"","what":"List of Summary and Analysis of Deviance Objects for Related Univariable GLMs — summanov","title":"List of Summary and Analysis of Deviance Objects for Related Univariable GLMs — summanov","text":"summanov() provides list summary analysis deviance objects series related univariable GLMs data binary dependent variable (two-column) dependent variable binomial proportions.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/summanov.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List of Summary and Analysis of Deviance Objects for Related Univariable GLMs — summanov","text":"","code":"summanov(data, .dep_var, ..., .family = binomial, .test = \"Chisq\")"},{"path":"https://mark-eis.github.io/ParaAnita/reference/summanov.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List of Summary and Analysis of Deviance Objects for Related Univariable GLMs — summanov","text":"data data frame, data frame extension (e.g. tibble). .dep_var <data-masking> quoted name binary dependent variable used LHS model formula; numeric values 0 1, two-column matrix columns giving numbers successes failures e.g., cbind(pn, qn). ... <tidy-select> quoted name(s) one factors character vectors .data, included (excluded)  independent variables list GLM analyses. .family description error distribution link function used model. Can character string naming family function, family function result call family function; default binomial. .test character string, (partially) matching one \"Chisq\", \"LRT\", \"Rao\", \"F\" \"Cp\"; default \"Chisq\".","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/summanov.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List of Summary and Analysis of Deviance Objects for Related Univariable GLMs — summanov","text":"list summ_anov objects length equal number factors character vectors selected using ... arguments. summ_anov object simply list class \"summ_anov\", comprising following two elements: - summary Summary generalised linear model fit given summary.glm. anova Analysis deviance generalised linear model fit given anova.glm.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/summanov.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"List of Summary and Analysis of Deviance Objects for Related Univariable GLMs — summanov","text":"Variables .data included (excluded)  independent variables list GLM analyses may selected using ... argument <tidy-select> syntax package dplyr, including use selection helpers. structure output list may changed list pairs pair lists conveniently using list_transpose. univariable GLMs may easily compared likewise univariable GLM anovas (analysis deviance). univ_anova provides succinct summmary univariable analyses deviance potential categorical independent variables data. anova_tbl also provides succinct summmary list anovas.","code":""},{"path":[]},{"path":"https://mark-eis.github.io/ParaAnita/reference/summanov.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"List of Summary and Analysis of Deviance Objects for Related Univariable GLMs — summanov","text":"","code":"## Simulate Bernoulli data (d <- list(     iv2 = list(g = c(\"a\", \"c\", \"e\"), h = c(\"b\", \"d\", \"f\")),     iv3 = list(i = c(\"a\", \"b\", \"c\"), j = c(\"d\", \"e\", \"f\")),     iv4 = list(k = c(\"a\", \"b\"), l = c(\"c\", \"d\"), m = c(\"e\", \"f\")) ) |> add_grps(bernoulli_data(levels = 6), iv, .key = _)) #> ___________________________ #> Simulated Bernoulli Data: - #>  #> # A tibble: 396 × 5 #>    iv    iv2   iv3   iv4      dv #>    <fct> <fct> <fct> <fct> <int> #>  1 a     g     i     k         0 #>  2 a     g     i     k         1 #>  3 a     g     i     k         0 #>  4 a     g     i     k         1 #>  5 a     g     i     k         0 #>  6 a     g     i     k         0 #>  7 a     g     i     k         0 #>  8 a     g     i     k         0 #>  9 a     g     i     k         1 #> 10 a     g     i     k         0 #> # ℹ 386 more rows  ## Binary dependent variable d |> summanov(dv, starts_with(\"iv\")) #> _______________________________________ #> GLM Summary and Analysis of Deviance: - #>  #> $iv #> ______________ #> GLM Summary: - #>  #>  #> Call: #> glm(formula = inject(!!.dep_var ~ !!sym(x)), family = .family,  #>     data = data) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)  0.12136    0.24664   0.492 0.622674     #> ivb         -0.06074    0.34856  -0.174 0.861668     #> ivc         -0.74707    0.35716  -2.092 0.036467 *   #> ivd         -0.95427    0.36410  -2.621 0.008770 **  #> ive         -1.34514    0.38354  -3.507 0.000453 *** #> ivf         -2.86220    0.57180  -5.006 5.57e-07 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 502.72  on 395  degrees of freedom #> Residual deviance: 449.92  on 390  degrees of freedom #> AIC: 461.92 #>  #> Number of Fisher Scoring iterations: 5 #>  #> ____________ #> GLM Anova: - #>  #> Analysis of Deviance Table #>  #> Model: binomial, link: logit #>  #> Response: dv #>  #> Terms added sequentially (first to last) #>  #>  #>      Df Deviance Resid. Df Resid. Dev  Pr(>Chi)     #> NULL                   395     502.72               #> iv    5   52.799       390     449.92 3.698e-10 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> $iv2 #> ______________ #> GLM Summary: - #>  #>  #> Call: #> glm(formula = inject(!!.dep_var ~ !!sym(x)), family = .family,  #>     data = data) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)  -0.5379     0.1473  -3.651 0.000261 *** #> iv2h         -0.3433     0.2147  -1.599 0.109728     #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 502.72  on 395  degrees of freedom #> Residual deviance: 500.15  on 394  degrees of freedom #> AIC: 504.15 #>  #> Number of Fisher Scoring iterations: 4 #>  #> ____________ #> GLM Anova: - #>  #> Analysis of Deviance Table #>  #> Model: binomial, link: logit #>  #> Response: dv #>  #> Terms added sequentially (first to last) #>  #>  #>      Df Deviance Resid. Df Resid. Dev Pr(>Chi) #> NULL                   395     502.72          #> iv2   1   2.5708       394     500.15   0.1088 #>  #> $iv3 #> ______________ #> GLM Summary: - #>  #>  #> Call: #> glm(formula = inject(!!.dep_var ~ !!sym(x)), family = .family,  #>     data = data) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)  -0.1417     0.1425  -0.994     0.32     #> iv3j         -1.2637     0.2285  -5.529 3.22e-08 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 502.72  on 395  degrees of freedom #> Residual deviance: 469.98  on 394  degrees of freedom #> AIC: 473.98 #>  #> Number of Fisher Scoring iterations: 4 #>  #> ____________ #> GLM Anova: - #>  #> Analysis of Deviance Table #>  #> Model: binomial, link: logit #>  #> Response: dv #>  #> Terms added sequentially (first to last) #>  #>  #>      Df Deviance Resid. Df Resid. Dev  Pr(>Chi)     #> NULL                   395     502.72               #> iv3   1   32.742       394     469.98 1.053e-08 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> $iv4 #> ______________ #> GLM Summary: - #>  #>  #> Call: #> glm(formula = inject(!!.dep_var ~ !!sym(x)), family = .family,  #>     data = data) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)  0.09097    0.17426   0.522  0.60163     #> iv4l        -0.81841    0.25467  -3.214  0.00131 **  #> iv4m        -1.87392    0.30306  -6.183 6.28e-10 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 502.72  on 395  degrees of freedom #> Residual deviance: 458.12  on 393  degrees of freedom #> AIC: 464.12 #>  #> Number of Fisher Scoring iterations: 4 #>  #> ____________ #> GLM Anova: - #>  #> Analysis of Deviance Table #>  #> Model: binomial, link: logit #>  #> Response: dv #>  #> Terms added sequentially (first to last) #>  #>  #>      Df Deviance Resid. Df Resid. Dev  Pr(>Chi)     #> NULL                   395     502.72               #> iv4   2   44.603       393     458.12 2.063e-10 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  d |> summanov(dv, starts_with(\"iv\") & !iv2) #> _______________________________________ #> GLM Summary and Analysis of Deviance: - #>  #> $iv #> ______________ #> GLM Summary: - #>  #>  #> Call: #> glm(formula = inject(!!.dep_var ~ !!sym(x)), family = .family,  #>     data = data) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)  0.12136    0.24664   0.492 0.622674     #> ivb         -0.06074    0.34856  -0.174 0.861668     #> ivc         -0.74707    0.35716  -2.092 0.036467 *   #> ivd         -0.95427    0.36410  -2.621 0.008770 **  #> ive         -1.34514    0.38354  -3.507 0.000453 *** #> ivf         -2.86220    0.57180  -5.006 5.57e-07 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 502.72  on 395  degrees of freedom #> Residual deviance: 449.92  on 390  degrees of freedom #> AIC: 461.92 #>  #> Number of Fisher Scoring iterations: 5 #>  #> ____________ #> GLM Anova: - #>  #> Analysis of Deviance Table #>  #> Model: binomial, link: logit #>  #> Response: dv #>  #> Terms added sequentially (first to last) #>  #>  #>      Df Deviance Resid. Df Resid. Dev  Pr(>Chi)     #> NULL                   395     502.72               #> iv    5   52.799       390     449.92 3.698e-10 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> $iv3 #> ______________ #> GLM Summary: - #>  #>  #> Call: #> glm(formula = inject(!!.dep_var ~ !!sym(x)), family = .family,  #>     data = data) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)  -0.1417     0.1425  -0.994     0.32     #> iv3j         -1.2637     0.2285  -5.529 3.22e-08 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 502.72  on 395  degrees of freedom #> Residual deviance: 469.98  on 394  degrees of freedom #> AIC: 473.98 #>  #> Number of Fisher Scoring iterations: 4 #>  #> ____________ #> GLM Anova: - #>  #> Analysis of Deviance Table #>  #> Model: binomial, link: logit #>  #> Response: dv #>  #> Terms added sequentially (first to last) #>  #>  #>      Df Deviance Resid. Df Resid. Dev  Pr(>Chi)     #> NULL                   395     502.72               #> iv3   1   32.742       394     469.98 1.053e-08 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> $iv4 #> ______________ #> GLM Summary: - #>  #>  #> Call: #> glm(formula = inject(!!.dep_var ~ !!sym(x)), family = .family,  #>     data = data) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)  0.09097    0.17426   0.522  0.60163     #> iv4l        -0.81841    0.25467  -3.214  0.00131 **  #> iv4m        -1.87392    0.30306  -6.183 6.28e-10 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 502.72  on 395  degrees of freedom #> Residual deviance: 458.12  on 393  degrees of freedom #> AIC: 464.12 #>  #> Number of Fisher Scoring iterations: 4 #>  #> ____________ #> GLM Anova: - #>  #> Analysis of Deviance Table #>  #> Model: binomial, link: logit #>  #> Response: dv #>  #> Terms added sequentially (first to last) #>  #>  #>      Df Deviance Resid. Df Resid. Dev  Pr(>Chi)     #> NULL                   395     502.72               #> iv4   2   44.603       393     458.12 2.063e-10 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ## Binomial proportions (d <- d |> binom_contingency(dv, starts_with(\"iv\"))) #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 6 × 6 #>   iv    iv2   iv3   iv4      pn    qn #> * <fct> <fct> <fct> <fct> <int> <int> #> 1 a     g     i     k        35    31 #> 2 b     h     i     k        34    32 #> 3 c     g     i     l        23    43 #> 4 d     h     j     l        20    46 #> 5 e     g     j     m        15    51 #> 6 f     h     j     m         4    62  (uva <- d |> summanov(cbind(pn, qn), num_range(\"iv\", 2:4))) #> _______________________________________ #> GLM Summary and Analysis of Deviance: - #>  #> $iv2 #> ______________ #> GLM Summary: - #>  #>  #> Call: #> glm(formula = inject(!!.dep_var ~ !!sym(x)), family = .family,  #>     data = data) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)  -0.5379     0.1473  -3.651 0.000261 *** #> iv2h         -0.3433     0.2147  -1.599 0.109728     #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 52.799  on 5  degrees of freedom #> Residual deviance: 50.228  on 4  degrees of freedom #> AIC: 80.06 #>  #> Number of Fisher Scoring iterations: 4 #>  #> ____________ #> GLM Anova: - #>  #> Analysis of Deviance Table #>  #> Model: binomial, link: logit #>  #> Response: cbind(pn, qn) #>  #> Terms added sequentially (first to last) #>  #>  #>      Df Deviance Resid. Df Resid. Dev Pr(>Chi) #> NULL                     5     52.799          #> iv2   1   2.5708         4     50.228   0.1088 #>  #> $iv3 #> ______________ #> GLM Summary: - #>  #>  #> Call: #> glm(formula = inject(!!.dep_var ~ !!sym(x)), family = .family,  #>     data = data) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)  -0.1417     0.1425  -0.994     0.32     #> iv3j         -1.2637     0.2285  -5.529 3.22e-08 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 52.799  on 5  degrees of freedom #> Residual deviance: 20.058  on 4  degrees of freedom #> AIC: 49.89 #>  #> Number of Fisher Scoring iterations: 4 #>  #> ____________ #> GLM Anova: - #>  #> Analysis of Deviance Table #>  #> Model: binomial, link: logit #>  #> Response: cbind(pn, qn) #>  #> Terms added sequentially (first to last) #>  #>  #>      Df Deviance Resid. Df Resid. Dev  Pr(>Chi)     #> NULL                     5     52.799               #> iv3   1   32.742         4     20.058 1.053e-08 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> $iv4 #> ______________ #> GLM Summary: - #>  #>  #> Call: #> glm(formula = inject(!!.dep_var ~ !!sym(x)), family = .family,  #>     data = data) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)  0.09097    0.17426   0.522  0.60163     #> iv4l        -0.81841    0.25467  -3.214  0.00131 **  #> iv4m        -1.87392    0.30306  -6.183 6.28e-10 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 52.7992  on 5  degrees of freedom #> Residual deviance:  8.1962  on 3  degrees of freedom #> AIC: 40.028 #>  #> Number of Fisher Scoring iterations: 4 #>  #> ____________ #> GLM Anova: - #>  #> Analysis of Deviance Table #>  #> Model: binomial, link: logit #>  #> Response: cbind(pn, qn) #>  #> Terms added sequentially (first to last) #>  #>  #>      Df Deviance Resid. Df Resid. Dev  Pr(>Chi)     #> NULL                     5     52.799               #> iv4   2   44.603         3      8.196 2.063e-10 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ## Change list of pairs into a pair of lists using {purrr} list_transpose() list_transpose(uva)$summary #> $iv2 #> ______________ #> GLM Summary: - #>  #>  #> Call: #> glm(formula = inject(!!.dep_var ~ !!sym(x)), family = .family,  #>     data = data) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)  -0.5379     0.1473  -3.651 0.000261 *** #> iv2h         -0.3433     0.2147  -1.599 0.109728     #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 52.799  on 5  degrees of freedom #> Residual deviance: 50.228  on 4  degrees of freedom #> AIC: 80.06 #>  #> Number of Fisher Scoring iterations: 4 #>  #>  #> $iv3 #> ______________ #> GLM Summary: - #>  #>  #> Call: #> glm(formula = inject(!!.dep_var ~ !!sym(x)), family = .family,  #>     data = data) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)  -0.1417     0.1425  -0.994     0.32     #> iv3j         -1.2637     0.2285  -5.529 3.22e-08 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 52.799  on 5  degrees of freedom #> Residual deviance: 20.058  on 4  degrees of freedom #> AIC: 49.89 #>  #> Number of Fisher Scoring iterations: 4 #>  #>  #> $iv4 #> ______________ #> GLM Summary: - #>  #>  #> Call: #> glm(formula = inject(!!.dep_var ~ !!sym(x)), family = .family,  #>     data = data) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)  0.09097    0.17426   0.522  0.60163     #> iv4l        -0.81841    0.25467  -3.214  0.00131 **  #> iv4m        -1.87392    0.30306  -6.183 6.28e-10 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 52.7992  on 5  degrees of freedom #> Residual deviance:  8.1962  on 3  degrees of freedom #> AIC: 40.028 #>  #> Number of Fisher Scoring iterations: 4 #>  #>   list_transpose(uva)$anova #> $iv2 #> ____________ #> GLM Anova: - #>  #> Analysis of Deviance Table #>  #> Model: binomial, link: logit #>  #> Response: cbind(pn, qn) #>  #> Terms added sequentially (first to last) #>  #>  #>      Df Deviance Resid. Df Resid. Dev Pr(>Chi) #> NULL                     5     52.799          #> iv2   1   2.5708         4     50.228   0.1088 #>  #> $iv3 #> ____________ #> GLM Anova: - #>  #> Analysis of Deviance Table #>  #> Model: binomial, link: logit #>  #> Response: cbind(pn, qn) #>  #> Terms added sequentially (first to last) #>  #>  #>      Df Deviance Resid. Df Resid. Dev  Pr(>Chi)     #> NULL                     5     52.799               #> iv3   1   32.742         4     20.058 1.053e-08 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> $iv4 #> ____________ #> GLM Anova: - #>  #> Analysis of Deviance Table #>  #> Model: binomial, link: logit #>  #> Response: cbind(pn, qn) #>  #> Terms added sequentially (first to last) #>  #>  #>      Df Deviance Resid. Df Resid. Dev  Pr(>Chi)     #> NULL                     5     52.799               #> iv4   2   44.603         3      8.196 2.063e-10 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   rm(d, uva)"},{"path":"https://mark-eis.github.io/ParaAnita/reference/tidyeval.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy eval helpers — tidyeval","title":"Tidy eval helpers — tidyeval","text":"page lists tidy eval tools reexported package rlang. learn using tidy eval scripts packages high level, see dplyr programming vignette ggplot2 packages vignette. Metaprogramming section Advanced R may also useful deeper dive. tidy eval operators {{, !!, !!! syntactic constructs specially interpreted tidy eval functions. mostly need {{, !! !!! advanced operators use simple cases. curly-curly operator {{ allows tunnel data-variables passed function arguments inside tidy eval functions. {{ designed individual arguments. pass multiple arguments contained dots, use ... normal way.   enquo() enquos() delay execution one several function arguments. former returns single expression, latter returns list expressions. defused, expressions longer evaluate . must injected back evaluation context !! (single expression) !!! (list expressions).   simple case, code equivalent usage {{ ... . Defusing enquo() enquos() needed complex cases, instance need inspect modify expressions way. .data pronoun object represents current slice data. variable name string, use .data pronoun subset variable [[.   Another tidy eval operator :=. makes possible use glue curly-curly syntax LHS =. technical reasons, R language support complex expressions left =, use := workaround.   Many tidy eval functions like dplyr::mutate() dplyr::summarise() give automatic name unnamed inputs. need create sort automatic names , use as_label(). instance, glue-tunnelling syntax can reproduced manually :   Expressions defused enquo() (tunnelled {{) need simple column names, can arbitrarily complex. as_label() handles cases gracefully. code assumes simple column name, use as_name() instead. safer throws error input name expected.","code":"my_function <- function(data, var, ...) {   data %>%     group_by(...) %>%     summarise(mean = mean({{ var }})) } my_function <- function(data, var, ...) {   # Defuse   var <- enquo(var)   dots <- enquos(...)    # Inject   data %>%     group_by(!!!dots) %>%     summarise(mean = mean(!!var)) } my_var <- \"disp\" mtcars %>% summarise(mean = mean(.data[[my_var]])) my_function <- function(data, var, suffix = \"foo\") {   # Use `{{` to tunnel function arguments and the usual glue   # operator `{` to interpolate plain strings.   data %>%     summarise(\"{{ var }}_mean_{suffix}\" := mean({{ var }})) } my_function <- function(data, var, suffix = \"foo\") {   var <- enquo(var)   prefix <- as_label(var)   data %>%     summarise(\"{prefix}_mean_{suffix}\" := mean(!!var)) }"},{"path":"https://mark-eis.github.io/ParaAnita/reference/univ_anova.html","id":null,"dir":"Reference","previous_headings":"","what":"Analyses of Deviance Summarising Fits of Univariable GLMs — univ_anova","title":"Analyses of Deviance Summarising Fits of Univariable GLMs — univ_anova","text":"univ_anova() provides succinct summary analyses deviance univariable GLMs based possible categorical independent variable Bernoulli binomial data set.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/univ_anova.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analyses of Deviance Summarising Fits of Univariable GLMs — univ_anova","text":"","code":"univ_anova(   data,   .dep_var,   .family = binomial,   .test = c(\"none\", \"Rao\", \"LRT\", \"Chisq\", \"F\") )"},{"path":"https://mark-eis.github.io/ParaAnita/reference/univ_anova.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analyses of Deviance Summarising Fits of Univariable GLMs — univ_anova","text":"data data frame, data frame extension (e.g. tibble). .dep_var <data-masking> quoted name binary dependent variable, numeric values 0 1, two-column matrix columns giving numbers successes failures e.g., cbind(pn, qn). .family family function; default \"binomial\". (See family details family functions.) .test character string, (partially) matching one \"none\", \"Chisq\", \"LRT\", \"Rao\", \"F\" \"Cp\"; default \"none\".","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/univ_anova.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Analyses of Deviance Summarising Fits of Univariable GLMs — univ_anova","text":"object class c(\"univ_anova\" \"announce\"), inheriting \"anova\" \"data.frame\" add1(), summarising differences fitted univariable GLMs null model.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/univ_anova.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Analyses of Deviance Summarising Fits of Univariable GLMs — univ_anova","text":"univ_anova() uses add1() stats package compare univariable GLMs possible categorical independent variable (.e., \"factor\" columns) .data null model. data types e.g. \"character\" vectors ignored converted \"factor\" included analysis.","code":""},{"path":[]},{"path":"https://mark-eis.github.io/ParaAnita/reference/univ_anova.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Analyses of Deviance Summarising Fits of Univariable GLMs — univ_anova","text":"","code":"(d <- list(     iv2 = list(g = c(\"a\", \"c\", \"e\"), h = c(\"b\", \"d\", \"f\")),     iv3 = list(i = c(\"a\", \"b\", \"c\"), j = c(\"d\", \"e\", \"f\")),     iv4 = list(k = c(\"a\", \"b\"), l = c(\"c\", \"d\"), m = c(\"e\", \"f\")) ) |> add_grps(bernoulli_data(levels = 6), iv, .key = _)) #> ___________________________ #> Simulated Bernoulli Data: - #>  #> # A tibble: 396 × 5 #>    iv    iv2   iv3   iv4      dv #>    <fct> <fct> <fct> <fct> <int> #>  1 a     g     i     k         1 #>  2 a     g     i     k         0 #>  3 a     g     i     k         0 #>  4 a     g     i     k         1 #>  5 a     g     i     k         1 #>  6 a     g     i     k         0 #>  7 a     g     i     k         1 #>  8 a     g     i     k         0 #>  9 a     g     i     k         1 #> 10 a     g     i     k         1 #> # ℹ 386 more rows  d |> univ_anova(dv, .test = \"LRT\") #> ___________________________________ #> Univariable Analysis of Deviance: - #>  #> Single term additions #>  #> Model: #> dv ~ 1 #>        Df Deviance    AIC    LRT  Pr(>Chi)     #> <none>      477.19 479.19                      #> iv      5   423.91 435.91 53.284 2.941e-10 *** #> iv2     1   470.67 474.67  6.516   0.01069 *   #> iv3     1   432.95 436.95 44.241 2.903e-11 *** #> iv4     2   433.06 439.06 44.125 2.620e-10 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1  d |> binom_contingency(dv, starts_with(\"iv\")) |> print() |>      univ_anova(cbind(pn, qn), .test = \"LRT\") #> _____________________________ #> Binomial Contingency Table: - #>  #> # A tibble: 6 × 6 #>   iv    iv2   iv3   iv4      pn    qn #> * <fct> <fct> <fct> <fct> <int> <int> #> 1 a     g     i     k        38    28 #> 2 b     h     i     k        26    40 #> 3 c     g     i     l        23    43 #> 4 d     h     j     l        12    54 #> 5 e     g     j     m         8    58 #> 6 f     h     j     m         8    58 #> ___________________________________ #> Univariable Analysis of Deviance: - #>  #> Single term additions #>  #> Model: #> cbind(pn, qn) ~ 1 #>        Df Deviance    AIC    LRT  Pr(>Chi)     #> <none>      53.284 80.822                      #> iv      5    0.000 37.538 53.284 2.941e-10 *** #> iv2     1   46.768 76.306  6.516   0.01069 *   #> iv3     1    9.043 38.580 44.241 2.903e-11 *** #> iv4     2    9.159 40.696 44.125 2.620e-10 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1  rm(d)"},{"path":"https://mark-eis.github.io/ParaAnita/reference/var_labs.html","id":null,"dir":"Reference","previous_headings":"","what":"Format or Lookup Variable Names for Plot Titles — var_labs","title":"Format or Lookup Variable Names for Plot Titles — var_labs","text":"Vectorised labeller function used ggplot.glm_plotdata() revising variable names use subtitles individual plots facet labels faceted plots.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/var_labs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format or Lookup Variable Names for Plot Titles — var_labs","text":"","code":"var_labs(labels)"},{"path":"https://mark-eis.github.io/ParaAnita/reference/var_labs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format or Lookup Variable Names for Plot Titles — var_labs","text":"labels character vector containing names variables revised.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/var_labs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format or Lookup Variable Names for Plot Titles — var_labs","text":"character vector containing revised names.","code":""},{"path":"https://mark-eis.github.io/ParaAnita/reference/var_labs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Format or Lookup Variable Names for Plot Titles — var_labs","text":"var_labs package ParaAnita simply applies str_to_title argument. user may override providing vectorised labeller function, see labeller facet_wrap example.","code":""},{"path":[]},{"path":"https://mark-eis.github.io/ParaAnita/reference/var_labs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Format or Lookup Variable Names for Plot Titles — var_labs","text":"","code":"## Default labeller c(\"matthew\", \"mark\", \"luke\", \"john\") |> var_labs() #> [[1]] #> [1] \"Matthew\" #>  #> [[2]] #> [1] \"Mark\" #>  #> [[3]] #> [1] \"Luke\" #>  #> [[4]] #> [1] \"John\" #>   ygps <- c(\"year\", \"ygroup1\", \"ygroup2\", \"ygroup3\", \"ygroup4\", \"ygroup5\", \"ygroup6\", \"ygroup7\") mgps <- c(\"month\", \"season\", \"mgroup2\", \"mgroup3\", \"mgroup4\", \"mgroup5\", \"mgroup6\") demog <- c(\"gender\", \"age_group\", \"location\", \"breed\")  # Vectorised function to replace terse variable names with names suitable for labelling plots var_labs <- as_labeller(     c(         c(\"Year\", paste(\"Year Group\", seq_along(ygps[-1]))) |> set_names(ygps),         c(\"Month\", \"Season\", paste(\"Month Group\", seq_along(mgps[-1])[-1])) |> set_names(mgps),         c(\"Animal Gender\", \"Age Group\", \"Geographic Location\", \"Cattle Breed\") |> set_names(demog)     ) )  ygps |> var_labs() #> [[1]] #> [1] \"Year\" #>  #> [[2]] #> [1] \"Year Group 1\" #>  #> [[3]] #> [1] \"Year Group 2\" #>  #> [[4]] #> [1] \"Year Group 3\" #>  #> [[5]] #> [1] \"Year Group 4\" #>  #> [[6]] #> [1] \"Year Group 5\" #>  #> [[7]] #> [1] \"Year Group 6\" #>  #> [[8]] #> [1] \"Year Group 7\" #>  mgps |> var_labs() #> [[1]] #> [1] \"Month\" #>  #> [[2]] #> [1] \"Season\" #>  #> [[3]] #> [1] \"Month Group 2\" #>  #> [[4]] #> [1] \"Month Group 3\" #>  #> [[5]] #> [1] \"Month Group 4\" #>  #> [[6]] #> [1] \"Month Group 5\" #>  #> [[7]] #> [1] \"Month Group 6\" #>  demog |> var_labs() #> [[1]] #> [1] \"Animal Gender\" #>  #> [[2]] #> [1] \"Age Group\" #>  #> [[3]] #> [1] \"Geographic Location\" #>  #> [[4]] #> [1] \"Cattle Breed\" #>   rm(demog, mgps, var_labs, ygps)"}]
